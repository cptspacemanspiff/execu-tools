class GraphModule(torch.nn.Module):
    def forward(self, p_model_model_encoder_embed_positions_weight: "f32[512, 512]", p_model_model_decoder_embed_positions_weight: "f32[512, 512]", p_model_model_encoder_embed_tokens_weight: "f32[59514, 512]", p_model_model_encoder_layers_0_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_0_self_attn_q_proj_bias: "f32[512]", p_model_model_encoder_layers_0_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_0_self_attn_k_proj_bias: "f32[512]", p_model_model_encoder_layers_0_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_0_self_attn_v_proj_bias: "f32[512]", p_model_model_encoder_layers_0_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_0_self_attn_out_proj_bias: "f32[512]", p_model_model_encoder_layers_0_self_attn_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_0_self_attn_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_0_fc1_weight: "f32[2048, 512]", p_model_model_encoder_layers_0_fc1_bias: "f32[2048]", p_model_model_encoder_layers_0_fc2_weight: "f32[512, 2048]", p_model_model_encoder_layers_0_fc2_bias: "f32[512]", p_model_model_encoder_layers_0_final_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_0_final_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_1_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_1_self_attn_q_proj_bias: "f32[512]", p_model_model_encoder_layers_1_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_1_self_attn_k_proj_bias: "f32[512]", p_model_model_encoder_layers_1_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_1_self_attn_v_proj_bias: "f32[512]", p_model_model_encoder_layers_1_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_1_self_attn_out_proj_bias: "f32[512]", p_model_model_encoder_layers_1_self_attn_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_1_self_attn_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_1_fc1_weight: "f32[2048, 512]", p_model_model_encoder_layers_1_fc1_bias: "f32[2048]", p_model_model_encoder_layers_1_fc2_weight: "f32[512, 2048]", p_model_model_encoder_layers_1_fc2_bias: "f32[512]", p_model_model_encoder_layers_1_final_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_1_final_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_2_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_2_self_attn_q_proj_bias: "f32[512]", p_model_model_encoder_layers_2_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_2_self_attn_k_proj_bias: "f32[512]", p_model_model_encoder_layers_2_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_2_self_attn_v_proj_bias: "f32[512]", p_model_model_encoder_layers_2_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_2_self_attn_out_proj_bias: "f32[512]", p_model_model_encoder_layers_2_self_attn_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_2_self_attn_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_2_fc1_weight: "f32[2048, 512]", p_model_model_encoder_layers_2_fc1_bias: "f32[2048]", p_model_model_encoder_layers_2_fc2_weight: "f32[512, 2048]", p_model_model_encoder_layers_2_fc2_bias: "f32[512]", p_model_model_encoder_layers_2_final_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_2_final_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_3_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_3_self_attn_q_proj_bias: "f32[512]", p_model_model_encoder_layers_3_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_3_self_attn_k_proj_bias: "f32[512]", p_model_model_encoder_layers_3_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_3_self_attn_v_proj_bias: "f32[512]", p_model_model_encoder_layers_3_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_3_self_attn_out_proj_bias: "f32[512]", p_model_model_encoder_layers_3_self_attn_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_3_self_attn_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_3_fc1_weight: "f32[2048, 512]", p_model_model_encoder_layers_3_fc1_bias: "f32[2048]", p_model_model_encoder_layers_3_fc2_weight: "f32[512, 2048]", p_model_model_encoder_layers_3_fc2_bias: "f32[512]", p_model_model_encoder_layers_3_final_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_3_final_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_4_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_4_self_attn_q_proj_bias: "f32[512]", p_model_model_encoder_layers_4_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_4_self_attn_k_proj_bias: "f32[512]", p_model_model_encoder_layers_4_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_4_self_attn_v_proj_bias: "f32[512]", p_model_model_encoder_layers_4_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_4_self_attn_out_proj_bias: "f32[512]", p_model_model_encoder_layers_4_self_attn_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_4_self_attn_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_4_fc1_weight: "f32[2048, 512]", p_model_model_encoder_layers_4_fc1_bias: "f32[2048]", p_model_model_encoder_layers_4_fc2_weight: "f32[512, 2048]", p_model_model_encoder_layers_4_fc2_bias: "f32[512]", p_model_model_encoder_layers_4_final_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_4_final_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_5_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_5_self_attn_q_proj_bias: "f32[512]", p_model_model_encoder_layers_5_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_5_self_attn_k_proj_bias: "f32[512]", p_model_model_encoder_layers_5_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_5_self_attn_v_proj_bias: "f32[512]", p_model_model_encoder_layers_5_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_encoder_layers_5_self_attn_out_proj_bias: "f32[512]", p_model_model_encoder_layers_5_self_attn_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_5_self_attn_layer_norm_bias: "f32[512]", p_model_model_encoder_layers_5_fc1_weight: "f32[2048, 512]", p_model_model_encoder_layers_5_fc1_bias: "f32[2048]", p_model_model_encoder_layers_5_fc2_weight: "f32[512, 2048]", p_model_model_encoder_layers_5_fc2_bias: "f32[512]", p_model_model_encoder_layers_5_final_layer_norm_weight: "f32[512]", p_model_model_encoder_layers_5_final_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_0_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_self_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_0_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_self_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_0_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_self_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_0_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_self_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_0_self_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_0_self_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_0_encoder_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_encoder_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_0_encoder_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_encoder_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_0_encoder_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_encoder_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_0_encoder_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_0_encoder_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_0_fc1_weight: "f32[2048, 512]", p_model_model_decoder_layers_0_fc1_bias: "f32[2048]", p_model_model_decoder_layers_0_fc2_weight: "f32[512, 2048]", p_model_model_decoder_layers_0_fc2_bias: "f32[512]", p_model_model_decoder_layers_0_final_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_0_final_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_1_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_self_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_1_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_self_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_1_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_self_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_1_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_self_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_1_self_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_1_self_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_1_encoder_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_encoder_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_1_encoder_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_encoder_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_1_encoder_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_encoder_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_1_encoder_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_1_encoder_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_1_fc1_weight: "f32[2048, 512]", p_model_model_decoder_layers_1_fc1_bias: "f32[2048]", p_model_model_decoder_layers_1_fc2_weight: "f32[512, 2048]", p_model_model_decoder_layers_1_fc2_bias: "f32[512]", p_model_model_decoder_layers_1_final_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_1_final_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_2_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_self_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_2_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_self_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_2_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_self_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_2_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_self_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_2_self_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_2_self_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_2_encoder_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_encoder_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_2_encoder_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_encoder_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_2_encoder_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_encoder_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_2_encoder_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_2_encoder_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_2_fc1_weight: "f32[2048, 512]", p_model_model_decoder_layers_2_fc1_bias: "f32[2048]", p_model_model_decoder_layers_2_fc2_weight: "f32[512, 2048]", p_model_model_decoder_layers_2_fc2_bias: "f32[512]", p_model_model_decoder_layers_2_final_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_2_final_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_3_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_self_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_3_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_self_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_3_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_self_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_3_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_self_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_3_self_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_3_self_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_3_encoder_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_encoder_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_3_encoder_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_encoder_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_3_encoder_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_encoder_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_3_encoder_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_3_encoder_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_3_fc1_weight: "f32[2048, 512]", p_model_model_decoder_layers_3_fc1_bias: "f32[2048]", p_model_model_decoder_layers_3_fc2_weight: "f32[512, 2048]", p_model_model_decoder_layers_3_fc2_bias: "f32[512]", p_model_model_decoder_layers_3_final_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_3_final_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_4_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_self_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_4_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_self_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_4_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_self_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_4_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_self_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_4_self_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_4_self_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_4_encoder_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_encoder_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_4_encoder_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_encoder_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_4_encoder_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_encoder_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_4_encoder_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_4_encoder_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_4_fc1_weight: "f32[2048, 512]", p_model_model_decoder_layers_4_fc1_bias: "f32[2048]", p_model_model_decoder_layers_4_fc2_weight: "f32[512, 2048]", p_model_model_decoder_layers_4_fc2_bias: "f32[512]", p_model_model_decoder_layers_4_final_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_4_final_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_5_self_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_self_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_5_self_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_self_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_5_self_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_self_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_5_self_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_self_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_5_self_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_5_self_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_5_encoder_attn_q_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_encoder_attn_q_proj_bias: "f32[512]", p_model_model_decoder_layers_5_encoder_attn_k_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_encoder_attn_k_proj_bias: "f32[512]", p_model_model_decoder_layers_5_encoder_attn_v_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_encoder_attn_v_proj_bias: "f32[512]", p_model_model_decoder_layers_5_encoder_attn_out_proj_weight: "f32[512, 512]", p_model_model_decoder_layers_5_encoder_attn_out_proj_bias: "f32[512]", p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias: "f32[512]", p_model_model_decoder_layers_5_fc1_weight: "f32[2048, 512]", p_model_model_decoder_layers_5_fc1_bias: "f32[2048]", p_model_model_decoder_layers_5_fc2_weight: "f32[512, 2048]", p_model_model_decoder_layers_5_fc2_bias: "f32[512]", p_model_model_decoder_layers_5_final_layer_norm_weight: "f32[512]", p_model_model_decoder_layers_5_final_layer_norm_bias: "f32[512]", p_model_lm_head_weight: "f32[59514, 512]", b___cache_self_attention_cache_key_cache_0: "f32[1, 8, 20, 64]", b___cache_self_attention_cache_value_cache_0: "f32[1, 8, 20, 64]", b___cache_cross_attention_cache_key_cache_0: "f32[1, 8, 40, 64]", b___cache_cross_attention_cache_value_cache_0: "f32[1, 8, 40, 64]", b___cache_self_attention_cache_key_cache_1: "f32[1, 8, 20, 64]", b___cache_self_attention_cache_value_cache_1: "f32[1, 8, 20, 64]", b___cache_cross_attention_cache_key_cache_1: "f32[1, 8, 40, 64]", b___cache_cross_attention_cache_value_cache_1: "f32[1, 8, 40, 64]", b___cache_self_attention_cache_key_cache_2: "f32[1, 8, 20, 64]", b___cache_self_attention_cache_value_cache_2: "f32[1, 8, 20, 64]", b___cache_cross_attention_cache_key_cache_2: "f32[1, 8, 40, 64]", b___cache_cross_attention_cache_value_cache_2: "f32[1, 8, 40, 64]", b___cache_self_attention_cache_key_cache_3: "f32[1, 8, 20, 64]", b___cache_self_attention_cache_value_cache_3: "f32[1, 8, 20, 64]", b___cache_cross_attention_cache_key_cache_3: "f32[1, 8, 40, 64]", b___cache_cross_attention_cache_value_cache_3: "f32[1, 8, 40, 64]", b___cache_self_attention_cache_key_cache_4: "f32[1, 8, 20, 64]", b___cache_self_attention_cache_value_cache_4: "f32[1, 8, 20, 64]", b___cache_cross_attention_cache_key_cache_4: "f32[1, 8, 40, 64]", b___cache_cross_attention_cache_value_cache_4: "f32[1, 8, 40, 64]", b___cache_self_attention_cache_key_cache_5: "f32[1, 8, 20, 64]", b___cache_self_attention_cache_value_cache_5: "f32[1, 8, 20, 64]", b___cache_cross_attention_cache_key_cache_5: "f32[1, 8, 40, 64]", b___cache_cross_attention_cache_value_cache_5: "f32[1, 8, 40, 64]", b_model_final_logits_bias: "f32[1, 59514]", c_lifted_tensor_0: "i64[]", c_lifted_tensor_1: "i64[]", c_lifted_tensor_2: "i64[]", c_lifted_tensor_3: "i64[]", c_lifted_tensor_4: "i64[1]", c_lifted_tensor_5: "f32[]", c_lifted_tensor_6: "f32[]", inputs: "i64[1, 23]"):
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:1845 in _tensor_or_none, code: return torch.tensor(token, device=device, dtype=torch.long)
        lift_fresh_copy: "i64[]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_0);  c_lifted_tensor_0 = None
        detach_: "i64[]" = torch.ops.aten.detach_.default(lift_fresh_copy);  lift_fresh_copy = detach_ = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:1845 in _tensor_or_none, code: return torch.tensor(token, device=device, dtype=torch.long)
        lift_fresh_copy_1: "i64[]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_1);  c_lifted_tensor_1 = None
        detach__1: "i64[]" = torch.ops.aten.detach_.default(lift_fresh_copy_1);  lift_fresh_copy_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:1845 in _tensor_or_none, code: return torch.tensor(token, device=device, dtype=torch.long)
        lift_fresh_copy_2: "i64[]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_2);  c_lifted_tensor_2 = None
        detach__2: "i64[]" = torch.ops.aten.detach_.default(lift_fresh_copy_2);  lift_fresh_copy_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:1845 in _tensor_or_none, code: return torch.tensor(token, device=device, dtype=torch.long)
        lift_fresh_copy_3: "i64[]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_3);  c_lifted_tensor_3 = None
        detach__3: "i64[]" = torch.ops.aten.detach_.default(lift_fresh_copy_3);  lift_fresh_copy_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:1860 in _prepare_special_tokens, code: eos_token_tensor = eos_token_tensor.unsqueeze(0)
        unsqueeze: "i64[1]" = torch.ops.aten.unsqueeze.default(detach__1, 0);  detach__1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:593 in _prepare_attention_mask_for_generation, code: default_attention_mask = torch.ones(inputs_tensor.shape[:2], dtype=torch.long, device=inputs_tensor.device)
        ones: "i64[1, 23]" = torch.ops.aten.ones.default([1, 23], dtype = torch.int64, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin: "b8[1, 23]" = torch.ops.aten.isin.Tensor_Tensor(inputs, detach__2)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:602 in _prepare_attention_mask_for_generation, code: isin_mps_friendly(elements=inputs_tensor, test_elements=pad_token_id).any()
        any_1: "b8[]" = torch.ops.aten.any.default(isin);  isin = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_1: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(unsqueeze, detach__2)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:605 in _prepare_attention_mask_for_generation, code: isin_mps_friendly(elements=eos_token_id, test_elements=pad_token_id).any()
        any_2: "b8[]" = torch.ops.aten.any.default(isin_1);  isin_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:604 in _prepare_attention_mask_for_generation, code: is_pad_token_not_equal_to_eos_token_id = (eos_token_id is None) or ~(
        bitwise_not: "b8[]" = torch.ops.aten.bitwise_not.default(any_2);  any_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:607 in _prepare_attention_mask_for_generation, code: can_infer_attention_mask = is_pad_token_in_inputs * is_pad_token_not_equal_to_eos_token_id
        mul: "b8[]" = torch.ops.aten.mul.Tensor(any_1, bitwise_not);  any_1 = bitwise_not = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:608 in _prepare_attention_mask_for_generation, code: attention_mask_from_padding = inputs_tensor.ne(pad_token_id).long()
        ne: "b8[1, 23]" = torch.ops.aten.ne.Tensor(inputs, detach__2)
        to: "i64[1, 23]" = torch.ops.aten.to.dtype(ne, torch.int64);  ne = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:611 in _prepare_attention_mask_for_generation, code: attention_mask_from_padding * can_infer_attention_mask + default_attention_mask * ~can_infer_attention_mask
        mul_1: "i64[1, 23]" = torch.ops.aten.mul.Tensor(to, mul);  to = None
        bitwise_not_1: "b8[]" = torch.ops.aten.bitwise_not.default(mul);  mul = None
        mul_2: "i64[1, 23]" = torch.ops.aten.mul.Tensor(ones, bitwise_not_1);  ones = bitwise_not_1 = None
        add: "i64[1, 23]" = torch.ops.aten.add.Tensor(mul_1, mul_2);  mul_1 = mul_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:728 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view: "i64[1, 23]" = torch.ops.aten.view.default(inputs, [-1, 23]);  inputs = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:735 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding: "f32[1, 23, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view, 59513);  view = None
        mul_3: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(embedding, 22.627416997969522);  embedding = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:102 in forward, code: positions = torch.arange(
        arange: "i64[23]" = torch.ops.aten.arange.start(0, 23, dtype = torch.int64, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_1: "f32[23, 512]" = torch.ops.aten.embedding.default(p_model_model_encoder_embed_positions_weight, arange);  p_model_model_encoder_embed_positions_weight = arange = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:739 in forward, code: hidden_states = inputs_embeds + embed_pos
        add_1: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(mul_3, embedding_1);  mul_3 = embedding_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:740 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(add_1, 0.1, False);  add_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_1: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1, 1);  slice_1 = None
        unsqueeze_2: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_1, 2);  unsqueeze_1 = None
        slice_2: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_2, 3, 0, 9223372036854775807);  unsqueeze_2 = None
        expand: "i64[1, 1, 23, 23]" = torch.ops.aten.expand.default(slice_2, [1, 1, 23, 23]);  slice_2 = None
        to_1: "f32[1, 1, 23, 23]" = torch.ops.aten.to.dtype(expand, torch.float32);  expand = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub: "f32[1, 1, 23, 23]" = torch.ops.aten.rsub.Scalar(to_1, 1.0);  to_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_2: "b8[1, 1, 23, 23]" = torch.ops.aten.to.dtype(rsub, torch.bool)
        masked_fill: "f32[1, 1, 23, 23]" = torch.ops.aten.masked_fill.Scalar(rsub, to_2, -3.4028234663852886e+38);  rsub = to_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout, p_model_model_encoder_layers_0_self_attn_q_proj_weight, p_model_model_encoder_layers_0_self_attn_q_proj_bias);  p_model_model_encoder_layers_0_self_attn_q_proj_weight = p_model_model_encoder_layers_0_self_attn_q_proj_bias = None
        mul_4: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(linear, 0.125);  linear = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_1: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(mul_4, [1, 23, 8, 64]);  mul_4 = None
        transpose: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None
        contiguous: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose);  transpose = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_1: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout, p_model_model_encoder_layers_0_self_attn_k_proj_weight, p_model_model_encoder_layers_0_self_attn_k_proj_bias);  p_model_model_encoder_layers_0_self_attn_k_proj_weight = p_model_model_encoder_layers_0_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_2: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_1, [1, -1, 8, 64]);  linear_1 = None
        transpose_1: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None
        contiguous_1: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_1);  transpose_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_2: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout, p_model_model_encoder_layers_0_self_attn_v_proj_weight, p_model_model_encoder_layers_0_self_attn_v_proj_bias);  p_model_model_encoder_layers_0_self_attn_v_proj_weight = p_model_model_encoder_layers_0_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_3: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_2, [1, -1, 8, 64]);  linear_2 = None
        transpose_2: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_3, 1, 2);  view_3 = None
        contiguous_2: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_2);  transpose_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_3: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(contiguous_1, 2, 3);  contiguous_1 = None
        matmul: "f32[1, 8, 23, 23]" = torch.ops.aten.matmul.default(contiguous, transpose_3);  contiguous = transpose_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_3: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(masked_fill, 0, 0, 9223372036854775807)
        slice_4: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_3, 1, 0, 9223372036854775807);  slice_3 = None
        slice_5: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_4, 2, 0, 9223372036854775807);  slice_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_2: "f32[1, 8, 23, 23]" = torch.ops.aten.add.Tensor(matmul, slice_5);  matmul = slice_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax: "f32[1, 8, 23, 23]" = torch.ops.aten.softmax.int(add_2, -1);  add_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_1: "f32[1, 8, 23, 23]" = torch.ops.aten.dropout.default(softmax, 0.0, False);  softmax = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_1: "f32[1, 8, 23, 64]" = torch.ops.aten.matmul.default(dropout_1, contiguous_2);  dropout_1 = contiguous_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_4: "f32[1, 23, 8, 64]" = torch.ops.aten.transpose.int(matmul_1, 1, 2);  matmul_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape: "f32[1, 23, 512]" = torch.ops.aten.reshape.default(transpose_4, [1, 23, 512]);  transpose_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_3: "f32[1, 23, 512]" = torch.ops.aten.linear.default(reshape, p_model_model_encoder_layers_0_self_attn_out_proj_weight, p_model_model_encoder_layers_0_self_attn_out_proj_bias);  reshape = p_model_model_encoder_layers_0_self_attn_out_proj_weight = p_model_model_encoder_layers_0_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:307 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_2: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_3, 0.1, False);  linear_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:308 in forward, code: hidden_states = residual + hidden_states
        add_3: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(dropout, dropout_2);  dropout = dropout_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:309 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_3, [512], p_model_model_encoder_layers_0_self_attn_layer_norm_weight, p_model_model_encoder_layers_0_self_attn_layer_norm_bias);  add_3 = p_model_model_encoder_layers_0_self_attn_layer_norm_weight = p_model_model_encoder_layers_0_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:312 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_4: "f32[1, 23, 2048]" = torch.ops.aten.linear.default(layer_norm, p_model_model_encoder_layers_0_fc1_weight, p_model_model_encoder_layers_0_fc1_bias);  p_model_model_encoder_layers_0_fc1_weight = p_model_model_encoder_layers_0_fc1_bias = None
        silu: "f32[1, 23, 2048]" = torch.ops.aten.silu.default(linear_4);  linear_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:313 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_3: "f32[1, 23, 2048]" = torch.ops.aten.dropout.default(silu, 0.0, False);  silu = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:314 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_5: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout_3, p_model_model_encoder_layers_0_fc2_weight, p_model_model_encoder_layers_0_fc2_bias);  dropout_3 = p_model_model_encoder_layers_0_fc2_weight = p_model_model_encoder_layers_0_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:315 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_4: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_5, 0.1, False);  linear_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:316 in forward, code: hidden_states = residual + hidden_states
        add_4: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm, dropout_4);  layer_norm = dropout_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:317 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_1: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_4, [512], p_model_model_encoder_layers_0_final_layer_norm_weight, p_model_model_encoder_layers_0_final_layer_norm_bias);  add_4 = p_model_model_encoder_layers_0_final_layer_norm_weight = p_model_model_encoder_layers_0_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_6: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_1, p_model_model_encoder_layers_1_self_attn_q_proj_weight, p_model_model_encoder_layers_1_self_attn_q_proj_bias);  p_model_model_encoder_layers_1_self_attn_q_proj_weight = p_model_model_encoder_layers_1_self_attn_q_proj_bias = None
        mul_5: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(linear_6, 0.125);  linear_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_4: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(mul_5, [1, 23, 8, 64]);  mul_5 = None
        transpose_5: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_4, 1, 2);  view_4 = None
        contiguous_3: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_5);  transpose_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_7: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_1, p_model_model_encoder_layers_1_self_attn_k_proj_weight, p_model_model_encoder_layers_1_self_attn_k_proj_bias);  p_model_model_encoder_layers_1_self_attn_k_proj_weight = p_model_model_encoder_layers_1_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_5: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_7, [1, -1, 8, 64]);  linear_7 = None
        transpose_6: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_5, 1, 2);  view_5 = None
        contiguous_4: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_6);  transpose_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_8: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_1, p_model_model_encoder_layers_1_self_attn_v_proj_weight, p_model_model_encoder_layers_1_self_attn_v_proj_bias);  p_model_model_encoder_layers_1_self_attn_v_proj_weight = p_model_model_encoder_layers_1_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_6: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_8, [1, -1, 8, 64]);  linear_8 = None
        transpose_7: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_6, 1, 2);  view_6 = None
        contiguous_5: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_7);  transpose_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_8: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(contiguous_4, 2, 3);  contiguous_4 = None
        matmul_2: "f32[1, 8, 23, 23]" = torch.ops.aten.matmul.default(contiguous_3, transpose_8);  contiguous_3 = transpose_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_6: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(masked_fill, 0, 0, 9223372036854775807)
        slice_7: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_6, 1, 0, 9223372036854775807);  slice_6 = None
        slice_8: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_7, 2, 0, 9223372036854775807);  slice_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_5: "f32[1, 8, 23, 23]" = torch.ops.aten.add.Tensor(matmul_2, slice_8);  matmul_2 = slice_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_1: "f32[1, 8, 23, 23]" = torch.ops.aten.softmax.int(add_5, -1);  add_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_5: "f32[1, 8, 23, 23]" = torch.ops.aten.dropout.default(softmax_1, 0.0, False);  softmax_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_3: "f32[1, 8, 23, 64]" = torch.ops.aten.matmul.default(dropout_5, contiguous_5);  dropout_5 = contiguous_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_9: "f32[1, 23, 8, 64]" = torch.ops.aten.transpose.int(matmul_3, 1, 2);  matmul_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_1: "f32[1, 23, 512]" = torch.ops.aten.reshape.default(transpose_9, [1, 23, 512]);  transpose_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_9: "f32[1, 23, 512]" = torch.ops.aten.linear.default(reshape_1, p_model_model_encoder_layers_1_self_attn_out_proj_weight, p_model_model_encoder_layers_1_self_attn_out_proj_bias);  reshape_1 = p_model_model_encoder_layers_1_self_attn_out_proj_weight = p_model_model_encoder_layers_1_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:307 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_6: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_9, 0.1, False);  linear_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:308 in forward, code: hidden_states = residual + hidden_states
        add_6: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_1, dropout_6);  layer_norm_1 = dropout_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:309 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_2: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_6, [512], p_model_model_encoder_layers_1_self_attn_layer_norm_weight, p_model_model_encoder_layers_1_self_attn_layer_norm_bias);  add_6 = p_model_model_encoder_layers_1_self_attn_layer_norm_weight = p_model_model_encoder_layers_1_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:312 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_10: "f32[1, 23, 2048]" = torch.ops.aten.linear.default(layer_norm_2, p_model_model_encoder_layers_1_fc1_weight, p_model_model_encoder_layers_1_fc1_bias);  p_model_model_encoder_layers_1_fc1_weight = p_model_model_encoder_layers_1_fc1_bias = None
        silu_1: "f32[1, 23, 2048]" = torch.ops.aten.silu.default(linear_10);  linear_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:313 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_7: "f32[1, 23, 2048]" = torch.ops.aten.dropout.default(silu_1, 0.0, False);  silu_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:314 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_11: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout_7, p_model_model_encoder_layers_1_fc2_weight, p_model_model_encoder_layers_1_fc2_bias);  dropout_7 = p_model_model_encoder_layers_1_fc2_weight = p_model_model_encoder_layers_1_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:315 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_8: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_11, 0.1, False);  linear_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:316 in forward, code: hidden_states = residual + hidden_states
        add_7: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_2, dropout_8);  layer_norm_2 = dropout_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:317 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_3: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_7, [512], p_model_model_encoder_layers_1_final_layer_norm_weight, p_model_model_encoder_layers_1_final_layer_norm_bias);  add_7 = p_model_model_encoder_layers_1_final_layer_norm_weight = p_model_model_encoder_layers_1_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_12: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_3, p_model_model_encoder_layers_2_self_attn_q_proj_weight, p_model_model_encoder_layers_2_self_attn_q_proj_bias);  p_model_model_encoder_layers_2_self_attn_q_proj_weight = p_model_model_encoder_layers_2_self_attn_q_proj_bias = None
        mul_6: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(linear_12, 0.125);  linear_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_7: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(mul_6, [1, 23, 8, 64]);  mul_6 = None
        transpose_10: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_7, 1, 2);  view_7 = None
        contiguous_6: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_10);  transpose_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_13: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_3, p_model_model_encoder_layers_2_self_attn_k_proj_weight, p_model_model_encoder_layers_2_self_attn_k_proj_bias);  p_model_model_encoder_layers_2_self_attn_k_proj_weight = p_model_model_encoder_layers_2_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_8: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_13, [1, -1, 8, 64]);  linear_13 = None
        transpose_11: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_8, 1, 2);  view_8 = None
        contiguous_7: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_11);  transpose_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_14: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_3, p_model_model_encoder_layers_2_self_attn_v_proj_weight, p_model_model_encoder_layers_2_self_attn_v_proj_bias);  p_model_model_encoder_layers_2_self_attn_v_proj_weight = p_model_model_encoder_layers_2_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_9: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_14, [1, -1, 8, 64]);  linear_14 = None
        transpose_12: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_9, 1, 2);  view_9 = None
        contiguous_8: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_12);  transpose_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_13: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(contiguous_7, 2, 3);  contiguous_7 = None
        matmul_4: "f32[1, 8, 23, 23]" = torch.ops.aten.matmul.default(contiguous_6, transpose_13);  contiguous_6 = transpose_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_9: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(masked_fill, 0, 0, 9223372036854775807)
        slice_10: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_9, 1, 0, 9223372036854775807);  slice_9 = None
        slice_11: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_10, 2, 0, 9223372036854775807);  slice_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_8: "f32[1, 8, 23, 23]" = torch.ops.aten.add.Tensor(matmul_4, slice_11);  matmul_4 = slice_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_2: "f32[1, 8, 23, 23]" = torch.ops.aten.softmax.int(add_8, -1);  add_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_9: "f32[1, 8, 23, 23]" = torch.ops.aten.dropout.default(softmax_2, 0.0, False);  softmax_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_5: "f32[1, 8, 23, 64]" = torch.ops.aten.matmul.default(dropout_9, contiguous_8);  dropout_9 = contiguous_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_14: "f32[1, 23, 8, 64]" = torch.ops.aten.transpose.int(matmul_5, 1, 2);  matmul_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_2: "f32[1, 23, 512]" = torch.ops.aten.reshape.default(transpose_14, [1, 23, 512]);  transpose_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_15: "f32[1, 23, 512]" = torch.ops.aten.linear.default(reshape_2, p_model_model_encoder_layers_2_self_attn_out_proj_weight, p_model_model_encoder_layers_2_self_attn_out_proj_bias);  reshape_2 = p_model_model_encoder_layers_2_self_attn_out_proj_weight = p_model_model_encoder_layers_2_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:307 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_10: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_15, 0.1, False);  linear_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:308 in forward, code: hidden_states = residual + hidden_states
        add_9: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_3, dropout_10);  layer_norm_3 = dropout_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:309 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_4: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_9, [512], p_model_model_encoder_layers_2_self_attn_layer_norm_weight, p_model_model_encoder_layers_2_self_attn_layer_norm_bias);  add_9 = p_model_model_encoder_layers_2_self_attn_layer_norm_weight = p_model_model_encoder_layers_2_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:312 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_16: "f32[1, 23, 2048]" = torch.ops.aten.linear.default(layer_norm_4, p_model_model_encoder_layers_2_fc1_weight, p_model_model_encoder_layers_2_fc1_bias);  p_model_model_encoder_layers_2_fc1_weight = p_model_model_encoder_layers_2_fc1_bias = None
        silu_2: "f32[1, 23, 2048]" = torch.ops.aten.silu.default(linear_16);  linear_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:313 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_11: "f32[1, 23, 2048]" = torch.ops.aten.dropout.default(silu_2, 0.0, False);  silu_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:314 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_17: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout_11, p_model_model_encoder_layers_2_fc2_weight, p_model_model_encoder_layers_2_fc2_bias);  dropout_11 = p_model_model_encoder_layers_2_fc2_weight = p_model_model_encoder_layers_2_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:315 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_12: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_17, 0.1, False);  linear_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:316 in forward, code: hidden_states = residual + hidden_states
        add_10: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_4, dropout_12);  layer_norm_4 = dropout_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:317 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_5: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_10, [512], p_model_model_encoder_layers_2_final_layer_norm_weight, p_model_model_encoder_layers_2_final_layer_norm_bias);  add_10 = p_model_model_encoder_layers_2_final_layer_norm_weight = p_model_model_encoder_layers_2_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_18: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_5, p_model_model_encoder_layers_3_self_attn_q_proj_weight, p_model_model_encoder_layers_3_self_attn_q_proj_bias);  p_model_model_encoder_layers_3_self_attn_q_proj_weight = p_model_model_encoder_layers_3_self_attn_q_proj_bias = None
        mul_7: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(linear_18, 0.125);  linear_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_10: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(mul_7, [1, 23, 8, 64]);  mul_7 = None
        transpose_15: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_10, 1, 2);  view_10 = None
        contiguous_9: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_15);  transpose_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_19: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_5, p_model_model_encoder_layers_3_self_attn_k_proj_weight, p_model_model_encoder_layers_3_self_attn_k_proj_bias);  p_model_model_encoder_layers_3_self_attn_k_proj_weight = p_model_model_encoder_layers_3_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_11: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_19, [1, -1, 8, 64]);  linear_19 = None
        transpose_16: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_11, 1, 2);  view_11 = None
        contiguous_10: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_16);  transpose_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_20: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_5, p_model_model_encoder_layers_3_self_attn_v_proj_weight, p_model_model_encoder_layers_3_self_attn_v_proj_bias);  p_model_model_encoder_layers_3_self_attn_v_proj_weight = p_model_model_encoder_layers_3_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_12: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_20, [1, -1, 8, 64]);  linear_20 = None
        transpose_17: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_12, 1, 2);  view_12 = None
        contiguous_11: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_17);  transpose_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_18: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(contiguous_10, 2, 3);  contiguous_10 = None
        matmul_6: "f32[1, 8, 23, 23]" = torch.ops.aten.matmul.default(contiguous_9, transpose_18);  contiguous_9 = transpose_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_12: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(masked_fill, 0, 0, 9223372036854775807)
        slice_13: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_12, 1, 0, 9223372036854775807);  slice_12 = None
        slice_14: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_13, 2, 0, 9223372036854775807);  slice_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_11: "f32[1, 8, 23, 23]" = torch.ops.aten.add.Tensor(matmul_6, slice_14);  matmul_6 = slice_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_3: "f32[1, 8, 23, 23]" = torch.ops.aten.softmax.int(add_11, -1);  add_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_13: "f32[1, 8, 23, 23]" = torch.ops.aten.dropout.default(softmax_3, 0.0, False);  softmax_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_7: "f32[1, 8, 23, 64]" = torch.ops.aten.matmul.default(dropout_13, contiguous_11);  dropout_13 = contiguous_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_19: "f32[1, 23, 8, 64]" = torch.ops.aten.transpose.int(matmul_7, 1, 2);  matmul_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_3: "f32[1, 23, 512]" = torch.ops.aten.reshape.default(transpose_19, [1, 23, 512]);  transpose_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_21: "f32[1, 23, 512]" = torch.ops.aten.linear.default(reshape_3, p_model_model_encoder_layers_3_self_attn_out_proj_weight, p_model_model_encoder_layers_3_self_attn_out_proj_bias);  reshape_3 = p_model_model_encoder_layers_3_self_attn_out_proj_weight = p_model_model_encoder_layers_3_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:307 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_14: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_21, 0.1, False);  linear_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:308 in forward, code: hidden_states = residual + hidden_states
        add_12: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_5, dropout_14);  layer_norm_5 = dropout_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:309 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_6: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_12, [512], p_model_model_encoder_layers_3_self_attn_layer_norm_weight, p_model_model_encoder_layers_3_self_attn_layer_norm_bias);  add_12 = p_model_model_encoder_layers_3_self_attn_layer_norm_weight = p_model_model_encoder_layers_3_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:312 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_22: "f32[1, 23, 2048]" = torch.ops.aten.linear.default(layer_norm_6, p_model_model_encoder_layers_3_fc1_weight, p_model_model_encoder_layers_3_fc1_bias);  p_model_model_encoder_layers_3_fc1_weight = p_model_model_encoder_layers_3_fc1_bias = None
        silu_3: "f32[1, 23, 2048]" = torch.ops.aten.silu.default(linear_22);  linear_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:313 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_15: "f32[1, 23, 2048]" = torch.ops.aten.dropout.default(silu_3, 0.0, False);  silu_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:314 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_23: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout_15, p_model_model_encoder_layers_3_fc2_weight, p_model_model_encoder_layers_3_fc2_bias);  dropout_15 = p_model_model_encoder_layers_3_fc2_weight = p_model_model_encoder_layers_3_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:315 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_16: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_23, 0.1, False);  linear_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:316 in forward, code: hidden_states = residual + hidden_states
        add_13: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_6, dropout_16);  layer_norm_6 = dropout_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:317 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_7: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_13, [512], p_model_model_encoder_layers_3_final_layer_norm_weight, p_model_model_encoder_layers_3_final_layer_norm_bias);  add_13 = p_model_model_encoder_layers_3_final_layer_norm_weight = p_model_model_encoder_layers_3_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_24: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_7, p_model_model_encoder_layers_4_self_attn_q_proj_weight, p_model_model_encoder_layers_4_self_attn_q_proj_bias);  p_model_model_encoder_layers_4_self_attn_q_proj_weight = p_model_model_encoder_layers_4_self_attn_q_proj_bias = None
        mul_8: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(linear_24, 0.125);  linear_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_13: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(mul_8, [1, 23, 8, 64]);  mul_8 = None
        transpose_20: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_13, 1, 2);  view_13 = None
        contiguous_12: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_20);  transpose_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_25: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_7, p_model_model_encoder_layers_4_self_attn_k_proj_weight, p_model_model_encoder_layers_4_self_attn_k_proj_bias);  p_model_model_encoder_layers_4_self_attn_k_proj_weight = p_model_model_encoder_layers_4_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_14: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_25, [1, -1, 8, 64]);  linear_25 = None
        transpose_21: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_14, 1, 2);  view_14 = None
        contiguous_13: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_21);  transpose_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_26: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_7, p_model_model_encoder_layers_4_self_attn_v_proj_weight, p_model_model_encoder_layers_4_self_attn_v_proj_bias);  p_model_model_encoder_layers_4_self_attn_v_proj_weight = p_model_model_encoder_layers_4_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_15: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_26, [1, -1, 8, 64]);  linear_26 = None
        transpose_22: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_15, 1, 2);  view_15 = None
        contiguous_14: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_22);  transpose_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_23: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(contiguous_13, 2, 3);  contiguous_13 = None
        matmul_8: "f32[1, 8, 23, 23]" = torch.ops.aten.matmul.default(contiguous_12, transpose_23);  contiguous_12 = transpose_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_15: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(masked_fill, 0, 0, 9223372036854775807)
        slice_16: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_15, 1, 0, 9223372036854775807);  slice_15 = None
        slice_17: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_16, 2, 0, 9223372036854775807);  slice_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_14: "f32[1, 8, 23, 23]" = torch.ops.aten.add.Tensor(matmul_8, slice_17);  matmul_8 = slice_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_4: "f32[1, 8, 23, 23]" = torch.ops.aten.softmax.int(add_14, -1);  add_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_17: "f32[1, 8, 23, 23]" = torch.ops.aten.dropout.default(softmax_4, 0.0, False);  softmax_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_9: "f32[1, 8, 23, 64]" = torch.ops.aten.matmul.default(dropout_17, contiguous_14);  dropout_17 = contiguous_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_24: "f32[1, 23, 8, 64]" = torch.ops.aten.transpose.int(matmul_9, 1, 2);  matmul_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_4: "f32[1, 23, 512]" = torch.ops.aten.reshape.default(transpose_24, [1, 23, 512]);  transpose_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_27: "f32[1, 23, 512]" = torch.ops.aten.linear.default(reshape_4, p_model_model_encoder_layers_4_self_attn_out_proj_weight, p_model_model_encoder_layers_4_self_attn_out_proj_bias);  reshape_4 = p_model_model_encoder_layers_4_self_attn_out_proj_weight = p_model_model_encoder_layers_4_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:307 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_18: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_27, 0.1, False);  linear_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:308 in forward, code: hidden_states = residual + hidden_states
        add_15: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_7, dropout_18);  layer_norm_7 = dropout_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:309 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_8: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_15, [512], p_model_model_encoder_layers_4_self_attn_layer_norm_weight, p_model_model_encoder_layers_4_self_attn_layer_norm_bias);  add_15 = p_model_model_encoder_layers_4_self_attn_layer_norm_weight = p_model_model_encoder_layers_4_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:312 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_28: "f32[1, 23, 2048]" = torch.ops.aten.linear.default(layer_norm_8, p_model_model_encoder_layers_4_fc1_weight, p_model_model_encoder_layers_4_fc1_bias);  p_model_model_encoder_layers_4_fc1_weight = p_model_model_encoder_layers_4_fc1_bias = None
        silu_4: "f32[1, 23, 2048]" = torch.ops.aten.silu.default(linear_28);  linear_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:313 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_19: "f32[1, 23, 2048]" = torch.ops.aten.dropout.default(silu_4, 0.0, False);  silu_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:314 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_29: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout_19, p_model_model_encoder_layers_4_fc2_weight, p_model_model_encoder_layers_4_fc2_bias);  dropout_19 = p_model_model_encoder_layers_4_fc2_weight = p_model_model_encoder_layers_4_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:315 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_20: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_29, 0.1, False);  linear_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:316 in forward, code: hidden_states = residual + hidden_states
        add_16: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_8, dropout_20);  layer_norm_8 = dropout_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:317 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_9: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_16, [512], p_model_model_encoder_layers_4_final_layer_norm_weight, p_model_model_encoder_layers_4_final_layer_norm_bias);  add_16 = p_model_model_encoder_layers_4_final_layer_norm_weight = p_model_model_encoder_layers_4_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_30: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_9, p_model_model_encoder_layers_5_self_attn_q_proj_weight, p_model_model_encoder_layers_5_self_attn_q_proj_bias);  p_model_model_encoder_layers_5_self_attn_q_proj_weight = p_model_model_encoder_layers_5_self_attn_q_proj_bias = None
        mul_9: "f32[1, 23, 512]" = torch.ops.aten.mul.Tensor(linear_30, 0.125);  linear_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_16: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(mul_9, [1, 23, 8, 64]);  mul_9 = None
        transpose_25: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_16, 1, 2);  view_16 = None
        contiguous_15: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_25);  transpose_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_31: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_9, p_model_model_encoder_layers_5_self_attn_k_proj_weight, p_model_model_encoder_layers_5_self_attn_k_proj_bias);  p_model_model_encoder_layers_5_self_attn_k_proj_weight = p_model_model_encoder_layers_5_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_17: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_31, [1, -1, 8, 64]);  linear_31 = None
        transpose_26: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_17, 1, 2);  view_17 = None
        contiguous_16: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_26);  transpose_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_32: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_9, p_model_model_encoder_layers_5_self_attn_v_proj_weight, p_model_model_encoder_layers_5_self_attn_v_proj_bias);  p_model_model_encoder_layers_5_self_attn_v_proj_weight = p_model_model_encoder_layers_5_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_18: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_32, [1, -1, 8, 64]);  linear_32 = None
        transpose_27: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_18, 1, 2);  view_18 = None
        contiguous_17: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_27);  transpose_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_28: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(contiguous_16, 2, 3);  contiguous_16 = None
        matmul_10: "f32[1, 8, 23, 23]" = torch.ops.aten.matmul.default(contiguous_15, transpose_28);  contiguous_15 = transpose_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_18: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(masked_fill, 0, 0, 9223372036854775807);  masked_fill = None
        slice_19: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_18, 1, 0, 9223372036854775807);  slice_18 = None
        slice_20: "f32[1, 1, 23, 23]" = torch.ops.aten.slice.Tensor(slice_19, 2, 0, 9223372036854775807);  slice_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_17: "f32[1, 8, 23, 23]" = torch.ops.aten.add.Tensor(matmul_10, slice_20);  matmul_10 = slice_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_5: "f32[1, 8, 23, 23]" = torch.ops.aten.softmax.int(add_17, -1);  add_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_21: "f32[1, 8, 23, 23]" = torch.ops.aten.dropout.default(softmax_5, 0.0, False);  softmax_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_11: "f32[1, 8, 23, 64]" = torch.ops.aten.matmul.default(dropout_21, contiguous_17);  dropout_21 = contiguous_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_29: "f32[1, 23, 8, 64]" = torch.ops.aten.transpose.int(matmul_11, 1, 2);  matmul_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_5: "f32[1, 23, 512]" = torch.ops.aten.reshape.default(transpose_29, [1, 23, 512]);  transpose_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_33: "f32[1, 23, 512]" = torch.ops.aten.linear.default(reshape_5, p_model_model_encoder_layers_5_self_attn_out_proj_weight, p_model_model_encoder_layers_5_self_attn_out_proj_bias);  reshape_5 = p_model_model_encoder_layers_5_self_attn_out_proj_weight = p_model_model_encoder_layers_5_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:307 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_22: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_33, 0.1, False);  linear_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:308 in forward, code: hidden_states = residual + hidden_states
        add_18: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_9, dropout_22);  layer_norm_9 = dropout_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:309 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_10: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_18, [512], p_model_model_encoder_layers_5_self_attn_layer_norm_weight, p_model_model_encoder_layers_5_self_attn_layer_norm_bias);  add_18 = p_model_model_encoder_layers_5_self_attn_layer_norm_weight = p_model_model_encoder_layers_5_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:312 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_34: "f32[1, 23, 2048]" = torch.ops.aten.linear.default(layer_norm_10, p_model_model_encoder_layers_5_fc1_weight, p_model_model_encoder_layers_5_fc1_bias);  p_model_model_encoder_layers_5_fc1_weight = p_model_model_encoder_layers_5_fc1_bias = None
        silu_5: "f32[1, 23, 2048]" = torch.ops.aten.silu.default(linear_34);  linear_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:313 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_23: "f32[1, 23, 2048]" = torch.ops.aten.dropout.default(silu_5, 0.0, False);  silu_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:314 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_35: "f32[1, 23, 512]" = torch.ops.aten.linear.default(dropout_23, p_model_model_encoder_layers_5_fc2_weight, p_model_model_encoder_layers_5_fc2_bias);  dropout_23 = p_model_model_encoder_layers_5_fc2_weight = p_model_model_encoder_layers_5_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:315 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_24: "f32[1, 23, 512]" = torch.ops.aten.dropout.default(linear_35, 0.1, False);  linear_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:316 in forward, code: hidden_states = residual + hidden_states
        add_19: "f32[1, 23, 512]" = torch.ops.aten.add.Tensor(layer_norm_10, dropout_24);  layer_norm_10 = dropout_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:317 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_11: "f32[1, 23, 512]" = torch.ops.aten.layer_norm.default(add_19, [512], p_model_model_encoder_layers_5_final_layer_norm_weight, p_model_model_encoder_layers_5_final_layer_norm_bias);  add_19 = p_model_model_encoder_layers_5_final_layer_norm_weight = p_model_model_encoder_layers_5_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:685 in _prepare_decoder_input_ids_for_generation, code: torch.ones((batch_size, 1), dtype=torch.long, device=device) * decoder_start_token_id
        ones_1: "i64[1, 1]" = torch.ops.aten.ones.default([1, 1], dtype = torch.int64, device = device(type='cpu'), pin_memory = False)
        mul_10: "i64[1, 1]" = torch.ops.aten.mul.Tensor(ones_1, detach__3);  ones_1 = detach__3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1607 in __init__, code: eos_token_id = torch.tensor(eos_token_id, device=device)
        lift_fresh_copy_4: "i64[1]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_4);  c_lifted_tensor_4 = None
        detach__4: "i64[1]" = torch.ops.aten.detach_.default(lift_fresh_copy_4);  lift_fresh_copy_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3231 in _sample, code: unfinished_sequences = torch.ones(batch_size, dtype=torch.long, device=input_ids.device)
        ones_2: "i64[1]" = torch.ops.aten.ones.default([1], dtype = torch.int64, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:1571 in _get_initial_cache_position, code: cache_position = torch.ones_like(input_ids[0, :], dtype=torch.int64).cumsum(0) - 1
        select: "i64[1]" = torch.ops.aten.select.int(mul_10, 0, 0)
        slice_21: "i64[1]" = torch.ops.aten.slice.Tensor(select, 0, 0, 9223372036854775807);  select = None
        ones_like: "i64[1]" = torch.ops.aten.ones_like.default(slice_21, dtype = torch.int64, pin_memory = False);  slice_21 = None
        cumsum: "i64[1]" = torch.ops.aten.cumsum.default(ones_like, 0);  ones_like = None
        sub: "i64[1]" = torch.ops.aten.sub.Tensor(cumsum, 1);  cumsum = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_1: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_2: "f32[20, 64]" = torch.ops.aten.select.int(select_1, 0, 0);  select_1 = None
        any_3: "b8[20]" = torch.ops.aten.any.dim(select_2, -1);  select_2 = None
        sum_1: "i64[]" = torch.ops.aten.sum.default(any_3);  any_3 = sum_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_3: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_4: "f32[20, 64]" = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None
        any_4: "b8[20]" = torch.ops.aten.any.dim(select_4, -1);  select_4 = None
        sum_2: "i64[]" = torch.ops.aten.sum.default(any_4);  any_4 = sum_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_22: "i64[1, 1]" = torch.ops.aten.slice.Tensor(mul_10, 0, 0, 9223372036854775807)
        slice_23: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_22, 1, -1, 9223372036854775807);  slice_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone: "i64[1, 1]" = torch.ops.aten.clone.default(slice_23, memory_format = torch.contiguous_format);  slice_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_19: "i64[1, 1]" = torch.ops.aten.view.default(clone, [-1, 1]);  clone = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_2: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_19, 59513);  view_19 = None
        mul_11: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_2, 22.627416997969522);  embedding_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_3: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(sub, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_24: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_4: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_24, 1);  slice_24 = None
        unsqueeze_5: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_4, 2);  unsqueeze_4 = None
        slice_25: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_5, 3, 0, 9223372036854775807);  unsqueeze_5 = None
        expand_1: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_25, [1, 1, 1, 23]);  slice_25 = None
        to_3: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_1, torch.float32);  expand_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_1: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_3, 1.0);  to_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_4: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_1, torch.bool)
        masked_fill_1: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_1, to_4, -3.4028234663852886e+38);  rsub_1 = to_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_3: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_3);  unsqueeze_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_5: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_3, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_3 = None
        add_20: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_11, to_5);  mul_11 = to_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_25: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_20, 0.1, False);  add_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_5: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_6: "f32[20, 64]" = torch.ops.aten.select.int(select_5, 0, 0);  select_5 = None
        any_5: "b8[20]" = torch.ops.aten.any.dim(select_6, -1);  select_6 = None
        sum_3: "i64[]" = torch.ops.aten.sum.default(any_5);  any_5 = sum_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_1: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_6: "i64[1, 1]" = torch.ops.aten.reshape.default(sub, [-1, 1])
        gt: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_1, reshape_6);  arange_1 = reshape_6 = None
        mul_: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full, gt);  full = gt = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_6: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul_, 0);  mul_ = None
        unsqueeze_7: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_6, 1);  unsqueeze_6 = None
        slice_26: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_7, 2, 0, 9223372036854775807);  unsqueeze_7 = None
        slice_27: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_26, 3, 0, 9223372036854775807);  slice_26 = None
        expand_2: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_27, [1, 1, -1, -1]);  slice_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_36: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_25, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_12: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_36, 0.125);  linear_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_20: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_12, [1, 1, 8, 64]);  mul_12 = None
        transpose_30: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_20, 1, 2);  view_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_37: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_25, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_21: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_37, [1, -1, 8, 64]);  linear_37 = None
        transpose_31: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_21, 1, 2);  view_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_38: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_25, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_22: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_38, [1, -1, 8, 64]);  linear_38 = None
        transpose_32: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_22, 1, 2);  view_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_6: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_31, torch.float32);  transpose_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_7: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_32, torch.float32);  transpose_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_28: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy_: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_28, 2, sub, to_6);  slice_28 = to_6 = index_copy_ = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_29: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__1: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_29, 2, sub, to_7);  slice_29 = to_7 = index_copy__1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_30: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_31: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_30, 2, 0, 9223372036854775807);  slice_30 = None
        slice_32: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_31, 3, 0, 9223372036854775807);  slice_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_33: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_34: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_33, 2, 0, 9223372036854775807);  slice_33 = None
        slice_35: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_34, 3, 0, 9223372036854775807);  slice_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_33: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_32, 2, 3);  slice_32 = None
        matmul_12: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_30, transpose_33);  transpose_30 = transpose_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_36: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_2, 0, 0, 9223372036854775807)
        slice_37: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_36, 1, 0, 9223372036854775807);  slice_36 = None
        slice_38: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_37, 2, 0, 9223372036854775807);  slice_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_21: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_12, slice_38);  matmul_12 = slice_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_6: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_21, -1);  add_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_26: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_6, 0.0, False);  softmax_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_13: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_26, slice_35);  dropout_26 = slice_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_34: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_13, 1, 2);  matmul_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_7: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_34, [1, 1, 512]);  transpose_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_39: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_7, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_27: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_39, 0.1, False);  linear_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_22: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_25, dropout_27);  dropout_25 = dropout_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_12: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_22, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_40: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_12, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_13: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_40, 0.125);  linear_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_23: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_13, [1, 1, 8, 64]);  mul_13 = None
        transpose_35: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_23, 1, 2);  view_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_41: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_0_encoder_attn_k_proj_weight, p_model_model_decoder_layers_0_encoder_attn_k_proj_bias);  p_model_model_decoder_layers_0_encoder_attn_k_proj_weight = p_model_model_decoder_layers_0_encoder_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_24: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_41, [1, -1, 8, 64]);  linear_41 = None
        transpose_36: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_24, 1, 2);  view_24 = None
        contiguous_18: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_36);  transpose_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_42: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_0_encoder_attn_v_proj_weight, p_model_model_decoder_layers_0_encoder_attn_v_proj_bias);  p_model_model_decoder_layers_0_encoder_attn_v_proj_weight = p_model_model_decoder_layers_0_encoder_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_25: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_42, [1, -1, 8, 64]);  linear_42 = None
        transpose_37: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_25, 1, 2);  view_25 = None
        contiguous_19: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_37);  transpose_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:208 in forward, code: cache_position = torch.arange(
        arange_2: "i64[23]" = torch.ops.aten.arange.start(0, 23, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_8: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_18, torch.float32);  contiguous_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_9: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_19, torch.float32);  contiguous_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_39: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__2: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_39, 2, arange_2, to_8);  slice_39 = to_8 = index_copy__2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_40: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__3: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_40, 2, arange_2, to_9);  slice_40 = arange_2 = to_9 = index_copy__3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:217 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_41: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_42: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_41, 2, 0, 23);  slice_41 = None
        slice_43: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_42, 3, 0, 9223372036854775807);  slice_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:218 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_44: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_45: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_44, 2, 0, 23);  slice_44 = None
        slice_46: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_45, 3, 0, 9223372036854775807);  slice_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_38: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_43, 2, 3);  slice_43 = None
        matmul_14: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_35, transpose_38);  transpose_35 = transpose_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_47: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_1, 0, 0, 9223372036854775807)
        slice_48: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_47, 1, 0, 9223372036854775807);  slice_47 = None
        slice_49: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_48, 2, 0, 9223372036854775807);  slice_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_23: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_14, slice_49);  matmul_14 = slice_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_7: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_23, -1);  add_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_28: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_7, 0.0, False);  softmax_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_15: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_28, slice_46);  dropout_28 = slice_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_39: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_15, 1, 2);  matmul_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_8: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_39, [1, 1, 512]);  transpose_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_43: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_8, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_29: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_43, 0.1, False);  linear_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_24: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_12, dropout_29);  layer_norm_12 = dropout_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_13: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_24, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_44: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_13, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_6: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_44);  linear_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_30: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_6, 0.0, False);  silu_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_45: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_30, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_31: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_45, 0.1, False);  linear_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_25: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_13, dropout_31);  layer_norm_13 = dropout_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_14: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_25, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_46: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_14, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_14: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_46, 0.125);  linear_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_26: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_14, [1, 1, 8, 64]);  mul_14 = None
        transpose_40: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_26, 1, 2);  view_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_47: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_14, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_27: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_47, [1, -1, 8, 64]);  linear_47 = None
        transpose_41: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_27, 1, 2);  view_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_48: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_14, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_28: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_48, [1, -1, 8, 64]);  linear_48 = None
        transpose_42: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_28, 1, 2);  view_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_10: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_41, torch.float32);  transpose_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_11: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_42, torch.float32);  transpose_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_50: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__4: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_50, 2, sub, to_10);  slice_50 = to_10 = index_copy__4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_51: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__5: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_51, 2, sub, to_11);  slice_51 = to_11 = index_copy__5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_52: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_53: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_52, 2, 0, 9223372036854775807);  slice_52 = None
        slice_54: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_53, 3, 0, 9223372036854775807);  slice_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_55: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_56: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_55, 2, 0, 9223372036854775807);  slice_55 = None
        slice_57: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_56, 3, 0, 9223372036854775807);  slice_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_43: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_54, 2, 3);  slice_54 = None
        matmul_16: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_40, transpose_43);  transpose_40 = transpose_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_58: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_2, 0, 0, 9223372036854775807)
        slice_59: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_58, 1, 0, 9223372036854775807);  slice_58 = None
        slice_60: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_59, 2, 0, 9223372036854775807);  slice_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_26: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_16, slice_60);  matmul_16 = slice_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_8: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_26, -1);  add_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_32: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_8, 0.0, False);  softmax_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_17: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_32, slice_57);  dropout_32 = slice_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_44: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_17, 1, 2);  matmul_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_9: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_44, [1, 1, 512]);  transpose_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_49: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_9, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_33: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_49, 0.1, False);  linear_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_27: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_14, dropout_33);  layer_norm_14 = dropout_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_15: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_27, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_50: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_15, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_15: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_50, 0.125);  linear_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_29: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_15, [1, 1, 8, 64]);  mul_15 = None
        transpose_45: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_29, 1, 2);  view_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_51: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_1_encoder_attn_k_proj_weight, p_model_model_decoder_layers_1_encoder_attn_k_proj_bias);  p_model_model_decoder_layers_1_encoder_attn_k_proj_weight = p_model_model_decoder_layers_1_encoder_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_30: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_51, [1, -1, 8, 64]);  linear_51 = None
        transpose_46: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_30, 1, 2);  view_30 = None
        contiguous_20: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_46);  transpose_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_52: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_1_encoder_attn_v_proj_weight, p_model_model_decoder_layers_1_encoder_attn_v_proj_bias);  p_model_model_decoder_layers_1_encoder_attn_v_proj_weight = p_model_model_decoder_layers_1_encoder_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_31: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_52, [1, -1, 8, 64]);  linear_52 = None
        transpose_47: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_31, 1, 2);  view_31 = None
        contiguous_21: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_47);  transpose_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:208 in forward, code: cache_position = torch.arange(
        arange_3: "i64[23]" = torch.ops.aten.arange.start(0, 23, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_12: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_20, torch.float32);  contiguous_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_13: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_21, torch.float32);  contiguous_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_61: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__6: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_61, 2, arange_3, to_12);  slice_61 = to_12 = index_copy__6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_62: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__7: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_62, 2, arange_3, to_13);  slice_62 = arange_3 = to_13 = index_copy__7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:217 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_63: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_64: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_63, 2, 0, 23);  slice_63 = None
        slice_65: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_64, 3, 0, 9223372036854775807);  slice_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:218 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_66: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_67: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_66, 2, 0, 23);  slice_66 = None
        slice_68: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_67, 3, 0, 9223372036854775807);  slice_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_48: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_65, 2, 3);  slice_65 = None
        matmul_18: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_45, transpose_48);  transpose_45 = transpose_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_69: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_1, 0, 0, 9223372036854775807)
        slice_70: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_69, 1, 0, 9223372036854775807);  slice_69 = None
        slice_71: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_70, 2, 0, 9223372036854775807);  slice_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_28: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_18, slice_71);  matmul_18 = slice_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_9: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_28, -1);  add_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_34: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_9, 0.0, False);  softmax_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_19: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_34, slice_68);  dropout_34 = slice_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_49: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_19, 1, 2);  matmul_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_10: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_49, [1, 1, 512]);  transpose_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_53: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_10, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_35: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_53, 0.1, False);  linear_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_29: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_15, dropout_35);  layer_norm_15 = dropout_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_16: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_29, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_54: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_16, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_7: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_54);  linear_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_36: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_7, 0.0, False);  silu_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_55: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_36, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_37: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_55, 0.1, False);  linear_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_30: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_16, dropout_37);  layer_norm_16 = dropout_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_17: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_30, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_56: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_17, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_16: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_56, 0.125);  linear_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_32: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_16, [1, 1, 8, 64]);  mul_16 = None
        transpose_50: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_32, 1, 2);  view_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_57: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_17, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_33: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_57, [1, -1, 8, 64]);  linear_57 = None
        transpose_51: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_33, 1, 2);  view_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_58: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_17, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_34: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_58, [1, -1, 8, 64]);  linear_58 = None
        transpose_52: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_34, 1, 2);  view_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_14: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_51, torch.float32);  transpose_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_15: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_52, torch.float32);  transpose_52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_72: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__8: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_72, 2, sub, to_14);  slice_72 = to_14 = index_copy__8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_73: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__9: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_73, 2, sub, to_15);  slice_73 = to_15 = index_copy__9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_74: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_75: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_74, 2, 0, 9223372036854775807);  slice_74 = None
        slice_76: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_75, 3, 0, 9223372036854775807);  slice_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_77: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_78: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_77, 2, 0, 9223372036854775807);  slice_77 = None
        slice_79: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_78, 3, 0, 9223372036854775807);  slice_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_53: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_76, 2, 3);  slice_76 = None
        matmul_20: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_50, transpose_53);  transpose_50 = transpose_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_80: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_2, 0, 0, 9223372036854775807)
        slice_81: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_80, 1, 0, 9223372036854775807);  slice_80 = None
        slice_82: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_81, 2, 0, 9223372036854775807);  slice_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_31: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_20, slice_82);  matmul_20 = slice_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_10: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_31, -1);  add_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_38: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_10, 0.0, False);  softmax_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_21: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_38, slice_79);  dropout_38 = slice_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_54: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_21, 1, 2);  matmul_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_11: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_54, [1, 1, 512]);  transpose_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_59: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_11, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_39: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_59, 0.1, False);  linear_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_32: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_17, dropout_39);  layer_norm_17 = dropout_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_18: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_32, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_60: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_18, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_17: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_60, 0.125);  linear_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_35: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_17, [1, 1, 8, 64]);  mul_17 = None
        transpose_55: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_35, 1, 2);  view_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_61: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_2_encoder_attn_k_proj_weight, p_model_model_decoder_layers_2_encoder_attn_k_proj_bias);  p_model_model_decoder_layers_2_encoder_attn_k_proj_weight = p_model_model_decoder_layers_2_encoder_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_36: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_61, [1, -1, 8, 64]);  linear_61 = None
        transpose_56: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_36, 1, 2);  view_36 = None
        contiguous_22: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_56);  transpose_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_62: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_2_encoder_attn_v_proj_weight, p_model_model_decoder_layers_2_encoder_attn_v_proj_bias);  p_model_model_decoder_layers_2_encoder_attn_v_proj_weight = p_model_model_decoder_layers_2_encoder_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_37: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_62, [1, -1, 8, 64]);  linear_62 = None
        transpose_57: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_37, 1, 2);  view_37 = None
        contiguous_23: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_57);  transpose_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:208 in forward, code: cache_position = torch.arange(
        arange_4: "i64[23]" = torch.ops.aten.arange.start(0, 23, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_16: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_22, torch.float32);  contiguous_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_17: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_23, torch.float32);  contiguous_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_83: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__10: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_83, 2, arange_4, to_16);  slice_83 = to_16 = index_copy__10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_84: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__11: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_84, 2, arange_4, to_17);  slice_84 = arange_4 = to_17 = index_copy__11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:217 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_85: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_86: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_85, 2, 0, 23);  slice_85 = None
        slice_87: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_86, 3, 0, 9223372036854775807);  slice_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:218 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_88: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_89: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_88, 2, 0, 23);  slice_88 = None
        slice_90: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_89, 3, 0, 9223372036854775807);  slice_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_58: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_87, 2, 3);  slice_87 = None
        matmul_22: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_55, transpose_58);  transpose_55 = transpose_58 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_91: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_1, 0, 0, 9223372036854775807)
        slice_92: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_91, 1, 0, 9223372036854775807);  slice_91 = None
        slice_93: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_92, 2, 0, 9223372036854775807);  slice_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_33: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_22, slice_93);  matmul_22 = slice_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_11: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_33, -1);  add_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_40: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_11, 0.0, False);  softmax_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_23: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_40, slice_90);  dropout_40 = slice_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_59: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_23, 1, 2);  matmul_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_12: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_59, [1, 1, 512]);  transpose_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_63: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_12, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_41: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_63, 0.1, False);  linear_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_34: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_18, dropout_41);  layer_norm_18 = dropout_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_19: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_34, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_64: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_19, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_8: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_64);  linear_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_42: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_8, 0.0, False);  silu_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_65: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_42, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_43: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_65, 0.1, False);  linear_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_35: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_19, dropout_43);  layer_norm_19 = dropout_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_20: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_35, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_66: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_20, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_18: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_66, 0.125);  linear_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_38: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_18, [1, 1, 8, 64]);  mul_18 = None
        transpose_60: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_38, 1, 2);  view_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_67: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_20, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_39: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_67, [1, -1, 8, 64]);  linear_67 = None
        transpose_61: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_39, 1, 2);  view_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_68: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_20, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_40: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_68, [1, -1, 8, 64]);  linear_68 = None
        transpose_62: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_40, 1, 2);  view_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_18: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_61, torch.float32);  transpose_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_19: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_62, torch.float32);  transpose_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_94: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__12: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_94, 2, sub, to_18);  slice_94 = to_18 = index_copy__12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_95: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__13: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_95, 2, sub, to_19);  slice_95 = to_19 = index_copy__13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_96: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_97: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_96, 2, 0, 9223372036854775807);  slice_96 = None
        slice_98: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_97, 3, 0, 9223372036854775807);  slice_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_99: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_100: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_99, 2, 0, 9223372036854775807);  slice_99 = None
        slice_101: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_100, 3, 0, 9223372036854775807);  slice_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_63: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_98, 2, 3);  slice_98 = None
        matmul_24: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_60, transpose_63);  transpose_60 = transpose_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_102: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_2, 0, 0, 9223372036854775807)
        slice_103: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_102, 1, 0, 9223372036854775807);  slice_102 = None
        slice_104: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_103, 2, 0, 9223372036854775807);  slice_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_36: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_24, slice_104);  matmul_24 = slice_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_12: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_36, -1);  add_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_44: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_12, 0.0, False);  softmax_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_25: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_44, slice_101);  dropout_44 = slice_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_64: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_25, 1, 2);  matmul_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_13: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_64, [1, 1, 512]);  transpose_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_69: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_13, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_45: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_69, 0.1, False);  linear_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_37: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_20, dropout_45);  layer_norm_20 = dropout_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_21: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_37, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_70: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_21, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_19: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_70, 0.125);  linear_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_41: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_19, [1, 1, 8, 64]);  mul_19 = None
        transpose_65: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_41, 1, 2);  view_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_71: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_3_encoder_attn_k_proj_weight, p_model_model_decoder_layers_3_encoder_attn_k_proj_bias);  p_model_model_decoder_layers_3_encoder_attn_k_proj_weight = p_model_model_decoder_layers_3_encoder_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_42: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_71, [1, -1, 8, 64]);  linear_71 = None
        transpose_66: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_42, 1, 2);  view_42 = None
        contiguous_24: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_66);  transpose_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_72: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_3_encoder_attn_v_proj_weight, p_model_model_decoder_layers_3_encoder_attn_v_proj_bias);  p_model_model_decoder_layers_3_encoder_attn_v_proj_weight = p_model_model_decoder_layers_3_encoder_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_43: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_72, [1, -1, 8, 64]);  linear_72 = None
        transpose_67: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_43, 1, 2);  view_43 = None
        contiguous_25: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_67);  transpose_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:208 in forward, code: cache_position = torch.arange(
        arange_5: "i64[23]" = torch.ops.aten.arange.start(0, 23, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_20: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_24, torch.float32);  contiguous_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_21: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_25, torch.float32);  contiguous_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_105: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__14: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_105, 2, arange_5, to_20);  slice_105 = to_20 = index_copy__14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_106: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__15: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_106, 2, arange_5, to_21);  slice_106 = arange_5 = to_21 = index_copy__15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:217 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_107: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_108: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_107, 2, 0, 23);  slice_107 = None
        slice_109: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_108, 3, 0, 9223372036854775807);  slice_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:218 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_110: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_111: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_110, 2, 0, 23);  slice_110 = None
        slice_112: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_111, 3, 0, 9223372036854775807);  slice_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_68: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_109, 2, 3);  slice_109 = None
        matmul_26: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_65, transpose_68);  transpose_65 = transpose_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_113: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_1, 0, 0, 9223372036854775807)
        slice_114: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_113, 1, 0, 9223372036854775807);  slice_113 = None
        slice_115: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_114, 2, 0, 9223372036854775807);  slice_114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_38: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_26, slice_115);  matmul_26 = slice_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_13: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_38, -1);  add_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_46: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_13, 0.0, False);  softmax_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_27: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_46, slice_112);  dropout_46 = slice_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_69: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_27, 1, 2);  matmul_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_14: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_69, [1, 1, 512]);  transpose_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_73: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_14, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_47: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_73, 0.1, False);  linear_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_39: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_21, dropout_47);  layer_norm_21 = dropout_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_22: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_39, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_74: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_22, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_9: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_74);  linear_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_48: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_9, 0.0, False);  silu_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_75: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_48, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_49: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_75, 0.1, False);  linear_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_40: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_22, dropout_49);  layer_norm_22 = dropout_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_23: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_40, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_76: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_23, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_20: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_76, 0.125);  linear_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_44: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_20, [1, 1, 8, 64]);  mul_20 = None
        transpose_70: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_44, 1, 2);  view_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_77: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_23, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_45: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_77, [1, -1, 8, 64]);  linear_77 = None
        transpose_71: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_45, 1, 2);  view_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_78: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_23, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_46: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_78, [1, -1, 8, 64]);  linear_78 = None
        transpose_72: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_46, 1, 2);  view_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_22: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_71, torch.float32);  transpose_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_23: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_72, torch.float32);  transpose_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_116: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__16: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_116, 2, sub, to_22);  slice_116 = to_22 = index_copy__16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_117: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__17: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_117, 2, sub, to_23);  slice_117 = to_23 = index_copy__17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_118: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_119: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_118, 2, 0, 9223372036854775807);  slice_118 = None
        slice_120: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_119, 3, 0, 9223372036854775807);  slice_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_121: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_122: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_121, 2, 0, 9223372036854775807);  slice_121 = None
        slice_123: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_122, 3, 0, 9223372036854775807);  slice_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_73: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_120, 2, 3);  slice_120 = None
        matmul_28: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_70, transpose_73);  transpose_70 = transpose_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_124: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_2, 0, 0, 9223372036854775807)
        slice_125: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_124, 1, 0, 9223372036854775807);  slice_124 = None
        slice_126: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_125, 2, 0, 9223372036854775807);  slice_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_41: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_28, slice_126);  matmul_28 = slice_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_14: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_41, -1);  add_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_50: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_14, 0.0, False);  softmax_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_29: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_50, slice_123);  dropout_50 = slice_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_74: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_29, 1, 2);  matmul_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_15: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_74, [1, 1, 512]);  transpose_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_79: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_15, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_51: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_79, 0.1, False);  linear_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_42: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_23, dropout_51);  layer_norm_23 = dropout_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_24: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_42, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_80: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_24, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_21: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_80, 0.125);  linear_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_47: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_21, [1, 1, 8, 64]);  mul_21 = None
        transpose_75: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_47, 1, 2);  view_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_81: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_4_encoder_attn_k_proj_weight, p_model_model_decoder_layers_4_encoder_attn_k_proj_bias);  p_model_model_decoder_layers_4_encoder_attn_k_proj_weight = p_model_model_decoder_layers_4_encoder_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_48: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_81, [1, -1, 8, 64]);  linear_81 = None
        transpose_76: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_48, 1, 2);  view_48 = None
        contiguous_26: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_76);  transpose_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_82: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_4_encoder_attn_v_proj_weight, p_model_model_decoder_layers_4_encoder_attn_v_proj_bias);  p_model_model_decoder_layers_4_encoder_attn_v_proj_weight = p_model_model_decoder_layers_4_encoder_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_49: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_82, [1, -1, 8, 64]);  linear_82 = None
        transpose_77: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_49, 1, 2);  view_49 = None
        contiguous_27: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_77);  transpose_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:208 in forward, code: cache_position = torch.arange(
        arange_6: "i64[23]" = torch.ops.aten.arange.start(0, 23, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_24: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_26, torch.float32);  contiguous_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_25: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_27, torch.float32);  contiguous_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_127: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__18: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_127, 2, arange_6, to_24);  slice_127 = to_24 = index_copy__18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_128: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__19: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_128, 2, arange_6, to_25);  slice_128 = arange_6 = to_25 = index_copy__19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:217 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_129: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_130: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_129, 2, 0, 23);  slice_129 = None
        slice_131: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_130, 3, 0, 9223372036854775807);  slice_130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:218 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_132: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_133: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_132, 2, 0, 23);  slice_132 = None
        slice_134: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_133, 3, 0, 9223372036854775807);  slice_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_78: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_131, 2, 3);  slice_131 = None
        matmul_30: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_75, transpose_78);  transpose_75 = transpose_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_135: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_1, 0, 0, 9223372036854775807)
        slice_136: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_135, 1, 0, 9223372036854775807);  slice_135 = None
        slice_137: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_136, 2, 0, 9223372036854775807);  slice_136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_43: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_30, slice_137);  matmul_30 = slice_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_15: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_43, -1);  add_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_52: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_15, 0.0, False);  softmax_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_31: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_52, slice_134);  dropout_52 = slice_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_79: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_31, 1, 2);  matmul_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_16: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_79, [1, 1, 512]);  transpose_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_83: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_16, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_53: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_83, 0.1, False);  linear_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_44: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_24, dropout_53);  layer_norm_24 = dropout_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_25: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_44, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_84: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_25, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_10: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_84);  linear_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_54: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_10, 0.0, False);  silu_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_85: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_54, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_55: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_85, 0.1, False);  linear_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_45: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_25, dropout_55);  layer_norm_25 = dropout_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_26: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_45, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_86: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_26, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_22: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_86, 0.125);  linear_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_50: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_22, [1, 1, 8, 64]);  mul_22 = None
        transpose_80: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_50, 1, 2);  view_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_87: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_26, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_51: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_87, [1, -1, 8, 64]);  linear_87 = None
        transpose_81: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_51, 1, 2);  view_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_88: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_26, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_52: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_88, [1, -1, 8, 64]);  linear_88 = None
        transpose_82: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_52, 1, 2);  view_52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_26: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_81, torch.float32);  transpose_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_27: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_82, torch.float32);  transpose_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_138: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__20: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_138, 2, sub, to_26);  slice_138 = to_26 = index_copy__20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_139: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__21: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_139, 2, sub, to_27);  slice_139 = to_27 = index_copy__21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_140: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_141: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_140, 2, 0, 9223372036854775807);  slice_140 = None
        slice_142: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_141, 3, 0, 9223372036854775807);  slice_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_143: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_144: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_143, 2, 0, 9223372036854775807);  slice_143 = None
        slice_145: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_144, 3, 0, 9223372036854775807);  slice_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_83: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_142, 2, 3);  slice_142 = None
        matmul_32: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_80, transpose_83);  transpose_80 = transpose_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_146: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_2, 0, 0, 9223372036854775807);  expand_2 = None
        slice_147: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_146, 1, 0, 9223372036854775807);  slice_146 = None
        slice_148: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_147, 2, 0, 9223372036854775807);  slice_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_46: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_32, slice_148);  matmul_32 = slice_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_16: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_46, -1);  add_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_56: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_16, 0.0, False);  softmax_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_33: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_56, slice_145);  dropout_56 = slice_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_84: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_33, 1, 2);  matmul_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_17: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_84, [1, 1, 512]);  transpose_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_89: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_17, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_57: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_89, 0.1, False);  linear_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_47: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_26, dropout_57);  layer_norm_26 = dropout_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_27: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_47, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_90: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_27, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_23: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_90, 0.125);  linear_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_53: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_23, [1, 1, 8, 64]);  mul_23 = None
        transpose_85: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_53, 1, 2);  view_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_91: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_5_encoder_attn_k_proj_weight, p_model_model_decoder_layers_5_encoder_attn_k_proj_bias);  p_model_model_decoder_layers_5_encoder_attn_k_proj_weight = p_model_model_decoder_layers_5_encoder_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_54: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_91, [1, -1, 8, 64]);  linear_91 = None
        transpose_86: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_54, 1, 2);  view_54 = None
        contiguous_28: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_86);  transpose_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_92: "f32[1, 23, 512]" = torch.ops.aten.linear.default(layer_norm_11, p_model_model_decoder_layers_5_encoder_attn_v_proj_weight, p_model_model_decoder_layers_5_encoder_attn_v_proj_bias);  layer_norm_11 = p_model_model_decoder_layers_5_encoder_attn_v_proj_weight = p_model_model_decoder_layers_5_encoder_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_55: "f32[1, 23, 8, 64]" = torch.ops.aten.view.default(linear_92, [1, -1, 8, 64]);  linear_92 = None
        transpose_87: "f32[1, 8, 23, 64]" = torch.ops.aten.transpose.int(view_55, 1, 2);  view_55 = None
        contiguous_29: "f32[1, 8, 23, 64]" = torch.ops.aten.contiguous.default(transpose_87);  transpose_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:208 in forward, code: cache_position = torch.arange(
        arange_7: "i64[23]" = torch.ops.aten.arange.start(0, 23, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_28: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_28, torch.float32);  contiguous_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_29: "f32[1, 8, 23, 64]" = torch.ops.aten.to.dtype(contiguous_29, torch.float32);  contiguous_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_149: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__22: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_149, 2, arange_7, to_28);  slice_149 = to_28 = index_copy__22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_150: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__23: "f32[1, 8, 40, 64]" = torch.ops.aten.index_copy_.default(slice_150, 2, arange_7, to_29);  slice_150 = arange_7 = to_29 = index_copy__23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:217 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_151: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_152: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_151, 2, 0, 23);  slice_151 = None
        slice_153: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_152, 3, 0, 9223372036854775807);  slice_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:218 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_154: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_155: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_154, 2, 0, 23);  slice_154 = None
        slice_156: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_155, 3, 0, 9223372036854775807);  slice_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_88: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_153, 2, 3);  slice_153 = None
        matmul_34: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_85, transpose_88);  transpose_85 = transpose_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_157: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_1, 0, 0, 9223372036854775807);  masked_fill_1 = None
        slice_158: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_157, 1, 0, 9223372036854775807);  slice_157 = None
        slice_159: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_158, 2, 0, 9223372036854775807);  slice_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_48: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_34, slice_159);  matmul_34 = slice_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_17: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_48, -1);  add_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_58: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_17, 0.0, False);  softmax_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_35: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_58, slice_156);  dropout_58 = slice_156 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_89: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_35, 1, 2);  matmul_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_18: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_89, [1, 1, 512]);  transpose_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_93: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_18, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_59: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_93, 0.1, False);  linear_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_49: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_27, dropout_59);  layer_norm_27 = dropout_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_28: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_49, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_94: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_28, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_11: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_94);  linear_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_60: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_11, 0.0, False);  silu_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_95: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_60, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_61: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_95, 0.1, False);  linear_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_50: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_28, dropout_61);  layer_norm_28 = dropout_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_29: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_50, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_96: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_29, p_model_lm_head_weight);  layer_norm_29 = None
        add_51: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_96, b_model_final_logits_bias);  linear_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_160: "i64[1]" = torch.ops.aten.slice.Tensor(sub, 0, -1, 9223372036854775807);  sub = None
        add_52: "i64[1]" = torch.ops.aten.add.Tensor(slice_160, 1);  slice_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_161: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_51, 0, 0, 9223372036854775807);  add_51 = None
        select_7: "f32[1, 59514]" = torch.ops.aten.select.int(slice_161, 1, -1);  slice_161 = None
        slice_162: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_7, 1, 0, 9223372036854775807);  select_7 = None
        clone_1: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_162);  slice_162 = None
        to_30: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_1, torch.float32);  clone_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_31: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_30, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1175 in _prepare_bias_variables, code: self.length_1_bias = torch.zeros((vocabulary_size,), dtype=torch.float).to(scores.device)
        zeros: "f32[59514]" = torch.ops.aten.zeros.default([59514], dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        to_32: "f32[59514]" = torch.ops.aten.to.dtype_layout(zeros, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  zeros = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1178 in _prepare_bias_variables, code: self.length_1_bias[sequence_ids[-1]] = bias
        lift_fresh_copy_5: "f32[]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_5);  c_lifted_tensor_5 = None
        select_8: "f32[]" = torch.ops.aten.select.int(to_32, 0, 59513)
        copy_: "f32[]" = torch.ops.aten.copy_.default(select_8, lift_fresh_copy_5);  select_8 = lift_fresh_copy_5 = copy_ = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_31, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add_: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like, to_32);  zeros_like = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_53: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_31, add_);  to_31 = add_ = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_53, -1);  add_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax: "i64[1]" = torch.ops.aten.argmax.default(log_softmax, -1);  log_softmax = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_24: "i64[1]" = torch.ops.aten.mul.Tensor(argmax, ones_2);  argmax = None
        rsub_2: "i64[1]" = torch.ops.aten.rsub.Scalar(ones_2, 1)
        mul_25: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_2);  rsub_2 = None
        add_54: "i64[1]" = torch.ops.aten.add.Tensor(mul_24, mul_25);  mul_24 = mul_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_163: "i64[1]" = torch.ops.aten.slice.Tensor(add_54, 0, 0, 9223372036854775807);  add_54 = None
        unsqueeze_8: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_163, 1);  slice_163 = None
        cat: "i64[1, 2]" = torch.ops.aten.cat.default([mul_10, unsqueeze_8], -1);  mul_10 = unsqueeze_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_1: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_2: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_1: "b8[1]" = torch.ops.aten.__or__.Tensor(full_1, full_2);  full_1 = full_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_33: "i64[1]" = torch.ops.aten.to.dtype_layout(unsqueeze, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  unsqueeze = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_164: "i64[1, 2]" = torch.ops.aten.slice.Tensor(cat, 0, 0, 9223372036854775807)
        select_9: "i64[1]" = torch.ops.aten.select.int(slice_164, 1, -1);  slice_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_2: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_9, to_33);  select_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_2: "b8[1]" = torch.ops.aten.__or__.Tensor(or_1, isin_2);  or_1 = isin_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_2: "b8[1]" = torch.ops.aten.bitwise_not.default(or_2);  or_2 = None
        and_1: "i64[1]" = torch.ops.aten.__and__.Tensor(ones_2, bitwise_not_2);  ones_2 = bitwise_not_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_1: "i64[]" = torch.ops.aten.max.default(and_1)
        eq: "b8[]" = torch.ops.aten.eq.Scalar(max_1, 0);  max_1 = eq = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_165: "i64[1, 2]" = torch.ops.aten.slice.Tensor(cat, 0, 0, 9223372036854775807)
        slice_166: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_165, 1, -1, 9223372036854775807);  slice_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_2: "i64[1, 1]" = torch.ops.aten.clone.default(slice_166, memory_format = torch.contiguous_format);  slice_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_56: "i64[1, 1]" = torch.ops.aten.view.default(clone_2, [-1, 1]);  clone_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_4: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_56, 59513);  view_56 = None
        mul_26: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_4, 22.627416997969522);  embedding_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_9: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_52, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_167: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_10: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_167, 1);  slice_167 = None
        unsqueeze_11: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_10, 2);  unsqueeze_10 = None
        slice_168: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_11, 3, 0, 9223372036854775807);  unsqueeze_11 = None
        expand_3: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_168, [1, 1, 1, 23]);  slice_168 = None
        to_34: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_3, torch.float32);  expand_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_3: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_34, 1.0);  to_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_35: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_3, torch.bool)
        masked_fill_2: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_3, to_35, -3.4028234663852886e+38);  rsub_3 = to_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_5: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_9);  unsqueeze_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_36: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_5, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_5 = None
        add_55: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_26, to_36);  mul_26 = to_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_62: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_55, 0.1, False);  add_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_10: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_11: "f32[20, 64]" = torch.ops.aten.select.int(select_10, 0, 0);  select_10 = None
        any_6: "b8[20]" = torch.ops.aten.any.dim(select_11, -1);  select_11 = None
        sum_4: "i64[]" = torch.ops.aten.sum.default(any_6);  any_6 = sum_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_3: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_8: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_19: "i64[1, 1]" = torch.ops.aten.reshape.default(add_52, [-1, 1])
        gt_1: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_8, reshape_19);  arange_8 = reshape_19 = None
        mul__1: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_3, gt_1);  full_3 = gt_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_12: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__1, 0);  mul__1 = None
        unsqueeze_13: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_12, 1);  unsqueeze_12 = None
        slice_169: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_13, 2, 0, 9223372036854775807);  unsqueeze_13 = None
        slice_170: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_169, 3, 0, 9223372036854775807);  slice_169 = None
        expand_4: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_170, [1, 1, -1, -1]);  slice_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_97: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_62, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_27: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_97, 0.125);  linear_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_57: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_27, [1, 1, 8, 64]);  mul_27 = None
        transpose_90: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_57, 1, 2);  view_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_98: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_62, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_58: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_98, [1, -1, 8, 64]);  linear_98 = None
        transpose_91: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_58, 1, 2);  view_58 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_99: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_62, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_59: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_99, [1, -1, 8, 64]);  linear_99 = None
        transpose_92: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_59, 1, 2);  view_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_37: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_91, torch.float32);  transpose_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_38: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_92, torch.float32);  transpose_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_171: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__24: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_171, 2, add_52, to_37);  slice_171 = to_37 = index_copy__24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_172: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__25: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_172, 2, add_52, to_38);  slice_172 = to_38 = index_copy__25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_173: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_174: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_173, 2, 0, 9223372036854775807);  slice_173 = None
        slice_175: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_174, 3, 0, 9223372036854775807);  slice_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_176: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_177: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_176, 2, 0, 9223372036854775807);  slice_176 = None
        slice_178: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_177, 3, 0, 9223372036854775807);  slice_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_93: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_175, 2, 3);  slice_175 = None
        matmul_36: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_90, transpose_93);  transpose_90 = transpose_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_179: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_4, 0, 0, 9223372036854775807)
        slice_180: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_179, 1, 0, 9223372036854775807);  slice_179 = None
        slice_181: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_180, 2, 0, 9223372036854775807);  slice_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_56: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_36, slice_181);  matmul_36 = slice_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_18: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_56, -1);  add_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_63: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_18, 0.0, False);  softmax_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_37: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_63, slice_178);  dropout_63 = slice_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_94: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_37, 1, 2);  matmul_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_20: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_94, [1, 1, 512]);  transpose_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_100: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_20, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_64: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_100, 0.1, False);  linear_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_57: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_62, dropout_64);  dropout_62 = dropout_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_30: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_57, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_101: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_30, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_28: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_101, 0.125);  linear_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_60: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_28, [1, 1, 8, 64]);  mul_28 = None
        transpose_95: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_60, 1, 2);  view_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_182: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_183: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_182, 2, 0, 23);  slice_182 = None
        slice_184: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_183, 3, 0, 9223372036854775807);  slice_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_185: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_186: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_185, 2, 0, 23);  slice_185 = None
        slice_187: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_186, 3, 0, 9223372036854775807);  slice_186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_96: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_184, 2, 3);  slice_184 = None
        matmul_38: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_95, transpose_96);  transpose_95 = transpose_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_188: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_2, 0, 0, 9223372036854775807)
        slice_189: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_188, 1, 0, 9223372036854775807);  slice_188 = None
        slice_190: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_189, 2, 0, 9223372036854775807);  slice_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_58: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_38, slice_190);  matmul_38 = slice_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_19: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_58, -1);  add_58 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_65: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_19, 0.0, False);  softmax_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_39: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_65, slice_187);  dropout_65 = slice_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_97: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_39, 1, 2);  matmul_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_21: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_97, [1, 1, 512]);  transpose_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_102: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_21, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_66: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_102, 0.1, False);  linear_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_59: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_30, dropout_66);  layer_norm_30 = dropout_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_31: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_59, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_103: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_31, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_12: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_103);  linear_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_67: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_12, 0.0, False);  silu_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_104: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_67, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_68: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_104, 0.1, False);  linear_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_60: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_31, dropout_68);  layer_norm_31 = dropout_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_32: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_60, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_105: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_32, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_29: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_105, 0.125);  linear_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_61: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_29, [1, 1, 8, 64]);  mul_29 = None
        transpose_98: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_61, 1, 2);  view_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_106: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_32, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_62: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_106, [1, -1, 8, 64]);  linear_106 = None
        transpose_99: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_62, 1, 2);  view_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_107: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_32, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_63: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_107, [1, -1, 8, 64]);  linear_107 = None
        transpose_100: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_63, 1, 2);  view_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_39: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_99, torch.float32);  transpose_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_40: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_100, torch.float32);  transpose_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_191: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__26: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_191, 2, add_52, to_39);  slice_191 = to_39 = index_copy__26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_192: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__27: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_192, 2, add_52, to_40);  slice_192 = to_40 = index_copy__27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_193: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_194: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_193, 2, 0, 9223372036854775807);  slice_193 = None
        slice_195: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_194, 3, 0, 9223372036854775807);  slice_194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_196: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_197: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_196, 2, 0, 9223372036854775807);  slice_196 = None
        slice_198: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_197, 3, 0, 9223372036854775807);  slice_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_101: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_195, 2, 3);  slice_195 = None
        matmul_40: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_98, transpose_101);  transpose_98 = transpose_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_199: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_4, 0, 0, 9223372036854775807)
        slice_200: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_199, 1, 0, 9223372036854775807);  slice_199 = None
        slice_201: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_200, 2, 0, 9223372036854775807);  slice_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_61: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_40, slice_201);  matmul_40 = slice_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_20: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_61, -1);  add_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_69: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_20, 0.0, False);  softmax_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_41: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_69, slice_198);  dropout_69 = slice_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_102: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_41, 1, 2);  matmul_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_22: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_102, [1, 1, 512]);  transpose_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_108: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_22, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_70: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_108, 0.1, False);  linear_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_62: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_32, dropout_70);  layer_norm_32 = dropout_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_33: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_62, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_109: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_33, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_30: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_109, 0.125);  linear_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_64: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_30, [1, 1, 8, 64]);  mul_30 = None
        transpose_103: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_64, 1, 2);  view_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_202: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_203: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_202, 2, 0, 23);  slice_202 = None
        slice_204: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_203, 3, 0, 9223372036854775807);  slice_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_205: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_206: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_205, 2, 0, 23);  slice_205 = None
        slice_207: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_206, 3, 0, 9223372036854775807);  slice_206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_104: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_204, 2, 3);  slice_204 = None
        matmul_42: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_103, transpose_104);  transpose_103 = transpose_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_208: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_2, 0, 0, 9223372036854775807)
        slice_209: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_208, 1, 0, 9223372036854775807);  slice_208 = None
        slice_210: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_209, 2, 0, 9223372036854775807);  slice_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_63: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_42, slice_210);  matmul_42 = slice_210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_21: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_63, -1);  add_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_71: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_21, 0.0, False);  softmax_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_43: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_71, slice_207);  dropout_71 = slice_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_105: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_43, 1, 2);  matmul_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_23: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_105, [1, 1, 512]);  transpose_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_110: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_23, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_72: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_110, 0.1, False);  linear_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_64: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_33, dropout_72);  layer_norm_33 = dropout_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_34: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_64, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_111: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_34, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_13: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_111);  linear_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_73: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_13, 0.0, False);  silu_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_112: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_73, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_74: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_112, 0.1, False);  linear_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_65: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_34, dropout_74);  layer_norm_34 = dropout_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_35: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_65, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_113: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_35, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_31: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_113, 0.125);  linear_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_65: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_31, [1, 1, 8, 64]);  mul_31 = None
        transpose_106: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_65, 1, 2);  view_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_114: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_35, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_66: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_114, [1, -1, 8, 64]);  linear_114 = None
        transpose_107: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_66, 1, 2);  view_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_115: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_35, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_67: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_115, [1, -1, 8, 64]);  linear_115 = None
        transpose_108: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_67, 1, 2);  view_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_41: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_107, torch.float32);  transpose_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_42: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_108, torch.float32);  transpose_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_211: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__28: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_211, 2, add_52, to_41);  slice_211 = to_41 = index_copy__28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_212: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__29: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_212, 2, add_52, to_42);  slice_212 = to_42 = index_copy__29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_213: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_214: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_213, 2, 0, 9223372036854775807);  slice_213 = None
        slice_215: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_214, 3, 0, 9223372036854775807);  slice_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_216: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_217: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_216, 2, 0, 9223372036854775807);  slice_216 = None
        slice_218: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_217, 3, 0, 9223372036854775807);  slice_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_109: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_215, 2, 3);  slice_215 = None
        matmul_44: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_106, transpose_109);  transpose_106 = transpose_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_219: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_4, 0, 0, 9223372036854775807)
        slice_220: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_219, 1, 0, 9223372036854775807);  slice_219 = None
        slice_221: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_220, 2, 0, 9223372036854775807);  slice_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_66: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_44, slice_221);  matmul_44 = slice_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_22: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_66, -1);  add_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_75: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_22, 0.0, False);  softmax_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_45: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_75, slice_218);  dropout_75 = slice_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_110: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_45, 1, 2);  matmul_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_24: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_110, [1, 1, 512]);  transpose_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_116: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_24, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_76: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_116, 0.1, False);  linear_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_67: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_35, dropout_76);  layer_norm_35 = dropout_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_36: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_67, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_117: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_36, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_32: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_117, 0.125);  linear_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_68: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_32, [1, 1, 8, 64]);  mul_32 = None
        transpose_111: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_68, 1, 2);  view_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_222: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_223: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_222, 2, 0, 23);  slice_222 = None
        slice_224: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_223, 3, 0, 9223372036854775807);  slice_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_225: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_226: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_225, 2, 0, 23);  slice_225 = None
        slice_227: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_226, 3, 0, 9223372036854775807);  slice_226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_112: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_224, 2, 3);  slice_224 = None
        matmul_46: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_111, transpose_112);  transpose_111 = transpose_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_228: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_2, 0, 0, 9223372036854775807)
        slice_229: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_228, 1, 0, 9223372036854775807);  slice_228 = None
        slice_230: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_229, 2, 0, 9223372036854775807);  slice_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_68: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_46, slice_230);  matmul_46 = slice_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_23: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_68, -1);  add_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_77: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_23, 0.0, False);  softmax_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_47: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_77, slice_227);  dropout_77 = slice_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_113: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_47, 1, 2);  matmul_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_25: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_113, [1, 1, 512]);  transpose_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_118: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_25, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_78: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_118, 0.1, False);  linear_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_69: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_36, dropout_78);  layer_norm_36 = dropout_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_37: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_69, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_119: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_37, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_14: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_119);  linear_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_79: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_14, 0.0, False);  silu_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_120: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_79, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_80: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_120, 0.1, False);  linear_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_70: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_37, dropout_80);  layer_norm_37 = dropout_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_38: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_70, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_121: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_38, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_33: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_121, 0.125);  linear_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_69: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_33, [1, 1, 8, 64]);  mul_33 = None
        transpose_114: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_69, 1, 2);  view_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_122: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_38, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_70: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_122, [1, -1, 8, 64]);  linear_122 = None
        transpose_115: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_70, 1, 2);  view_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_123: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_38, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_71: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_123, [1, -1, 8, 64]);  linear_123 = None
        transpose_116: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_71, 1, 2);  view_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_43: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_115, torch.float32);  transpose_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_44: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_116, torch.float32);  transpose_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_231: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__30: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_231, 2, add_52, to_43);  slice_231 = to_43 = index_copy__30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_232: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__31: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_232, 2, add_52, to_44);  slice_232 = to_44 = index_copy__31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_233: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_234: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_233, 2, 0, 9223372036854775807);  slice_233 = None
        slice_235: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_234, 3, 0, 9223372036854775807);  slice_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_236: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_237: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_236, 2, 0, 9223372036854775807);  slice_236 = None
        slice_238: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_237, 3, 0, 9223372036854775807);  slice_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_117: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_235, 2, 3);  slice_235 = None
        matmul_48: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_114, transpose_117);  transpose_114 = transpose_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_239: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_4, 0, 0, 9223372036854775807)
        slice_240: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_239, 1, 0, 9223372036854775807);  slice_239 = None
        slice_241: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_240, 2, 0, 9223372036854775807);  slice_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_71: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_48, slice_241);  matmul_48 = slice_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_24: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_71, -1);  add_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_81: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_24, 0.0, False);  softmax_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_49: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_81, slice_238);  dropout_81 = slice_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_118: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_49, 1, 2);  matmul_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_26: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_118, [1, 1, 512]);  transpose_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_124: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_26, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_82: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_124, 0.1, False);  linear_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_72: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_38, dropout_82);  layer_norm_38 = dropout_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_39: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_72, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_125: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_39, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_34: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_125, 0.125);  linear_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_72: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_34, [1, 1, 8, 64]);  mul_34 = None
        transpose_119: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_72, 1, 2);  view_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_242: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_243: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_242, 2, 0, 23);  slice_242 = None
        slice_244: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_243, 3, 0, 9223372036854775807);  slice_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_245: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_246: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_245, 2, 0, 23);  slice_245 = None
        slice_247: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_246, 3, 0, 9223372036854775807);  slice_246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_120: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_244, 2, 3);  slice_244 = None
        matmul_50: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_119, transpose_120);  transpose_119 = transpose_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_248: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_2, 0, 0, 9223372036854775807)
        slice_249: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_248, 1, 0, 9223372036854775807);  slice_248 = None
        slice_250: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_249, 2, 0, 9223372036854775807);  slice_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_73: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_50, slice_250);  matmul_50 = slice_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_25: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_73, -1);  add_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_83: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_25, 0.0, False);  softmax_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_51: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_83, slice_247);  dropout_83 = slice_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_121: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_51, 1, 2);  matmul_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_27: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_121, [1, 1, 512]);  transpose_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_126: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_27, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_84: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_126, 0.1, False);  linear_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_74: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_39, dropout_84);  layer_norm_39 = dropout_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_40: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_74, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_127: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_40, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_15: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_127);  linear_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_85: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_15, 0.0, False);  silu_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_128: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_85, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_86: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_128, 0.1, False);  linear_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_75: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_40, dropout_86);  layer_norm_40 = dropout_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_41: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_75, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_129: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_41, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_35: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_129, 0.125);  linear_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_73: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_35, [1, 1, 8, 64]);  mul_35 = None
        transpose_122: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_73, 1, 2);  view_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_130: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_41, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_74: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_130, [1, -1, 8, 64]);  linear_130 = None
        transpose_123: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_74, 1, 2);  view_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_131: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_41, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_75: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_131, [1, -1, 8, 64]);  linear_131 = None
        transpose_124: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_75, 1, 2);  view_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_45: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_123, torch.float32);  transpose_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_46: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_124, torch.float32);  transpose_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_251: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__32: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_251, 2, add_52, to_45);  slice_251 = to_45 = index_copy__32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_252: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__33: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_252, 2, add_52, to_46);  slice_252 = to_46 = index_copy__33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_253: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_254: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_253, 2, 0, 9223372036854775807);  slice_253 = None
        slice_255: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_254, 3, 0, 9223372036854775807);  slice_254 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_256: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_257: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_256, 2, 0, 9223372036854775807);  slice_256 = None
        slice_258: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_257, 3, 0, 9223372036854775807);  slice_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_125: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_255, 2, 3);  slice_255 = None
        matmul_52: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_122, transpose_125);  transpose_122 = transpose_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_259: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_4, 0, 0, 9223372036854775807)
        slice_260: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_259, 1, 0, 9223372036854775807);  slice_259 = None
        slice_261: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_260, 2, 0, 9223372036854775807);  slice_260 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_76: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_52, slice_261);  matmul_52 = slice_261 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_26: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_76, -1);  add_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_87: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_26, 0.0, False);  softmax_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_53: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_87, slice_258);  dropout_87 = slice_258 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_126: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_53, 1, 2);  matmul_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_28: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_126, [1, 1, 512]);  transpose_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_132: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_28, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_88: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_132, 0.1, False);  linear_132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_77: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_41, dropout_88);  layer_norm_41 = dropout_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_42: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_77, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_133: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_42, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_36: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_133, 0.125);  linear_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_76: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_36, [1, 1, 8, 64]);  mul_36 = None
        transpose_127: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_76, 1, 2);  view_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_262: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_263: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_262, 2, 0, 23);  slice_262 = None
        slice_264: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_263, 3, 0, 9223372036854775807);  slice_263 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_265: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_266: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_265, 2, 0, 23);  slice_265 = None
        slice_267: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_266, 3, 0, 9223372036854775807);  slice_266 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_128: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_264, 2, 3);  slice_264 = None
        matmul_54: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_127, transpose_128);  transpose_127 = transpose_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_268: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_2, 0, 0, 9223372036854775807)
        slice_269: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_268, 1, 0, 9223372036854775807);  slice_268 = None
        slice_270: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_269, 2, 0, 9223372036854775807);  slice_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_78: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_54, slice_270);  matmul_54 = slice_270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_27: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_78, -1);  add_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_89: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_27, 0.0, False);  softmax_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_55: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_89, slice_267);  dropout_89 = slice_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_129: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_55, 1, 2);  matmul_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_29: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_129, [1, 1, 512]);  transpose_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_134: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_29, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_90: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_134, 0.1, False);  linear_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_79: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_42, dropout_90);  layer_norm_42 = dropout_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_43: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_79, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_135: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_43, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_16: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_135);  linear_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_91: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_16, 0.0, False);  silu_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_136: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_91, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_92: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_136, 0.1, False);  linear_136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_80: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_43, dropout_92);  layer_norm_43 = dropout_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_44: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_80, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_137: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_44, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_37: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_137, 0.125);  linear_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_77: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_37, [1, 1, 8, 64]);  mul_37 = None
        transpose_130: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_77, 1, 2);  view_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_138: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_44, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_78: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_138, [1, -1, 8, 64]);  linear_138 = None
        transpose_131: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_78, 1, 2);  view_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_139: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_44, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_79: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_139, [1, -1, 8, 64]);  linear_139 = None
        transpose_132: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_79, 1, 2);  view_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_47: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_131, torch.float32);  transpose_131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_48: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_132, torch.float32);  transpose_132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_271: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__34: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_271, 2, add_52, to_47);  slice_271 = to_47 = index_copy__34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_272: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__35: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_272, 2, add_52, to_48);  slice_272 = to_48 = index_copy__35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_273: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_274: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_273, 2, 0, 9223372036854775807);  slice_273 = None
        slice_275: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_274, 3, 0, 9223372036854775807);  slice_274 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_276: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_277: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_276, 2, 0, 9223372036854775807);  slice_276 = None
        slice_278: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_277, 3, 0, 9223372036854775807);  slice_277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_133: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_275, 2, 3);  slice_275 = None
        matmul_56: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_130, transpose_133);  transpose_130 = transpose_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_279: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_4, 0, 0, 9223372036854775807);  expand_4 = None
        slice_280: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_279, 1, 0, 9223372036854775807);  slice_279 = None
        slice_281: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_280, 2, 0, 9223372036854775807);  slice_280 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_81: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_56, slice_281);  matmul_56 = slice_281 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_28: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_81, -1);  add_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_93: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_28, 0.0, False);  softmax_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_57: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_93, slice_278);  dropout_93 = slice_278 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_134: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_57, 1, 2);  matmul_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_30: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_134, [1, 1, 512]);  transpose_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_140: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_30, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_94: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_140, 0.1, False);  linear_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_82: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_44, dropout_94);  layer_norm_44 = dropout_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_45: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_82, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_141: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_45, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_38: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_141, 0.125);  linear_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_80: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_38, [1, 1, 8, 64]);  mul_38 = None
        transpose_135: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_80, 1, 2);  view_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_282: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_283: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_282, 2, 0, 23);  slice_282 = None
        slice_284: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_283, 3, 0, 9223372036854775807);  slice_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_285: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_286: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_285, 2, 0, 23);  slice_285 = None
        slice_287: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_286, 3, 0, 9223372036854775807);  slice_286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_136: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_284, 2, 3);  slice_284 = None
        matmul_58: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_135, transpose_136);  transpose_135 = transpose_136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_288: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_2, 0, 0, 9223372036854775807);  masked_fill_2 = None
        slice_289: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_288, 1, 0, 9223372036854775807);  slice_288 = None
        slice_290: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_289, 2, 0, 9223372036854775807);  slice_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_83: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_58, slice_290);  matmul_58 = slice_290 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_29: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_83, -1);  add_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_95: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_29, 0.0, False);  softmax_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_59: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_95, slice_287);  dropout_95 = slice_287 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_137: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_59, 1, 2);  matmul_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_31: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_137, [1, 1, 512]);  transpose_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_142: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_31, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_96: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_142, 0.1, False);  linear_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_84: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_45, dropout_96);  layer_norm_45 = dropout_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_46: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_84, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_143: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_46, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_17: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_143);  linear_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_97: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_17, 0.0, False);  silu_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_144: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_97, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_98: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_144, 0.1, False);  linear_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_85: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_46, dropout_98);  layer_norm_46 = dropout_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_47: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_85, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_145: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_47, p_model_lm_head_weight);  layer_norm_47 = None
        add_86: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_145, b_model_final_logits_bias);  linear_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_291: "i64[1]" = torch.ops.aten.slice.Tensor(add_52, 0, -1, 9223372036854775807);  add_52 = None
        add_87: "i64[1]" = torch.ops.aten.add.Tensor(slice_291, 1);  slice_291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_292: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_86, 0, 0, 9223372036854775807);  add_86 = None
        select_12: "f32[1, 59514]" = torch.ops.aten.select.int(slice_292, 1, -1);  slice_292 = None
        slice_293: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_12, 1, 0, 9223372036854775807);  select_12 = None
        clone_3: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_293);  slice_293 = None
        to_49: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_3, torch.float32);  clone_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_50: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_49, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_1: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_50, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__1: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_1, to_32);  zeros_like_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_88: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_50, add__1);  to_50 = add__1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_1: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_88, -1);  add_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_1: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_1, -1);  log_softmax_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_39: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_1, and_1);  argmax_1 = None
        rsub_4: "i64[1]" = torch.ops.aten.rsub.Scalar(and_1, 1)
        mul_40: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_4);  rsub_4 = None
        add_89: "i64[1]" = torch.ops.aten.add.Tensor(mul_39, mul_40);  mul_39 = mul_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_294: "i64[1]" = torch.ops.aten.slice.Tensor(add_89, 0, 0, 9223372036854775807);  add_89 = None
        unsqueeze_14: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_294, 1);  slice_294 = None
        cat_1: "i64[1, 3]" = torch.ops.aten.cat.default([cat, unsqueeze_14], -1);  cat = unsqueeze_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_4: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_5: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_3: "b8[1]" = torch.ops.aten.__or__.Tensor(full_4, full_5);  full_4 = full_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_51: "i64[1]" = torch.ops.aten.to.dtype_layout(to_33, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_295: "i64[1, 3]" = torch.ops.aten.slice.Tensor(cat_1, 0, 0, 9223372036854775807)
        select_13: "i64[1]" = torch.ops.aten.select.int(slice_295, 1, -1);  slice_295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_3: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_13, to_51);  select_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_4: "b8[1]" = torch.ops.aten.__or__.Tensor(or_3, isin_3);  or_3 = isin_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_3: "b8[1]" = torch.ops.aten.bitwise_not.default(or_4);  or_4 = None
        and_2: "i64[1]" = torch.ops.aten.__and__.Tensor(and_1, bitwise_not_3);  and_1 = bitwise_not_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_2: "i64[]" = torch.ops.aten.max.default(and_2)
        eq_1: "b8[]" = torch.ops.aten.eq.Scalar(max_2, 0);  max_2 = eq_1 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_296: "i64[1, 3]" = torch.ops.aten.slice.Tensor(cat_1, 0, 0, 9223372036854775807)
        slice_297: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_296, 1, -1, 9223372036854775807);  slice_296 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_4: "i64[1, 1]" = torch.ops.aten.clone.default(slice_297, memory_format = torch.contiguous_format);  slice_297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_81: "i64[1, 1]" = torch.ops.aten.view.default(clone_4, [-1, 1]);  clone_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_6: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_81, 59513);  view_81 = None
        mul_41: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_6, 22.627416997969522);  embedding_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_15: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_87, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_298: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_16: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_298, 1);  slice_298 = None
        unsqueeze_17: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_16, 2);  unsqueeze_16 = None
        slice_299: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_17, 3, 0, 9223372036854775807);  unsqueeze_17 = None
        expand_5: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_299, [1, 1, 1, 23]);  slice_299 = None
        to_52: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_5, torch.float32);  expand_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_5: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_52, 1.0);  to_52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_53: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_5, torch.bool)
        masked_fill_3: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_5, to_53, -3.4028234663852886e+38);  rsub_5 = to_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_7: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_15);  unsqueeze_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_54: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_7, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_7 = None
        add_90: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_41, to_54);  mul_41 = to_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_99: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_90, 0.1, False);  add_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_14: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_15: "f32[20, 64]" = torch.ops.aten.select.int(select_14, 0, 0);  select_14 = None
        any_7: "b8[20]" = torch.ops.aten.any.dim(select_15, -1);  select_15 = None
        sum_5: "i64[]" = torch.ops.aten.sum.default(any_7);  any_7 = sum_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_6: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_9: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_32: "i64[1, 1]" = torch.ops.aten.reshape.default(add_87, [-1, 1])
        gt_2: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_9, reshape_32);  arange_9 = reshape_32 = None
        mul__2: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_6, gt_2);  full_6 = gt_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_18: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__2, 0);  mul__2 = None
        unsqueeze_19: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_18, 1);  unsqueeze_18 = None
        slice_300: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_19, 2, 0, 9223372036854775807);  unsqueeze_19 = None
        slice_301: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_300, 3, 0, 9223372036854775807);  slice_300 = None
        expand_6: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_301, [1, 1, -1, -1]);  slice_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_146: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_99, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_42: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_146, 0.125);  linear_146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_82: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_42, [1, 1, 8, 64]);  mul_42 = None
        transpose_138: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_82, 1, 2);  view_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_147: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_99, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_83: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_147, [1, -1, 8, 64]);  linear_147 = None
        transpose_139: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_83, 1, 2);  view_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_148: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_99, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_84: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_148, [1, -1, 8, 64]);  linear_148 = None
        transpose_140: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_84, 1, 2);  view_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_55: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_139, torch.float32);  transpose_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_56: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_140, torch.float32);  transpose_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_302: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__36: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_302, 2, add_87, to_55);  slice_302 = to_55 = index_copy__36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_303: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__37: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_303, 2, add_87, to_56);  slice_303 = to_56 = index_copy__37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_304: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_305: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_304, 2, 0, 9223372036854775807);  slice_304 = None
        slice_306: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_305, 3, 0, 9223372036854775807);  slice_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_307: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_308: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_307, 2, 0, 9223372036854775807);  slice_307 = None
        slice_309: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_308, 3, 0, 9223372036854775807);  slice_308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_141: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_306, 2, 3);  slice_306 = None
        matmul_60: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_138, transpose_141);  transpose_138 = transpose_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_310: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_6, 0, 0, 9223372036854775807)
        slice_311: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_310, 1, 0, 9223372036854775807);  slice_310 = None
        slice_312: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_311, 2, 0, 9223372036854775807);  slice_311 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_91: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_60, slice_312);  matmul_60 = slice_312 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_30: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_91, -1);  add_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_100: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_30, 0.0, False);  softmax_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_61: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_100, slice_309);  dropout_100 = slice_309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_142: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_61, 1, 2);  matmul_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_33: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_142, [1, 1, 512]);  transpose_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_149: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_33, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_101: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_149, 0.1, False);  linear_149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_92: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_99, dropout_101);  dropout_99 = dropout_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_48: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_92, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_150: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_48, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_43: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_150, 0.125);  linear_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_85: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_43, [1, 1, 8, 64]);  mul_43 = None
        transpose_143: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_85, 1, 2);  view_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_313: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_314: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_313, 2, 0, 23);  slice_313 = None
        slice_315: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_314, 3, 0, 9223372036854775807);  slice_314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_316: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_317: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_316, 2, 0, 23);  slice_316 = None
        slice_318: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_317, 3, 0, 9223372036854775807);  slice_317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_144: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_315, 2, 3);  slice_315 = None
        matmul_62: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_143, transpose_144);  transpose_143 = transpose_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_319: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_3, 0, 0, 9223372036854775807)
        slice_320: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_319, 1, 0, 9223372036854775807);  slice_319 = None
        slice_321: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_320, 2, 0, 9223372036854775807);  slice_320 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_93: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_62, slice_321);  matmul_62 = slice_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_31: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_93, -1);  add_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_102: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_31, 0.0, False);  softmax_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_63: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_102, slice_318);  dropout_102 = slice_318 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_145: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_63, 1, 2);  matmul_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_34: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_145, [1, 1, 512]);  transpose_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_151: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_34, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_103: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_151, 0.1, False);  linear_151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_94: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_48, dropout_103);  layer_norm_48 = dropout_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_49: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_94, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_152: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_49, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_18: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_152);  linear_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_104: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_18, 0.0, False);  silu_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_153: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_104, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_105: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_153, 0.1, False);  linear_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_95: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_49, dropout_105);  layer_norm_49 = dropout_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_50: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_95, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_154: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_50, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_44: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_154, 0.125);  linear_154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_86: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_44, [1, 1, 8, 64]);  mul_44 = None
        transpose_146: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_86, 1, 2);  view_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_155: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_50, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_87: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_155, [1, -1, 8, 64]);  linear_155 = None
        transpose_147: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_87, 1, 2);  view_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_156: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_50, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_88: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_156, [1, -1, 8, 64]);  linear_156 = None
        transpose_148: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_88, 1, 2);  view_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_57: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_147, torch.float32);  transpose_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_58: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_148, torch.float32);  transpose_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_322: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__38: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_322, 2, add_87, to_57);  slice_322 = to_57 = index_copy__38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_323: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__39: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_323, 2, add_87, to_58);  slice_323 = to_58 = index_copy__39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_324: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_325: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_324, 2, 0, 9223372036854775807);  slice_324 = None
        slice_326: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_325, 3, 0, 9223372036854775807);  slice_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_327: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_328: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_327, 2, 0, 9223372036854775807);  slice_327 = None
        slice_329: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_328, 3, 0, 9223372036854775807);  slice_328 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_149: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_326, 2, 3);  slice_326 = None
        matmul_64: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_146, transpose_149);  transpose_146 = transpose_149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_330: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_6, 0, 0, 9223372036854775807)
        slice_331: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_330, 1, 0, 9223372036854775807);  slice_330 = None
        slice_332: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_331, 2, 0, 9223372036854775807);  slice_331 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_96: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_64, slice_332);  matmul_64 = slice_332 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_32: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_96, -1);  add_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_106: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_32, 0.0, False);  softmax_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_65: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_106, slice_329);  dropout_106 = slice_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_150: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_65, 1, 2);  matmul_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_35: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_150, [1, 1, 512]);  transpose_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_157: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_35, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_107: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_157, 0.1, False);  linear_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_97: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_50, dropout_107);  layer_norm_50 = dropout_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_51: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_97, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_158: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_51, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_45: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_158, 0.125);  linear_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_89: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_45, [1, 1, 8, 64]);  mul_45 = None
        transpose_151: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_89, 1, 2);  view_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_333: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_334: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_333, 2, 0, 23);  slice_333 = None
        slice_335: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_334, 3, 0, 9223372036854775807);  slice_334 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_336: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_337: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_336, 2, 0, 23);  slice_336 = None
        slice_338: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_337, 3, 0, 9223372036854775807);  slice_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_152: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_335, 2, 3);  slice_335 = None
        matmul_66: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_151, transpose_152);  transpose_151 = transpose_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_339: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_3, 0, 0, 9223372036854775807)
        slice_340: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_339, 1, 0, 9223372036854775807);  slice_339 = None
        slice_341: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_340, 2, 0, 9223372036854775807);  slice_340 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_98: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_66, slice_341);  matmul_66 = slice_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_33: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_98, -1);  add_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_108: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_33, 0.0, False);  softmax_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_67: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_108, slice_338);  dropout_108 = slice_338 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_153: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_67, 1, 2);  matmul_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_36: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_153, [1, 1, 512]);  transpose_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_159: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_36, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_109: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_159, 0.1, False);  linear_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_99: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_51, dropout_109);  layer_norm_51 = dropout_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_52: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_99, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_160: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_52, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_19: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_160);  linear_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_110: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_19, 0.0, False);  silu_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_161: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_110, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_111: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_161, 0.1, False);  linear_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_100: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_52, dropout_111);  layer_norm_52 = dropout_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_53: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_100, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_162: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_53, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_46: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_162, 0.125);  linear_162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_90: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_46, [1, 1, 8, 64]);  mul_46 = None
        transpose_154: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_90, 1, 2);  view_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_163: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_53, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_91: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_163, [1, -1, 8, 64]);  linear_163 = None
        transpose_155: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_91, 1, 2);  view_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_164: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_53, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_92: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_164, [1, -1, 8, 64]);  linear_164 = None
        transpose_156: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_92, 1, 2);  view_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_59: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_155, torch.float32);  transpose_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_60: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_156, torch.float32);  transpose_156 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_342: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__40: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_342, 2, add_87, to_59);  slice_342 = to_59 = index_copy__40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_343: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__41: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_343, 2, add_87, to_60);  slice_343 = to_60 = index_copy__41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_344: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_345: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_344, 2, 0, 9223372036854775807);  slice_344 = None
        slice_346: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_345, 3, 0, 9223372036854775807);  slice_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_347: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_348: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_347, 2, 0, 9223372036854775807);  slice_347 = None
        slice_349: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_348, 3, 0, 9223372036854775807);  slice_348 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_157: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_346, 2, 3);  slice_346 = None
        matmul_68: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_154, transpose_157);  transpose_154 = transpose_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_350: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_6, 0, 0, 9223372036854775807)
        slice_351: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_350, 1, 0, 9223372036854775807);  slice_350 = None
        slice_352: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_351, 2, 0, 9223372036854775807);  slice_351 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_101: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_68, slice_352);  matmul_68 = slice_352 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_34: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_101, -1);  add_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_112: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_34, 0.0, False);  softmax_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_69: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_112, slice_349);  dropout_112 = slice_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_158: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_69, 1, 2);  matmul_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_37: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_158, [1, 1, 512]);  transpose_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_165: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_37, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_113: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_165, 0.1, False);  linear_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_102: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_53, dropout_113);  layer_norm_53 = dropout_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_54: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_102, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_166: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_54, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_47: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_166, 0.125);  linear_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_93: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_47, [1, 1, 8, 64]);  mul_47 = None
        transpose_159: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_93, 1, 2);  view_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_353: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_354: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_353, 2, 0, 23);  slice_353 = None
        slice_355: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_354, 3, 0, 9223372036854775807);  slice_354 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_356: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_357: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_356, 2, 0, 23);  slice_356 = None
        slice_358: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_357, 3, 0, 9223372036854775807);  slice_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_160: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_355, 2, 3);  slice_355 = None
        matmul_70: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_159, transpose_160);  transpose_159 = transpose_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_359: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_3, 0, 0, 9223372036854775807)
        slice_360: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_359, 1, 0, 9223372036854775807);  slice_359 = None
        slice_361: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_360, 2, 0, 9223372036854775807);  slice_360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_103: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_70, slice_361);  matmul_70 = slice_361 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_35: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_103, -1);  add_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_114: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_35, 0.0, False);  softmax_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_71: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_114, slice_358);  dropout_114 = slice_358 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_161: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_71, 1, 2);  matmul_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_38: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_161, [1, 1, 512]);  transpose_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_167: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_38, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_115: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_167, 0.1, False);  linear_167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_104: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_54, dropout_115);  layer_norm_54 = dropout_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_55: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_104, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_168: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_55, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_20: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_168);  linear_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_116: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_20, 0.0, False);  silu_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_169: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_116, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_117: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_169, 0.1, False);  linear_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_105: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_55, dropout_117);  layer_norm_55 = dropout_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_56: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_105, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_170: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_56, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_48: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_170, 0.125);  linear_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_94: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_48, [1, 1, 8, 64]);  mul_48 = None
        transpose_162: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_94, 1, 2);  view_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_171: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_56, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_95: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_171, [1, -1, 8, 64]);  linear_171 = None
        transpose_163: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_95, 1, 2);  view_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_172: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_56, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_96: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_172, [1, -1, 8, 64]);  linear_172 = None
        transpose_164: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_96, 1, 2);  view_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_61: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_163, torch.float32);  transpose_163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_62: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_164, torch.float32);  transpose_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_362: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__42: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_362, 2, add_87, to_61);  slice_362 = to_61 = index_copy__42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_363: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__43: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_363, 2, add_87, to_62);  slice_363 = to_62 = index_copy__43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_364: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_365: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_364, 2, 0, 9223372036854775807);  slice_364 = None
        slice_366: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_365, 3, 0, 9223372036854775807);  slice_365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_367: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_368: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_367, 2, 0, 9223372036854775807);  slice_367 = None
        slice_369: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_368, 3, 0, 9223372036854775807);  slice_368 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_165: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_366, 2, 3);  slice_366 = None
        matmul_72: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_162, transpose_165);  transpose_162 = transpose_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_370: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_6, 0, 0, 9223372036854775807)
        slice_371: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_370, 1, 0, 9223372036854775807);  slice_370 = None
        slice_372: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_371, 2, 0, 9223372036854775807);  slice_371 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_106: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_72, slice_372);  matmul_72 = slice_372 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_36: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_106, -1);  add_106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_118: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_36, 0.0, False);  softmax_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_73: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_118, slice_369);  dropout_118 = slice_369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_166: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_73, 1, 2);  matmul_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_39: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_166, [1, 1, 512]);  transpose_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_173: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_39, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_119: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_173, 0.1, False);  linear_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_107: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_56, dropout_119);  layer_norm_56 = dropout_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_57: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_107, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_174: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_57, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_49: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_174, 0.125);  linear_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_97: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_49, [1, 1, 8, 64]);  mul_49 = None
        transpose_167: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_97, 1, 2);  view_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_373: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_374: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_373, 2, 0, 23);  slice_373 = None
        slice_375: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_374, 3, 0, 9223372036854775807);  slice_374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_376: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_377: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_376, 2, 0, 23);  slice_376 = None
        slice_378: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_377, 3, 0, 9223372036854775807);  slice_377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_168: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_375, 2, 3);  slice_375 = None
        matmul_74: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_167, transpose_168);  transpose_167 = transpose_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_379: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_3, 0, 0, 9223372036854775807)
        slice_380: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_379, 1, 0, 9223372036854775807);  slice_379 = None
        slice_381: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_380, 2, 0, 9223372036854775807);  slice_380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_108: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_74, slice_381);  matmul_74 = slice_381 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_37: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_108, -1);  add_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_120: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_37, 0.0, False);  softmax_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_75: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_120, slice_378);  dropout_120 = slice_378 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_169: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_75, 1, 2);  matmul_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_40: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_169, [1, 1, 512]);  transpose_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_175: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_40, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_121: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_175, 0.1, False);  linear_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_109: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_57, dropout_121);  layer_norm_57 = dropout_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_58: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_109, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_176: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_58, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_21: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_176);  linear_176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_122: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_21, 0.0, False);  silu_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_177: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_122, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_123: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_177, 0.1, False);  linear_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_110: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_58, dropout_123);  layer_norm_58 = dropout_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_59: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_110, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_178: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_59, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_50: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_178, 0.125);  linear_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_98: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_50, [1, 1, 8, 64]);  mul_50 = None
        transpose_170: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_98, 1, 2);  view_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_179: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_59, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_99: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_179, [1, -1, 8, 64]);  linear_179 = None
        transpose_171: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_99, 1, 2);  view_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_180: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_59, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_100: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_180, [1, -1, 8, 64]);  linear_180 = None
        transpose_172: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_100, 1, 2);  view_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_63: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_171, torch.float32);  transpose_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_64: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_172, torch.float32);  transpose_172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_382: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__44: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_382, 2, add_87, to_63);  slice_382 = to_63 = index_copy__44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_383: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__45: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_383, 2, add_87, to_64);  slice_383 = to_64 = index_copy__45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_384: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_385: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_384, 2, 0, 9223372036854775807);  slice_384 = None
        slice_386: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_385, 3, 0, 9223372036854775807);  slice_385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_387: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_388: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_387, 2, 0, 9223372036854775807);  slice_387 = None
        slice_389: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_388, 3, 0, 9223372036854775807);  slice_388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_173: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_386, 2, 3);  slice_386 = None
        matmul_76: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_170, transpose_173);  transpose_170 = transpose_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_390: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_6, 0, 0, 9223372036854775807)
        slice_391: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_390, 1, 0, 9223372036854775807);  slice_390 = None
        slice_392: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_391, 2, 0, 9223372036854775807);  slice_391 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_111: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_76, slice_392);  matmul_76 = slice_392 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_38: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_111, -1);  add_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_124: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_38, 0.0, False);  softmax_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_77: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_124, slice_389);  dropout_124 = slice_389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_174: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_77, 1, 2);  matmul_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_41: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_174, [1, 1, 512]);  transpose_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_181: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_41, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_125: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_181, 0.1, False);  linear_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_112: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_59, dropout_125);  layer_norm_59 = dropout_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_60: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_112, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_182: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_60, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_51: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_182, 0.125);  linear_182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_101: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_51, [1, 1, 8, 64]);  mul_51 = None
        transpose_175: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_101, 1, 2);  view_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_393: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_394: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_393, 2, 0, 23);  slice_393 = None
        slice_395: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_394, 3, 0, 9223372036854775807);  slice_394 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_396: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_397: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_396, 2, 0, 23);  slice_396 = None
        slice_398: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_397, 3, 0, 9223372036854775807);  slice_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_176: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_395, 2, 3);  slice_395 = None
        matmul_78: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_175, transpose_176);  transpose_175 = transpose_176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_399: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_3, 0, 0, 9223372036854775807)
        slice_400: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_399, 1, 0, 9223372036854775807);  slice_399 = None
        slice_401: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_400, 2, 0, 9223372036854775807);  slice_400 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_113: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_78, slice_401);  matmul_78 = slice_401 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_39: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_113, -1);  add_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_126: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_39, 0.0, False);  softmax_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_79: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_126, slice_398);  dropout_126 = slice_398 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_177: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_79, 1, 2);  matmul_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_42: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_177, [1, 1, 512]);  transpose_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_183: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_42, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_127: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_183, 0.1, False);  linear_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_114: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_60, dropout_127);  layer_norm_60 = dropout_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_61: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_114, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_184: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_61, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_22: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_184);  linear_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_128: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_22, 0.0, False);  silu_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_185: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_128, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_129: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_185, 0.1, False);  linear_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_115: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_61, dropout_129);  layer_norm_61 = dropout_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_62: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_115, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_186: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_62, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_52: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_186, 0.125);  linear_186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_102: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_52, [1, 1, 8, 64]);  mul_52 = None
        transpose_178: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_102, 1, 2);  view_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_187: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_62, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_103: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_187, [1, -1, 8, 64]);  linear_187 = None
        transpose_179: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_103, 1, 2);  view_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_188: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_62, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_104: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_188, [1, -1, 8, 64]);  linear_188 = None
        transpose_180: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_104, 1, 2);  view_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_65: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_179, torch.float32);  transpose_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_66: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_180, torch.float32);  transpose_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_402: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__46: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_402, 2, add_87, to_65);  slice_402 = to_65 = index_copy__46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_403: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__47: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_403, 2, add_87, to_66);  slice_403 = to_66 = index_copy__47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_404: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_405: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_404, 2, 0, 9223372036854775807);  slice_404 = None
        slice_406: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_405, 3, 0, 9223372036854775807);  slice_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_407: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_408: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_407, 2, 0, 9223372036854775807);  slice_407 = None
        slice_409: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_408, 3, 0, 9223372036854775807);  slice_408 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_181: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_406, 2, 3);  slice_406 = None
        matmul_80: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_178, transpose_181);  transpose_178 = transpose_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_410: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_6, 0, 0, 9223372036854775807);  expand_6 = None
        slice_411: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_410, 1, 0, 9223372036854775807);  slice_410 = None
        slice_412: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_411, 2, 0, 9223372036854775807);  slice_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_116: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_80, slice_412);  matmul_80 = slice_412 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_40: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_116, -1);  add_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_130: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_40, 0.0, False);  softmax_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_81: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_130, slice_409);  dropout_130 = slice_409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_182: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_81, 1, 2);  matmul_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_43: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_182, [1, 1, 512]);  transpose_182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_189: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_43, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_131: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_189, 0.1, False);  linear_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_117: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_62, dropout_131);  layer_norm_62 = dropout_131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_63: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_117, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_190: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_63, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_53: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_190, 0.125);  linear_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_105: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_53, [1, 1, 8, 64]);  mul_53 = None
        transpose_183: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_105, 1, 2);  view_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_413: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_414: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_413, 2, 0, 23);  slice_413 = None
        slice_415: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_414, 3, 0, 9223372036854775807);  slice_414 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_416: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_417: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_416, 2, 0, 23);  slice_416 = None
        slice_418: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_417, 3, 0, 9223372036854775807);  slice_417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_184: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_415, 2, 3);  slice_415 = None
        matmul_82: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_183, transpose_184);  transpose_183 = transpose_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_419: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_3, 0, 0, 9223372036854775807);  masked_fill_3 = None
        slice_420: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_419, 1, 0, 9223372036854775807);  slice_419 = None
        slice_421: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_420, 2, 0, 9223372036854775807);  slice_420 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_118: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_82, slice_421);  matmul_82 = slice_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_41: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_118, -1);  add_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_132: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_41, 0.0, False);  softmax_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_83: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_132, slice_418);  dropout_132 = slice_418 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_185: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_83, 1, 2);  matmul_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_44: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_185, [1, 1, 512]);  transpose_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_191: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_44, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_133: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_191, 0.1, False);  linear_191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_119: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_63, dropout_133);  layer_norm_63 = dropout_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_64: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_119, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_192: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_64, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_23: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_192);  linear_192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_134: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_23, 0.0, False);  silu_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_193: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_134, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_135: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_193, 0.1, False);  linear_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_120: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_64, dropout_135);  layer_norm_64 = dropout_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_65: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_120, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_194: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_65, p_model_lm_head_weight);  layer_norm_65 = None
        add_121: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_194, b_model_final_logits_bias);  linear_194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_422: "i64[1]" = torch.ops.aten.slice.Tensor(add_87, 0, -1, 9223372036854775807);  add_87 = None
        add_122: "i64[1]" = torch.ops.aten.add.Tensor(slice_422, 1);  slice_422 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_423: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_121, 0, 0, 9223372036854775807);  add_121 = None
        select_16: "f32[1, 59514]" = torch.ops.aten.select.int(slice_423, 1, -1);  slice_423 = None
        slice_424: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_16, 1, 0, 9223372036854775807);  select_16 = None
        clone_5: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_424);  slice_424 = None
        to_67: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_5, torch.float32);  clone_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_68: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_67, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_2: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_68, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__2: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_2, to_32);  zeros_like_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_123: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_68, add__2);  to_68 = add__2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_2: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_123, -1);  add_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_2: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_2, -1);  log_softmax_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_54: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_2, and_2);  argmax_2 = None
        rsub_6: "i64[1]" = torch.ops.aten.rsub.Scalar(and_2, 1)
        mul_55: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_6);  rsub_6 = None
        add_124: "i64[1]" = torch.ops.aten.add.Tensor(mul_54, mul_55);  mul_54 = mul_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_425: "i64[1]" = torch.ops.aten.slice.Tensor(add_124, 0, 0, 9223372036854775807);  add_124 = None
        unsqueeze_20: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_425, 1);  slice_425 = None
        cat_2: "i64[1, 4]" = torch.ops.aten.cat.default([cat_1, unsqueeze_20], -1);  cat_1 = unsqueeze_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_7: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_8: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_5: "b8[1]" = torch.ops.aten.__or__.Tensor(full_7, full_8);  full_7 = full_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_69: "i64[1]" = torch.ops.aten.to.dtype_layout(to_51, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_426: "i64[1, 4]" = torch.ops.aten.slice.Tensor(cat_2, 0, 0, 9223372036854775807)
        select_17: "i64[1]" = torch.ops.aten.select.int(slice_426, 1, -1);  slice_426 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_4: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_17, to_69);  select_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_6: "b8[1]" = torch.ops.aten.__or__.Tensor(or_5, isin_4);  or_5 = isin_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_4: "b8[1]" = torch.ops.aten.bitwise_not.default(or_6);  or_6 = None
        and_3: "i64[1]" = torch.ops.aten.__and__.Tensor(and_2, bitwise_not_4);  and_2 = bitwise_not_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_3: "i64[]" = torch.ops.aten.max.default(and_3)
        eq_2: "b8[]" = torch.ops.aten.eq.Scalar(max_3, 0);  max_3 = eq_2 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_427: "i64[1, 4]" = torch.ops.aten.slice.Tensor(cat_2, 0, 0, 9223372036854775807)
        slice_428: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_427, 1, -1, 9223372036854775807);  slice_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_6: "i64[1, 1]" = torch.ops.aten.clone.default(slice_428, memory_format = torch.contiguous_format);  slice_428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_106: "i64[1, 1]" = torch.ops.aten.view.default(clone_6, [-1, 1]);  clone_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_8: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_106, 59513);  view_106 = None
        mul_56: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_8, 22.627416997969522);  embedding_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_21: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_122, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_429: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_22: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_429, 1);  slice_429 = None
        unsqueeze_23: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_22, 2);  unsqueeze_22 = None
        slice_430: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_23, 3, 0, 9223372036854775807);  unsqueeze_23 = None
        expand_7: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_430, [1, 1, 1, 23]);  slice_430 = None
        to_70: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_7, torch.float32);  expand_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_7: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_70, 1.0);  to_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_71: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_7, torch.bool)
        masked_fill_4: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_7, to_71, -3.4028234663852886e+38);  rsub_7 = to_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_9: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_21);  unsqueeze_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_72: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_9, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_9 = None
        add_125: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_56, to_72);  mul_56 = to_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_136: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_125, 0.1, False);  add_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_18: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_19: "f32[20, 64]" = torch.ops.aten.select.int(select_18, 0, 0);  select_18 = None
        any_8: "b8[20]" = torch.ops.aten.any.dim(select_19, -1);  select_19 = None
        sum_6: "i64[]" = torch.ops.aten.sum.default(any_8);  any_8 = sum_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_9: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_10: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_45: "i64[1, 1]" = torch.ops.aten.reshape.default(add_122, [-1, 1])
        gt_3: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_10, reshape_45);  arange_10 = reshape_45 = None
        mul__3: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_9, gt_3);  full_9 = gt_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_24: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__3, 0);  mul__3 = None
        unsqueeze_25: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_24, 1);  unsqueeze_24 = None
        slice_431: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_25, 2, 0, 9223372036854775807);  unsqueeze_25 = None
        slice_432: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_431, 3, 0, 9223372036854775807);  slice_431 = None
        expand_8: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_432, [1, 1, -1, -1]);  slice_432 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_195: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_136, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_57: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_195, 0.125);  linear_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_107: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_57, [1, 1, 8, 64]);  mul_57 = None
        transpose_186: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_107, 1, 2);  view_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_196: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_136, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_108: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_196, [1, -1, 8, 64]);  linear_196 = None
        transpose_187: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_108, 1, 2);  view_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_197: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_136, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_109: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_197, [1, -1, 8, 64]);  linear_197 = None
        transpose_188: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_109, 1, 2);  view_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_73: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_187, torch.float32);  transpose_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_74: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_188, torch.float32);  transpose_188 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_433: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__48: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_433, 2, add_122, to_73);  slice_433 = to_73 = index_copy__48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_434: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__49: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_434, 2, add_122, to_74);  slice_434 = to_74 = index_copy__49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_435: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_436: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_435, 2, 0, 9223372036854775807);  slice_435 = None
        slice_437: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_436, 3, 0, 9223372036854775807);  slice_436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_438: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_439: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_438, 2, 0, 9223372036854775807);  slice_438 = None
        slice_440: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_439, 3, 0, 9223372036854775807);  slice_439 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_189: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_437, 2, 3);  slice_437 = None
        matmul_84: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_186, transpose_189);  transpose_186 = transpose_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_441: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_8, 0, 0, 9223372036854775807)
        slice_442: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_441, 1, 0, 9223372036854775807);  slice_441 = None
        slice_443: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_442, 2, 0, 9223372036854775807);  slice_442 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_126: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_84, slice_443);  matmul_84 = slice_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_42: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_126, -1);  add_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_137: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_42, 0.0, False);  softmax_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_85: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_137, slice_440);  dropout_137 = slice_440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_190: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_85, 1, 2);  matmul_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_46: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_190, [1, 1, 512]);  transpose_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_198: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_46, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_138: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_198, 0.1, False);  linear_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_127: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_136, dropout_138);  dropout_136 = dropout_138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_66: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_127, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_199: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_66, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_58: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_199, 0.125);  linear_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_110: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_58, [1, 1, 8, 64]);  mul_58 = None
        transpose_191: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_110, 1, 2);  view_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_444: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_445: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_444, 2, 0, 23);  slice_444 = None
        slice_446: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_445, 3, 0, 9223372036854775807);  slice_445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_447: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_448: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_447, 2, 0, 23);  slice_447 = None
        slice_449: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_448, 3, 0, 9223372036854775807);  slice_448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_192: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_446, 2, 3);  slice_446 = None
        matmul_86: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_191, transpose_192);  transpose_191 = transpose_192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_450: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_4, 0, 0, 9223372036854775807)
        slice_451: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_450, 1, 0, 9223372036854775807);  slice_450 = None
        slice_452: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_451, 2, 0, 9223372036854775807);  slice_451 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_128: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_86, slice_452);  matmul_86 = slice_452 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_43: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_128, -1);  add_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_139: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_43, 0.0, False);  softmax_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_87: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_139, slice_449);  dropout_139 = slice_449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_193: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_87, 1, 2);  matmul_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_47: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_193, [1, 1, 512]);  transpose_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_200: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_47, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_140: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_200, 0.1, False);  linear_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_129: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_66, dropout_140);  layer_norm_66 = dropout_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_67: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_129, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_201: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_67, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_24: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_201);  linear_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_141: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_24, 0.0, False);  silu_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_202: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_141, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_142: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_202, 0.1, False);  linear_202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_130: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_67, dropout_142);  layer_norm_67 = dropout_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_68: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_130, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_203: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_68, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_59: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_203, 0.125);  linear_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_111: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_59, [1, 1, 8, 64]);  mul_59 = None
        transpose_194: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_111, 1, 2);  view_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_204: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_68, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_112: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_204, [1, -1, 8, 64]);  linear_204 = None
        transpose_195: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_112, 1, 2);  view_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_205: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_68, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_113: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_205, [1, -1, 8, 64]);  linear_205 = None
        transpose_196: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_113, 1, 2);  view_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_75: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_195, torch.float32);  transpose_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_76: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_196, torch.float32);  transpose_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_453: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__50: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_453, 2, add_122, to_75);  slice_453 = to_75 = index_copy__50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_454: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__51: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_454, 2, add_122, to_76);  slice_454 = to_76 = index_copy__51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_455: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_456: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_455, 2, 0, 9223372036854775807);  slice_455 = None
        slice_457: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_456, 3, 0, 9223372036854775807);  slice_456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_458: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_459: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_458, 2, 0, 9223372036854775807);  slice_458 = None
        slice_460: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_459, 3, 0, 9223372036854775807);  slice_459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_197: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_457, 2, 3);  slice_457 = None
        matmul_88: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_194, transpose_197);  transpose_194 = transpose_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_461: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_8, 0, 0, 9223372036854775807)
        slice_462: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_461, 1, 0, 9223372036854775807);  slice_461 = None
        slice_463: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_462, 2, 0, 9223372036854775807);  slice_462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_131: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_88, slice_463);  matmul_88 = slice_463 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_44: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_131, -1);  add_131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_143: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_44, 0.0, False);  softmax_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_89: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_143, slice_460);  dropout_143 = slice_460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_198: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_89, 1, 2);  matmul_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_48: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_198, [1, 1, 512]);  transpose_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_206: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_48, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_144: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_206, 0.1, False);  linear_206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_132: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_68, dropout_144);  layer_norm_68 = dropout_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_69: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_132, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_207: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_69, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_60: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_207, 0.125);  linear_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_114: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_60, [1, 1, 8, 64]);  mul_60 = None
        transpose_199: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_114, 1, 2);  view_114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_464: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_465: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_464, 2, 0, 23);  slice_464 = None
        slice_466: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_465, 3, 0, 9223372036854775807);  slice_465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_467: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_468: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_467, 2, 0, 23);  slice_467 = None
        slice_469: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_468, 3, 0, 9223372036854775807);  slice_468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_200: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_466, 2, 3);  slice_466 = None
        matmul_90: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_199, transpose_200);  transpose_199 = transpose_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_470: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_4, 0, 0, 9223372036854775807)
        slice_471: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_470, 1, 0, 9223372036854775807);  slice_470 = None
        slice_472: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_471, 2, 0, 9223372036854775807);  slice_471 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_133: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_90, slice_472);  matmul_90 = slice_472 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_45: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_133, -1);  add_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_145: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_45, 0.0, False);  softmax_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_91: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_145, slice_469);  dropout_145 = slice_469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_201: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_91, 1, 2);  matmul_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_49: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_201, [1, 1, 512]);  transpose_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_208: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_49, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_146: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_208, 0.1, False);  linear_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_134: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_69, dropout_146);  layer_norm_69 = dropout_146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_70: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_134, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_209: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_70, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_25: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_209);  linear_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_147: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_25, 0.0, False);  silu_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_210: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_147, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_148: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_210, 0.1, False);  linear_210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_135: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_70, dropout_148);  layer_norm_70 = dropout_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_71: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_135, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_211: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_71, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_61: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_211, 0.125);  linear_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_115: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_61, [1, 1, 8, 64]);  mul_61 = None
        transpose_202: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_115, 1, 2);  view_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_212: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_71, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_116: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_212, [1, -1, 8, 64]);  linear_212 = None
        transpose_203: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_116, 1, 2);  view_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_213: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_71, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_117: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_213, [1, -1, 8, 64]);  linear_213 = None
        transpose_204: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_117, 1, 2);  view_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_77: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_203, torch.float32);  transpose_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_78: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_204, torch.float32);  transpose_204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_473: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__52: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_473, 2, add_122, to_77);  slice_473 = to_77 = index_copy__52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_474: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__53: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_474, 2, add_122, to_78);  slice_474 = to_78 = index_copy__53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_475: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_476: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_475, 2, 0, 9223372036854775807);  slice_475 = None
        slice_477: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_476, 3, 0, 9223372036854775807);  slice_476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_478: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_479: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_478, 2, 0, 9223372036854775807);  slice_478 = None
        slice_480: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_479, 3, 0, 9223372036854775807);  slice_479 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_205: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_477, 2, 3);  slice_477 = None
        matmul_92: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_202, transpose_205);  transpose_202 = transpose_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_481: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_8, 0, 0, 9223372036854775807)
        slice_482: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_481, 1, 0, 9223372036854775807);  slice_481 = None
        slice_483: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_482, 2, 0, 9223372036854775807);  slice_482 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_136: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_92, slice_483);  matmul_92 = slice_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_46: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_136, -1);  add_136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_149: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_46, 0.0, False);  softmax_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_93: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_149, slice_480);  dropout_149 = slice_480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_206: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_93, 1, 2);  matmul_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_50: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_206, [1, 1, 512]);  transpose_206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_214: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_50, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_150: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_214, 0.1, False);  linear_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_137: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_71, dropout_150);  layer_norm_71 = dropout_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_72: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_137, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_215: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_72, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_62: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_215, 0.125);  linear_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_118: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_62, [1, 1, 8, 64]);  mul_62 = None
        transpose_207: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_118, 1, 2);  view_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_484: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_485: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_484, 2, 0, 23);  slice_484 = None
        slice_486: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_485, 3, 0, 9223372036854775807);  slice_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_487: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_488: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_487, 2, 0, 23);  slice_487 = None
        slice_489: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_488, 3, 0, 9223372036854775807);  slice_488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_208: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_486, 2, 3);  slice_486 = None
        matmul_94: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_207, transpose_208);  transpose_207 = transpose_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_490: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_4, 0, 0, 9223372036854775807)
        slice_491: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_490, 1, 0, 9223372036854775807);  slice_490 = None
        slice_492: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_491, 2, 0, 9223372036854775807);  slice_491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_138: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_94, slice_492);  matmul_94 = slice_492 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_47: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_138, -1);  add_138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_151: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_47, 0.0, False);  softmax_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_95: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_151, slice_489);  dropout_151 = slice_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_209: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_95, 1, 2);  matmul_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_51: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_209, [1, 1, 512]);  transpose_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_216: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_51, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_152: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_216, 0.1, False);  linear_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_139: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_72, dropout_152);  layer_norm_72 = dropout_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_73: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_139, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_217: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_73, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_26: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_217);  linear_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_153: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_26, 0.0, False);  silu_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_218: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_153, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_154: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_218, 0.1, False);  linear_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_140: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_73, dropout_154);  layer_norm_73 = dropout_154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_74: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_140, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_219: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_74, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_63: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_219, 0.125);  linear_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_119: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_63, [1, 1, 8, 64]);  mul_63 = None
        transpose_210: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_119, 1, 2);  view_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_220: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_74, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_120: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_220, [1, -1, 8, 64]);  linear_220 = None
        transpose_211: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_120, 1, 2);  view_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_221: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_74, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_121: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_221, [1, -1, 8, 64]);  linear_221 = None
        transpose_212: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_121, 1, 2);  view_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_79: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_211, torch.float32);  transpose_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_80: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_212, torch.float32);  transpose_212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_493: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__54: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_493, 2, add_122, to_79);  slice_493 = to_79 = index_copy__54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_494: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__55: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_494, 2, add_122, to_80);  slice_494 = to_80 = index_copy__55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_495: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_496: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_495, 2, 0, 9223372036854775807);  slice_495 = None
        slice_497: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_496, 3, 0, 9223372036854775807);  slice_496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_498: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_499: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_498, 2, 0, 9223372036854775807);  slice_498 = None
        slice_500: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_499, 3, 0, 9223372036854775807);  slice_499 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_213: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_497, 2, 3);  slice_497 = None
        matmul_96: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_210, transpose_213);  transpose_210 = transpose_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_501: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_8, 0, 0, 9223372036854775807)
        slice_502: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_501, 1, 0, 9223372036854775807);  slice_501 = None
        slice_503: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_502, 2, 0, 9223372036854775807);  slice_502 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_141: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_96, slice_503);  matmul_96 = slice_503 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_48: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_141, -1);  add_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_155: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_48, 0.0, False);  softmax_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_97: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_155, slice_500);  dropout_155 = slice_500 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_214: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_97, 1, 2);  matmul_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_52: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_214, [1, 1, 512]);  transpose_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_222: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_52, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_156: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_222, 0.1, False);  linear_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_142: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_74, dropout_156);  layer_norm_74 = dropout_156 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_75: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_142, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_223: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_75, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_64: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_223, 0.125);  linear_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_122: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_64, [1, 1, 8, 64]);  mul_64 = None
        transpose_215: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_122, 1, 2);  view_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_504: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_505: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_504, 2, 0, 23);  slice_504 = None
        slice_506: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_505, 3, 0, 9223372036854775807);  slice_505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_507: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_508: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_507, 2, 0, 23);  slice_507 = None
        slice_509: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_508, 3, 0, 9223372036854775807);  slice_508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_216: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_506, 2, 3);  slice_506 = None
        matmul_98: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_215, transpose_216);  transpose_215 = transpose_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_510: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_4, 0, 0, 9223372036854775807)
        slice_511: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_510, 1, 0, 9223372036854775807);  slice_510 = None
        slice_512: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_511, 2, 0, 9223372036854775807);  slice_511 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_143: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_98, slice_512);  matmul_98 = slice_512 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_49: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_143, -1);  add_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_157: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_49, 0.0, False);  softmax_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_99: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_157, slice_509);  dropout_157 = slice_509 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_217: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_99, 1, 2);  matmul_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_53: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_217, [1, 1, 512]);  transpose_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_224: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_53, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_158: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_224, 0.1, False);  linear_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_144: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_75, dropout_158);  layer_norm_75 = dropout_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_76: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_144, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_225: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_76, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_27: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_225);  linear_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_159: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_27, 0.0, False);  silu_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_226: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_159, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_160: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_226, 0.1, False);  linear_226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_145: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_76, dropout_160);  layer_norm_76 = dropout_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_77: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_145, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_227: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_77, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_65: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_227, 0.125);  linear_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_123: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_65, [1, 1, 8, 64]);  mul_65 = None
        transpose_218: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_123, 1, 2);  view_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_228: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_77, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_124: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_228, [1, -1, 8, 64]);  linear_228 = None
        transpose_219: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_124, 1, 2);  view_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_229: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_77, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_125: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_229, [1, -1, 8, 64]);  linear_229 = None
        transpose_220: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_125, 1, 2);  view_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_81: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_219, torch.float32);  transpose_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_82: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_220, torch.float32);  transpose_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_513: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__56: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_513, 2, add_122, to_81);  slice_513 = to_81 = index_copy__56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_514: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__57: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_514, 2, add_122, to_82);  slice_514 = to_82 = index_copy__57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_515: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_516: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_515, 2, 0, 9223372036854775807);  slice_515 = None
        slice_517: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_516, 3, 0, 9223372036854775807);  slice_516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_518: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_519: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_518, 2, 0, 9223372036854775807);  slice_518 = None
        slice_520: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_519, 3, 0, 9223372036854775807);  slice_519 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_221: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_517, 2, 3);  slice_517 = None
        matmul_100: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_218, transpose_221);  transpose_218 = transpose_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_521: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_8, 0, 0, 9223372036854775807)
        slice_522: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_521, 1, 0, 9223372036854775807);  slice_521 = None
        slice_523: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_522, 2, 0, 9223372036854775807);  slice_522 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_146: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_100, slice_523);  matmul_100 = slice_523 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_50: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_146, -1);  add_146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_161: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_50, 0.0, False);  softmax_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_101: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_161, slice_520);  dropout_161 = slice_520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_222: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_101, 1, 2);  matmul_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_54: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_222, [1, 1, 512]);  transpose_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_230: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_54, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_162: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_230, 0.1, False);  linear_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_147: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_77, dropout_162);  layer_norm_77 = dropout_162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_78: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_147, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_231: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_78, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_66: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_231, 0.125);  linear_231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_126: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_66, [1, 1, 8, 64]);  mul_66 = None
        transpose_223: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_126, 1, 2);  view_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_524: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_525: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_524, 2, 0, 23);  slice_524 = None
        slice_526: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_525, 3, 0, 9223372036854775807);  slice_525 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_527: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_528: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_527, 2, 0, 23);  slice_527 = None
        slice_529: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_528, 3, 0, 9223372036854775807);  slice_528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_224: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_526, 2, 3);  slice_526 = None
        matmul_102: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_223, transpose_224);  transpose_223 = transpose_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_530: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_4, 0, 0, 9223372036854775807)
        slice_531: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_530, 1, 0, 9223372036854775807);  slice_530 = None
        slice_532: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_531, 2, 0, 9223372036854775807);  slice_531 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_148: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_102, slice_532);  matmul_102 = slice_532 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_51: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_148, -1);  add_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_163: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_51, 0.0, False);  softmax_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_103: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_163, slice_529);  dropout_163 = slice_529 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_225: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_103, 1, 2);  matmul_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_55: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_225, [1, 1, 512]);  transpose_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_232: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_55, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_164: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_232, 0.1, False);  linear_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_149: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_78, dropout_164);  layer_norm_78 = dropout_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_79: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_149, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_233: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_79, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_28: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_233);  linear_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_165: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_28, 0.0, False);  silu_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_234: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_165, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_166: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_234, 0.1, False);  linear_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_150: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_79, dropout_166);  layer_norm_79 = dropout_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_80: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_150, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_235: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_80, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_67: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_235, 0.125);  linear_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_127: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_67, [1, 1, 8, 64]);  mul_67 = None
        transpose_226: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_127, 1, 2);  view_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_236: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_80, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_128: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_236, [1, -1, 8, 64]);  linear_236 = None
        transpose_227: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_128, 1, 2);  view_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_237: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_80, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_129: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_237, [1, -1, 8, 64]);  linear_237 = None
        transpose_228: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_129, 1, 2);  view_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_83: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_227, torch.float32);  transpose_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_84: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_228, torch.float32);  transpose_228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_533: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__58: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_533, 2, add_122, to_83);  slice_533 = to_83 = index_copy__58 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_534: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__59: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_534, 2, add_122, to_84);  slice_534 = to_84 = index_copy__59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_535: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_536: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_535, 2, 0, 9223372036854775807);  slice_535 = None
        slice_537: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_536, 3, 0, 9223372036854775807);  slice_536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_538: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_539: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_538, 2, 0, 9223372036854775807);  slice_538 = None
        slice_540: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_539, 3, 0, 9223372036854775807);  slice_539 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_229: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_537, 2, 3);  slice_537 = None
        matmul_104: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_226, transpose_229);  transpose_226 = transpose_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_541: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_8, 0, 0, 9223372036854775807);  expand_8 = None
        slice_542: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_541, 1, 0, 9223372036854775807);  slice_541 = None
        slice_543: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_542, 2, 0, 9223372036854775807);  slice_542 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_151: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_104, slice_543);  matmul_104 = slice_543 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_52: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_151, -1);  add_151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_167: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_52, 0.0, False);  softmax_52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_105: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_167, slice_540);  dropout_167 = slice_540 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_230: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_105, 1, 2);  matmul_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_56: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_230, [1, 1, 512]);  transpose_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_238: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_56, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_168: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_238, 0.1, False);  linear_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_152: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_80, dropout_168);  layer_norm_80 = dropout_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_81: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_152, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_239: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_81, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_68: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_239, 0.125);  linear_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_130: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_68, [1, 1, 8, 64]);  mul_68 = None
        transpose_231: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_130, 1, 2);  view_130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_544: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_545: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_544, 2, 0, 23);  slice_544 = None
        slice_546: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_545, 3, 0, 9223372036854775807);  slice_545 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_547: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_548: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_547, 2, 0, 23);  slice_547 = None
        slice_549: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_548, 3, 0, 9223372036854775807);  slice_548 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_232: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_546, 2, 3);  slice_546 = None
        matmul_106: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_231, transpose_232);  transpose_231 = transpose_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_550: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_4, 0, 0, 9223372036854775807);  masked_fill_4 = None
        slice_551: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_550, 1, 0, 9223372036854775807);  slice_550 = None
        slice_552: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_551, 2, 0, 9223372036854775807);  slice_551 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_153: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_106, slice_552);  matmul_106 = slice_552 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_53: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_153, -1);  add_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_169: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_53, 0.0, False);  softmax_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_107: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_169, slice_549);  dropout_169 = slice_549 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_233: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_107, 1, 2);  matmul_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_57: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_233, [1, 1, 512]);  transpose_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_240: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_57, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_170: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_240, 0.1, False);  linear_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_154: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_81, dropout_170);  layer_norm_81 = dropout_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_82: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_154, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_241: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_82, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_29: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_241);  linear_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_171: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_29, 0.0, False);  silu_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_242: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_171, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_172: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_242, 0.1, False);  linear_242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_155: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_82, dropout_172);  layer_norm_82 = dropout_172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_83: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_155, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_243: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_83, p_model_lm_head_weight);  layer_norm_83 = None
        add_156: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_243, b_model_final_logits_bias);  linear_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_553: "i64[1]" = torch.ops.aten.slice.Tensor(add_122, 0, -1, 9223372036854775807);  add_122 = None
        add_157: "i64[1]" = torch.ops.aten.add.Tensor(slice_553, 1);  slice_553 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_554: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_156, 0, 0, 9223372036854775807);  add_156 = None
        select_20: "f32[1, 59514]" = torch.ops.aten.select.int(slice_554, 1, -1);  slice_554 = None
        slice_555: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_20, 1, 0, 9223372036854775807);  select_20 = None
        clone_7: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_555);  slice_555 = None
        to_85: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_7, torch.float32);  clone_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_86: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_85, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_3: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_86, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__3: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_3, to_32);  zeros_like_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_158: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_86, add__3);  to_86 = add__3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_3: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_158, -1);  add_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_3: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_3, -1);  log_softmax_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_69: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_3, and_3);  argmax_3 = None
        rsub_8: "i64[1]" = torch.ops.aten.rsub.Scalar(and_3, 1)
        mul_70: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_8);  rsub_8 = None
        add_159: "i64[1]" = torch.ops.aten.add.Tensor(mul_69, mul_70);  mul_69 = mul_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_556: "i64[1]" = torch.ops.aten.slice.Tensor(add_159, 0, 0, 9223372036854775807);  add_159 = None
        unsqueeze_26: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_556, 1);  slice_556 = None
        cat_3: "i64[1, 5]" = torch.ops.aten.cat.default([cat_2, unsqueeze_26], -1);  cat_2 = unsqueeze_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_10: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_11: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_7: "b8[1]" = torch.ops.aten.__or__.Tensor(full_10, full_11);  full_10 = full_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_87: "i64[1]" = torch.ops.aten.to.dtype_layout(to_69, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_557: "i64[1, 5]" = torch.ops.aten.slice.Tensor(cat_3, 0, 0, 9223372036854775807)
        select_21: "i64[1]" = torch.ops.aten.select.int(slice_557, 1, -1);  slice_557 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_5: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_21, to_87);  select_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_8: "b8[1]" = torch.ops.aten.__or__.Tensor(or_7, isin_5);  or_7 = isin_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_5: "b8[1]" = torch.ops.aten.bitwise_not.default(or_8);  or_8 = None
        and_4: "i64[1]" = torch.ops.aten.__and__.Tensor(and_3, bitwise_not_5);  and_3 = bitwise_not_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_4: "i64[]" = torch.ops.aten.max.default(and_4)
        eq_3: "b8[]" = torch.ops.aten.eq.Scalar(max_4, 0);  max_4 = eq_3 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_558: "i64[1, 5]" = torch.ops.aten.slice.Tensor(cat_3, 0, 0, 9223372036854775807)
        slice_559: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_558, 1, -1, 9223372036854775807);  slice_558 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_8: "i64[1, 1]" = torch.ops.aten.clone.default(slice_559, memory_format = torch.contiguous_format);  slice_559 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_131: "i64[1, 1]" = torch.ops.aten.view.default(clone_8, [-1, 1]);  clone_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_10: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_131, 59513);  view_131 = None
        mul_71: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_10, 22.627416997969522);  embedding_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_27: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_157, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_560: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_28: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_560, 1);  slice_560 = None
        unsqueeze_29: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_28, 2);  unsqueeze_28 = None
        slice_561: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_29, 3, 0, 9223372036854775807);  unsqueeze_29 = None
        expand_9: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_561, [1, 1, 1, 23]);  slice_561 = None
        to_88: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_9, torch.float32);  expand_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_9: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_88, 1.0);  to_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_89: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_9, torch.bool)
        masked_fill_5: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_9, to_89, -3.4028234663852886e+38);  rsub_9 = to_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_11: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_27);  unsqueeze_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_90: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_11, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_11 = None
        add_160: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_71, to_90);  mul_71 = to_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_173: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_160, 0.1, False);  add_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_22: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_23: "f32[20, 64]" = torch.ops.aten.select.int(select_22, 0, 0);  select_22 = None
        any_9: "b8[20]" = torch.ops.aten.any.dim(select_23, -1);  select_23 = None
        sum_7: "i64[]" = torch.ops.aten.sum.default(any_9);  any_9 = sum_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_12: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_11: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_58: "i64[1, 1]" = torch.ops.aten.reshape.default(add_157, [-1, 1])
        gt_4: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_11, reshape_58);  arange_11 = reshape_58 = None
        mul__4: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_12, gt_4);  full_12 = gt_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_30: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__4, 0);  mul__4 = None
        unsqueeze_31: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_30, 1);  unsqueeze_30 = None
        slice_562: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_31, 2, 0, 9223372036854775807);  unsqueeze_31 = None
        slice_563: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_562, 3, 0, 9223372036854775807);  slice_562 = None
        expand_10: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_563, [1, 1, -1, -1]);  slice_563 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_244: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_173, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_72: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_244, 0.125);  linear_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_132: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_72, [1, 1, 8, 64]);  mul_72 = None
        transpose_234: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_132, 1, 2);  view_132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_245: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_173, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_133: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_245, [1, -1, 8, 64]);  linear_245 = None
        transpose_235: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_133, 1, 2);  view_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_246: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_173, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_134: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_246, [1, -1, 8, 64]);  linear_246 = None
        transpose_236: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_134, 1, 2);  view_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_91: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_235, torch.float32);  transpose_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_92: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_236, torch.float32);  transpose_236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_564: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__60: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_564, 2, add_157, to_91);  slice_564 = to_91 = index_copy__60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_565: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__61: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_565, 2, add_157, to_92);  slice_565 = to_92 = index_copy__61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_566: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_567: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_566, 2, 0, 9223372036854775807);  slice_566 = None
        slice_568: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_567, 3, 0, 9223372036854775807);  slice_567 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_569: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_570: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_569, 2, 0, 9223372036854775807);  slice_569 = None
        slice_571: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_570, 3, 0, 9223372036854775807);  slice_570 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_237: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_568, 2, 3);  slice_568 = None
        matmul_108: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_234, transpose_237);  transpose_234 = transpose_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_572: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_10, 0, 0, 9223372036854775807)
        slice_573: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_572, 1, 0, 9223372036854775807);  slice_572 = None
        slice_574: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_573, 2, 0, 9223372036854775807);  slice_573 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_161: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_108, slice_574);  matmul_108 = slice_574 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_54: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_161, -1);  add_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_174: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_54, 0.0, False);  softmax_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_109: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_174, slice_571);  dropout_174 = slice_571 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_238: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_109, 1, 2);  matmul_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_59: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_238, [1, 1, 512]);  transpose_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_247: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_59, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_175: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_247, 0.1, False);  linear_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_162: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_173, dropout_175);  dropout_173 = dropout_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_84: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_162, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_248: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_84, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_73: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_248, 0.125);  linear_248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_135: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_73, [1, 1, 8, 64]);  mul_73 = None
        transpose_239: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_135, 1, 2);  view_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_575: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_576: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_575, 2, 0, 23);  slice_575 = None
        slice_577: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_576, 3, 0, 9223372036854775807);  slice_576 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_578: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_579: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_578, 2, 0, 23);  slice_578 = None
        slice_580: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_579, 3, 0, 9223372036854775807);  slice_579 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_240: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_577, 2, 3);  slice_577 = None
        matmul_110: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_239, transpose_240);  transpose_239 = transpose_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_581: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_5, 0, 0, 9223372036854775807)
        slice_582: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_581, 1, 0, 9223372036854775807);  slice_581 = None
        slice_583: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_582, 2, 0, 9223372036854775807);  slice_582 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_163: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_110, slice_583);  matmul_110 = slice_583 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_55: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_163, -1);  add_163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_176: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_55, 0.0, False);  softmax_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_111: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_176, slice_580);  dropout_176 = slice_580 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_241: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_111, 1, 2);  matmul_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_60: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_241, [1, 1, 512]);  transpose_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_249: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_60, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_177: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_249, 0.1, False);  linear_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_164: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_84, dropout_177);  layer_norm_84 = dropout_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_85: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_164, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_250: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_85, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_30: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_250);  linear_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_178: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_30, 0.0, False);  silu_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_251: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_178, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_179: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_251, 0.1, False);  linear_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_165: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_85, dropout_179);  layer_norm_85 = dropout_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_86: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_165, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_252: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_86, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_74: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_252, 0.125);  linear_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_136: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_74, [1, 1, 8, 64]);  mul_74 = None
        transpose_242: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_136, 1, 2);  view_136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_253: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_86, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_137: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_253, [1, -1, 8, 64]);  linear_253 = None
        transpose_243: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_137, 1, 2);  view_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_254: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_86, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_138: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_254, [1, -1, 8, 64]);  linear_254 = None
        transpose_244: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_138, 1, 2);  view_138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_93: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_243, torch.float32);  transpose_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_94: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_244, torch.float32);  transpose_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_584: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__62: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_584, 2, add_157, to_93);  slice_584 = to_93 = index_copy__62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_585: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__63: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_585, 2, add_157, to_94);  slice_585 = to_94 = index_copy__63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_586: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_587: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_586, 2, 0, 9223372036854775807);  slice_586 = None
        slice_588: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_587, 3, 0, 9223372036854775807);  slice_587 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_589: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_590: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_589, 2, 0, 9223372036854775807);  slice_589 = None
        slice_591: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_590, 3, 0, 9223372036854775807);  slice_590 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_245: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_588, 2, 3);  slice_588 = None
        matmul_112: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_242, transpose_245);  transpose_242 = transpose_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_592: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_10, 0, 0, 9223372036854775807)
        slice_593: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_592, 1, 0, 9223372036854775807);  slice_592 = None
        slice_594: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_593, 2, 0, 9223372036854775807);  slice_593 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_166: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_112, slice_594);  matmul_112 = slice_594 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_56: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_166, -1);  add_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_180: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_56, 0.0, False);  softmax_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_113: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_180, slice_591);  dropout_180 = slice_591 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_246: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_113, 1, 2);  matmul_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_61: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_246, [1, 1, 512]);  transpose_246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_255: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_61, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_181: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_255, 0.1, False);  linear_255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_167: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_86, dropout_181);  layer_norm_86 = dropout_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_87: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_167, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_256: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_87, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_75: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_256, 0.125);  linear_256 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_139: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_75, [1, 1, 8, 64]);  mul_75 = None
        transpose_247: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_139, 1, 2);  view_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_595: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_596: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_595, 2, 0, 23);  slice_595 = None
        slice_597: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_596, 3, 0, 9223372036854775807);  slice_596 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_598: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_599: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_598, 2, 0, 23);  slice_598 = None
        slice_600: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_599, 3, 0, 9223372036854775807);  slice_599 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_248: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_597, 2, 3);  slice_597 = None
        matmul_114: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_247, transpose_248);  transpose_247 = transpose_248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_601: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_5, 0, 0, 9223372036854775807)
        slice_602: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_601, 1, 0, 9223372036854775807);  slice_601 = None
        slice_603: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_602, 2, 0, 9223372036854775807);  slice_602 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_168: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_114, slice_603);  matmul_114 = slice_603 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_57: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_168, -1);  add_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_182: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_57, 0.0, False);  softmax_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_115: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_182, slice_600);  dropout_182 = slice_600 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_249: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_115, 1, 2);  matmul_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_62: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_249, [1, 1, 512]);  transpose_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_257: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_62, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_183: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_257, 0.1, False);  linear_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_169: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_87, dropout_183);  layer_norm_87 = dropout_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_88: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_169, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_258: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_88, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_31: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_258);  linear_258 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_184: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_31, 0.0, False);  silu_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_259: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_184, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_185: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_259, 0.1, False);  linear_259 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_170: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_88, dropout_185);  layer_norm_88 = dropout_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_89: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_170, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_260: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_89, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_76: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_260, 0.125);  linear_260 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_140: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_76, [1, 1, 8, 64]);  mul_76 = None
        transpose_250: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_140, 1, 2);  view_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_261: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_89, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_141: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_261, [1, -1, 8, 64]);  linear_261 = None
        transpose_251: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_141, 1, 2);  view_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_262: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_89, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_142: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_262, [1, -1, 8, 64]);  linear_262 = None
        transpose_252: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_142, 1, 2);  view_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_95: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_251, torch.float32);  transpose_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_96: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_252, torch.float32);  transpose_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_604: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__64: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_604, 2, add_157, to_95);  slice_604 = to_95 = index_copy__64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_605: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__65: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_605, 2, add_157, to_96);  slice_605 = to_96 = index_copy__65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_606: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_607: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_606, 2, 0, 9223372036854775807);  slice_606 = None
        slice_608: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_607, 3, 0, 9223372036854775807);  slice_607 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_609: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_610: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_609, 2, 0, 9223372036854775807);  slice_609 = None
        slice_611: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_610, 3, 0, 9223372036854775807);  slice_610 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_253: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_608, 2, 3);  slice_608 = None
        matmul_116: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_250, transpose_253);  transpose_250 = transpose_253 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_612: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_10, 0, 0, 9223372036854775807)
        slice_613: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_612, 1, 0, 9223372036854775807);  slice_612 = None
        slice_614: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_613, 2, 0, 9223372036854775807);  slice_613 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_171: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_116, slice_614);  matmul_116 = slice_614 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_58: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_171, -1);  add_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_186: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_58, 0.0, False);  softmax_58 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_117: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_186, slice_611);  dropout_186 = slice_611 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_254: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_117, 1, 2);  matmul_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_63: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_254, [1, 1, 512]);  transpose_254 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_263: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_63, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_187: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_263, 0.1, False);  linear_263 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_172: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_89, dropout_187);  layer_norm_89 = dropout_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_90: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_172, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_264: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_90, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_77: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_264, 0.125);  linear_264 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_143: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_77, [1, 1, 8, 64]);  mul_77 = None
        transpose_255: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_143, 1, 2);  view_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_615: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_616: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_615, 2, 0, 23);  slice_615 = None
        slice_617: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_616, 3, 0, 9223372036854775807);  slice_616 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_618: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_619: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_618, 2, 0, 23);  slice_618 = None
        slice_620: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_619, 3, 0, 9223372036854775807);  slice_619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_256: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_617, 2, 3);  slice_617 = None
        matmul_118: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_255, transpose_256);  transpose_255 = transpose_256 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_621: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_5, 0, 0, 9223372036854775807)
        slice_622: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_621, 1, 0, 9223372036854775807);  slice_621 = None
        slice_623: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_622, 2, 0, 9223372036854775807);  slice_622 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_173: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_118, slice_623);  matmul_118 = slice_623 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_59: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_173, -1);  add_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_188: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_59, 0.0, False);  softmax_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_119: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_188, slice_620);  dropout_188 = slice_620 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_257: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_119, 1, 2);  matmul_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_64: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_257, [1, 1, 512]);  transpose_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_265: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_64, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_189: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_265, 0.1, False);  linear_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_174: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_90, dropout_189);  layer_norm_90 = dropout_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_91: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_174, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_266: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_91, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_32: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_266);  linear_266 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_190: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_32, 0.0, False);  silu_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_267: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_190, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_191: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_267, 0.1, False);  linear_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_175: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_91, dropout_191);  layer_norm_91 = dropout_191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_92: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_175, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_268: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_92, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_78: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_268, 0.125);  linear_268 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_144: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_78, [1, 1, 8, 64]);  mul_78 = None
        transpose_258: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_144, 1, 2);  view_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_269: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_92, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_145: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_269, [1, -1, 8, 64]);  linear_269 = None
        transpose_259: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_145, 1, 2);  view_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_270: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_92, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_146: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_270, [1, -1, 8, 64]);  linear_270 = None
        transpose_260: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_146, 1, 2);  view_146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_97: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_259, torch.float32);  transpose_259 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_98: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_260, torch.float32);  transpose_260 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_624: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__66: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_624, 2, add_157, to_97);  slice_624 = to_97 = index_copy__66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_625: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__67: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_625, 2, add_157, to_98);  slice_625 = to_98 = index_copy__67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_626: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_627: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_626, 2, 0, 9223372036854775807);  slice_626 = None
        slice_628: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_627, 3, 0, 9223372036854775807);  slice_627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_629: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_630: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_629, 2, 0, 9223372036854775807);  slice_629 = None
        slice_631: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_630, 3, 0, 9223372036854775807);  slice_630 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_261: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_628, 2, 3);  slice_628 = None
        matmul_120: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_258, transpose_261);  transpose_258 = transpose_261 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_632: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_10, 0, 0, 9223372036854775807)
        slice_633: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_632, 1, 0, 9223372036854775807);  slice_632 = None
        slice_634: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_633, 2, 0, 9223372036854775807);  slice_633 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_176: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_120, slice_634);  matmul_120 = slice_634 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_60: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_176, -1);  add_176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_192: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_60, 0.0, False);  softmax_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_121: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_192, slice_631);  dropout_192 = slice_631 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_262: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_121, 1, 2);  matmul_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_65: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_262, [1, 1, 512]);  transpose_262 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_271: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_65, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_193: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_271, 0.1, False);  linear_271 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_177: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_92, dropout_193);  layer_norm_92 = dropout_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_93: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_177, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_272: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_93, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_79: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_272, 0.125);  linear_272 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_147: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_79, [1, 1, 8, 64]);  mul_79 = None
        transpose_263: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_147, 1, 2);  view_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_635: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_636: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_635, 2, 0, 23);  slice_635 = None
        slice_637: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_636, 3, 0, 9223372036854775807);  slice_636 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_638: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_639: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_638, 2, 0, 23);  slice_638 = None
        slice_640: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_639, 3, 0, 9223372036854775807);  slice_639 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_264: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_637, 2, 3);  slice_637 = None
        matmul_122: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_263, transpose_264);  transpose_263 = transpose_264 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_641: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_5, 0, 0, 9223372036854775807)
        slice_642: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_641, 1, 0, 9223372036854775807);  slice_641 = None
        slice_643: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_642, 2, 0, 9223372036854775807);  slice_642 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_178: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_122, slice_643);  matmul_122 = slice_643 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_61: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_178, -1);  add_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_194: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_61, 0.0, False);  softmax_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_123: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_194, slice_640);  dropout_194 = slice_640 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_265: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_123, 1, 2);  matmul_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_66: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_265, [1, 1, 512]);  transpose_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_273: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_66, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_195: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_273, 0.1, False);  linear_273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_179: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_93, dropout_195);  layer_norm_93 = dropout_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_94: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_179, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_274: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_94, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_33: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_274);  linear_274 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_196: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_33, 0.0, False);  silu_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_275: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_196, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_197: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_275, 0.1, False);  linear_275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_180: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_94, dropout_197);  layer_norm_94 = dropout_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_95: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_180, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_276: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_95, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_80: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_276, 0.125);  linear_276 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_148: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_80, [1, 1, 8, 64]);  mul_80 = None
        transpose_266: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_148, 1, 2);  view_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_277: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_95, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_149: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_277, [1, -1, 8, 64]);  linear_277 = None
        transpose_267: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_149, 1, 2);  view_149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_278: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_95, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_150: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_278, [1, -1, 8, 64]);  linear_278 = None
        transpose_268: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_150, 1, 2);  view_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_99: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_267, torch.float32);  transpose_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_100: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_268, torch.float32);  transpose_268 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_644: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__68: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_644, 2, add_157, to_99);  slice_644 = to_99 = index_copy__68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_645: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__69: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_645, 2, add_157, to_100);  slice_645 = to_100 = index_copy__69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_646: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_647: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_646, 2, 0, 9223372036854775807);  slice_646 = None
        slice_648: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_647, 3, 0, 9223372036854775807);  slice_647 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_649: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_650: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_649, 2, 0, 9223372036854775807);  slice_649 = None
        slice_651: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_650, 3, 0, 9223372036854775807);  slice_650 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_269: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_648, 2, 3);  slice_648 = None
        matmul_124: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_266, transpose_269);  transpose_266 = transpose_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_652: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_10, 0, 0, 9223372036854775807)
        slice_653: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_652, 1, 0, 9223372036854775807);  slice_652 = None
        slice_654: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_653, 2, 0, 9223372036854775807);  slice_653 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_181: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_124, slice_654);  matmul_124 = slice_654 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_62: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_181, -1);  add_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_198: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_62, 0.0, False);  softmax_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_125: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_198, slice_651);  dropout_198 = slice_651 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_270: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_125, 1, 2);  matmul_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_67: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_270, [1, 1, 512]);  transpose_270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_279: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_67, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_199: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_279, 0.1, False);  linear_279 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_182: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_95, dropout_199);  layer_norm_95 = dropout_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_96: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_182, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_280: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_96, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_81: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_280, 0.125);  linear_280 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_151: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_81, [1, 1, 8, 64]);  mul_81 = None
        transpose_271: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_151, 1, 2);  view_151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_655: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_656: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_655, 2, 0, 23);  slice_655 = None
        slice_657: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_656, 3, 0, 9223372036854775807);  slice_656 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_658: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_659: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_658, 2, 0, 23);  slice_658 = None
        slice_660: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_659, 3, 0, 9223372036854775807);  slice_659 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_272: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_657, 2, 3);  slice_657 = None
        matmul_126: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_271, transpose_272);  transpose_271 = transpose_272 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_661: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_5, 0, 0, 9223372036854775807)
        slice_662: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_661, 1, 0, 9223372036854775807);  slice_661 = None
        slice_663: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_662, 2, 0, 9223372036854775807);  slice_662 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_183: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_126, slice_663);  matmul_126 = slice_663 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_63: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_183, -1);  add_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_200: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_63, 0.0, False);  softmax_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_127: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_200, slice_660);  dropout_200 = slice_660 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_273: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_127, 1, 2);  matmul_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_68: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_273, [1, 1, 512]);  transpose_273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_281: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_68, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_201: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_281, 0.1, False);  linear_281 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_184: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_96, dropout_201);  layer_norm_96 = dropout_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_97: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_184, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_282: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_97, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_34: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_282);  linear_282 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_202: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_34, 0.0, False);  silu_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_283: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_202, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_203: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_283, 0.1, False);  linear_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_185: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_97, dropout_203);  layer_norm_97 = dropout_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_98: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_185, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_284: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_98, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_82: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_284, 0.125);  linear_284 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_152: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_82, [1, 1, 8, 64]);  mul_82 = None
        transpose_274: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_152, 1, 2);  view_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_285: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_98, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_153: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_285, [1, -1, 8, 64]);  linear_285 = None
        transpose_275: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_153, 1, 2);  view_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_286: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_98, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_154: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_286, [1, -1, 8, 64]);  linear_286 = None
        transpose_276: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_154, 1, 2);  view_154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_101: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_275, torch.float32);  transpose_275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_102: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_276, torch.float32);  transpose_276 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_664: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__70: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_664, 2, add_157, to_101);  slice_664 = to_101 = index_copy__70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_665: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__71: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_665, 2, add_157, to_102);  slice_665 = to_102 = index_copy__71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_666: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_667: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_666, 2, 0, 9223372036854775807);  slice_666 = None
        slice_668: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_667, 3, 0, 9223372036854775807);  slice_667 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_669: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_670: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_669, 2, 0, 9223372036854775807);  slice_669 = None
        slice_671: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_670, 3, 0, 9223372036854775807);  slice_670 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_277: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_668, 2, 3);  slice_668 = None
        matmul_128: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_274, transpose_277);  transpose_274 = transpose_277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_672: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_10, 0, 0, 9223372036854775807);  expand_10 = None
        slice_673: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_672, 1, 0, 9223372036854775807);  slice_672 = None
        slice_674: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_673, 2, 0, 9223372036854775807);  slice_673 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_186: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_128, slice_674);  matmul_128 = slice_674 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_64: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_186, -1);  add_186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_204: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_64, 0.0, False);  softmax_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_129: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_204, slice_671);  dropout_204 = slice_671 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_278: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_129, 1, 2);  matmul_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_69: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_278, [1, 1, 512]);  transpose_278 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_287: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_69, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_205: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_287, 0.1, False);  linear_287 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_187: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_98, dropout_205);  layer_norm_98 = dropout_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_99: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_187, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_288: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_99, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_83: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_288, 0.125);  linear_288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_155: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_83, [1, 1, 8, 64]);  mul_83 = None
        transpose_279: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_155, 1, 2);  view_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_675: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_676: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_675, 2, 0, 23);  slice_675 = None
        slice_677: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_676, 3, 0, 9223372036854775807);  slice_676 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_678: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_679: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_678, 2, 0, 23);  slice_678 = None
        slice_680: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_679, 3, 0, 9223372036854775807);  slice_679 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_280: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_677, 2, 3);  slice_677 = None
        matmul_130: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_279, transpose_280);  transpose_279 = transpose_280 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_681: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_5, 0, 0, 9223372036854775807);  masked_fill_5 = None
        slice_682: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_681, 1, 0, 9223372036854775807);  slice_681 = None
        slice_683: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_682, 2, 0, 9223372036854775807);  slice_682 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_188: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_130, slice_683);  matmul_130 = slice_683 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_65: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_188, -1);  add_188 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_206: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_65, 0.0, False);  softmax_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_131: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_206, slice_680);  dropout_206 = slice_680 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_281: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_131, 1, 2);  matmul_131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_70: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_281, [1, 1, 512]);  transpose_281 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_289: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_70, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_207: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_289, 0.1, False);  linear_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_189: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_99, dropout_207);  layer_norm_99 = dropout_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_100: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_189, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_290: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_100, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_35: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_290);  linear_290 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_208: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_35, 0.0, False);  silu_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_291: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_208, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_209: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_291, 0.1, False);  linear_291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_190: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_100, dropout_209);  layer_norm_100 = dropout_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_101: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_190, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_292: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_101, p_model_lm_head_weight);  layer_norm_101 = None
        add_191: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_292, b_model_final_logits_bias);  linear_292 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_684: "i64[1]" = torch.ops.aten.slice.Tensor(add_157, 0, -1, 9223372036854775807);  add_157 = None
        add_192: "i64[1]" = torch.ops.aten.add.Tensor(slice_684, 1);  slice_684 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_685: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_191, 0, 0, 9223372036854775807);  add_191 = None
        select_24: "f32[1, 59514]" = torch.ops.aten.select.int(slice_685, 1, -1);  slice_685 = None
        slice_686: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_24, 1, 0, 9223372036854775807);  select_24 = None
        clone_9: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_686);  slice_686 = None
        to_103: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_9, torch.float32);  clone_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_104: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_103, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_4: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_104, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__4: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_4, to_32);  zeros_like_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_193: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_104, add__4);  to_104 = add__4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_4: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_193, -1);  add_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_4: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_4, -1);  log_softmax_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_84: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_4, and_4);  argmax_4 = None
        rsub_10: "i64[1]" = torch.ops.aten.rsub.Scalar(and_4, 1)
        mul_85: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_10);  rsub_10 = None
        add_194: "i64[1]" = torch.ops.aten.add.Tensor(mul_84, mul_85);  mul_84 = mul_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_687: "i64[1]" = torch.ops.aten.slice.Tensor(add_194, 0, 0, 9223372036854775807);  add_194 = None
        unsqueeze_32: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_687, 1);  slice_687 = None
        cat_4: "i64[1, 6]" = torch.ops.aten.cat.default([cat_3, unsqueeze_32], -1);  cat_3 = unsqueeze_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_13: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_14: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_9: "b8[1]" = torch.ops.aten.__or__.Tensor(full_13, full_14);  full_13 = full_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_105: "i64[1]" = torch.ops.aten.to.dtype_layout(to_87, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_688: "i64[1, 6]" = torch.ops.aten.slice.Tensor(cat_4, 0, 0, 9223372036854775807)
        select_25: "i64[1]" = torch.ops.aten.select.int(slice_688, 1, -1);  slice_688 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_6: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_25, to_105);  select_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_10: "b8[1]" = torch.ops.aten.__or__.Tensor(or_9, isin_6);  or_9 = isin_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_6: "b8[1]" = torch.ops.aten.bitwise_not.default(or_10);  or_10 = None
        and_5: "i64[1]" = torch.ops.aten.__and__.Tensor(and_4, bitwise_not_6);  and_4 = bitwise_not_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_5: "i64[]" = torch.ops.aten.max.default(and_5)
        eq_4: "b8[]" = torch.ops.aten.eq.Scalar(max_5, 0);  max_5 = eq_4 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_689: "i64[1, 6]" = torch.ops.aten.slice.Tensor(cat_4, 0, 0, 9223372036854775807)
        slice_690: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_689, 1, -1, 9223372036854775807);  slice_689 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_10: "i64[1, 1]" = torch.ops.aten.clone.default(slice_690, memory_format = torch.contiguous_format);  slice_690 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_156: "i64[1, 1]" = torch.ops.aten.view.default(clone_10, [-1, 1]);  clone_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_12: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_156, 59513);  view_156 = None
        mul_86: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_12, 22.627416997969522);  embedding_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_33: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_192, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_691: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_34: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_691, 1);  slice_691 = None
        unsqueeze_35: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_34, 2);  unsqueeze_34 = None
        slice_692: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_35, 3, 0, 9223372036854775807);  unsqueeze_35 = None
        expand_11: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_692, [1, 1, 1, 23]);  slice_692 = None
        to_106: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_11, torch.float32);  expand_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_11: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_106, 1.0);  to_106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_107: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_11, torch.bool)
        masked_fill_6: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_11, to_107, -3.4028234663852886e+38);  rsub_11 = to_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_13: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_33);  unsqueeze_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_108: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_13, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_13 = None
        add_195: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_86, to_108);  mul_86 = to_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_210: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_195, 0.1, False);  add_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_26: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_27: "f32[20, 64]" = torch.ops.aten.select.int(select_26, 0, 0);  select_26 = None
        any_10: "b8[20]" = torch.ops.aten.any.dim(select_27, -1);  select_27 = None
        sum_8: "i64[]" = torch.ops.aten.sum.default(any_10);  any_10 = sum_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_15: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_12: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_71: "i64[1, 1]" = torch.ops.aten.reshape.default(add_192, [-1, 1])
        gt_5: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_12, reshape_71);  arange_12 = reshape_71 = None
        mul__5: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_15, gt_5);  full_15 = gt_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_36: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__5, 0);  mul__5 = None
        unsqueeze_37: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_36, 1);  unsqueeze_36 = None
        slice_693: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_37, 2, 0, 9223372036854775807);  unsqueeze_37 = None
        slice_694: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_693, 3, 0, 9223372036854775807);  slice_693 = None
        expand_12: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_694, [1, 1, -1, -1]);  slice_694 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_293: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_210, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_87: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_293, 0.125);  linear_293 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_157: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_87, [1, 1, 8, 64]);  mul_87 = None
        transpose_282: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_157, 1, 2);  view_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_294: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_210, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_158: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_294, [1, -1, 8, 64]);  linear_294 = None
        transpose_283: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_158, 1, 2);  view_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_295: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_210, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_159: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_295, [1, -1, 8, 64]);  linear_295 = None
        transpose_284: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_159, 1, 2);  view_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_109: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_283, torch.float32);  transpose_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_110: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_284, torch.float32);  transpose_284 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_695: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__72: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_695, 2, add_192, to_109);  slice_695 = to_109 = index_copy__72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_696: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__73: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_696, 2, add_192, to_110);  slice_696 = to_110 = index_copy__73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_697: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_698: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_697, 2, 0, 9223372036854775807);  slice_697 = None
        slice_699: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_698, 3, 0, 9223372036854775807);  slice_698 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_700: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_701: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_700, 2, 0, 9223372036854775807);  slice_700 = None
        slice_702: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_701, 3, 0, 9223372036854775807);  slice_701 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_285: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_699, 2, 3);  slice_699 = None
        matmul_132: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_282, transpose_285);  transpose_282 = transpose_285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_703: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_12, 0, 0, 9223372036854775807)
        slice_704: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_703, 1, 0, 9223372036854775807);  slice_703 = None
        slice_705: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_704, 2, 0, 9223372036854775807);  slice_704 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_196: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_132, slice_705);  matmul_132 = slice_705 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_66: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_196, -1);  add_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_211: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_66, 0.0, False);  softmax_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_133: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_211, slice_702);  dropout_211 = slice_702 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_286: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_133, 1, 2);  matmul_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_72: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_286, [1, 1, 512]);  transpose_286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_296: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_72, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_212: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_296, 0.1, False);  linear_296 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_197: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_210, dropout_212);  dropout_210 = dropout_212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_102: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_197, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_297: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_102, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_88: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_297, 0.125);  linear_297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_160: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_88, [1, 1, 8, 64]);  mul_88 = None
        transpose_287: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_160, 1, 2);  view_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_706: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_707: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_706, 2, 0, 23);  slice_706 = None
        slice_708: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_707, 3, 0, 9223372036854775807);  slice_707 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_709: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_710: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_709, 2, 0, 23);  slice_709 = None
        slice_711: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_710, 3, 0, 9223372036854775807);  slice_710 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_288: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_708, 2, 3);  slice_708 = None
        matmul_134: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_287, transpose_288);  transpose_287 = transpose_288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_712: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_6, 0, 0, 9223372036854775807)
        slice_713: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_712, 1, 0, 9223372036854775807);  slice_712 = None
        slice_714: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_713, 2, 0, 9223372036854775807);  slice_713 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_198: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_134, slice_714);  matmul_134 = slice_714 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_67: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_198, -1);  add_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_213: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_67, 0.0, False);  softmax_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_135: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_213, slice_711);  dropout_213 = slice_711 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_289: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_135, 1, 2);  matmul_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_73: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_289, [1, 1, 512]);  transpose_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_298: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_73, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_214: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_298, 0.1, False);  linear_298 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_199: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_102, dropout_214);  layer_norm_102 = dropout_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_103: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_199, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_299: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_103, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_36: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_299);  linear_299 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_215: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_36, 0.0, False);  silu_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_300: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_215, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_216: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_300, 0.1, False);  linear_300 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_200: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_103, dropout_216);  layer_norm_103 = dropout_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_104: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_200, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_301: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_104, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_89: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_301, 0.125);  linear_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_161: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_89, [1, 1, 8, 64]);  mul_89 = None
        transpose_290: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_161, 1, 2);  view_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_302: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_104, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_162: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_302, [1, -1, 8, 64]);  linear_302 = None
        transpose_291: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_162, 1, 2);  view_162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_303: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_104, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_163: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_303, [1, -1, 8, 64]);  linear_303 = None
        transpose_292: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_163, 1, 2);  view_163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_111: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_291, torch.float32);  transpose_291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_112: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_292, torch.float32);  transpose_292 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_715: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__74: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_715, 2, add_192, to_111);  slice_715 = to_111 = index_copy__74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_716: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__75: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_716, 2, add_192, to_112);  slice_716 = to_112 = index_copy__75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_717: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_718: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_717, 2, 0, 9223372036854775807);  slice_717 = None
        slice_719: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_718, 3, 0, 9223372036854775807);  slice_718 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_720: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_721: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_720, 2, 0, 9223372036854775807);  slice_720 = None
        slice_722: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_721, 3, 0, 9223372036854775807);  slice_721 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_293: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_719, 2, 3);  slice_719 = None
        matmul_136: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_290, transpose_293);  transpose_290 = transpose_293 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_723: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_12, 0, 0, 9223372036854775807)
        slice_724: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_723, 1, 0, 9223372036854775807);  slice_723 = None
        slice_725: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_724, 2, 0, 9223372036854775807);  slice_724 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_201: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_136, slice_725);  matmul_136 = slice_725 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_68: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_201, -1);  add_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_217: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_68, 0.0, False);  softmax_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_137: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_217, slice_722);  dropout_217 = slice_722 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_294: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_137, 1, 2);  matmul_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_74: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_294, [1, 1, 512]);  transpose_294 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_304: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_74, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_218: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_304, 0.1, False);  linear_304 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_202: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_104, dropout_218);  layer_norm_104 = dropout_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_105: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_202, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_305: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_105, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_90: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_305, 0.125);  linear_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_164: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_90, [1, 1, 8, 64]);  mul_90 = None
        transpose_295: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_164, 1, 2);  view_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_726: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_727: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_726, 2, 0, 23);  slice_726 = None
        slice_728: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_727, 3, 0, 9223372036854775807);  slice_727 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_729: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_730: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_729, 2, 0, 23);  slice_729 = None
        slice_731: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_730, 3, 0, 9223372036854775807);  slice_730 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_296: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_728, 2, 3);  slice_728 = None
        matmul_138: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_295, transpose_296);  transpose_295 = transpose_296 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_732: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_6, 0, 0, 9223372036854775807)
        slice_733: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_732, 1, 0, 9223372036854775807);  slice_732 = None
        slice_734: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_733, 2, 0, 9223372036854775807);  slice_733 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_203: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_138, slice_734);  matmul_138 = slice_734 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_69: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_203, -1);  add_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_219: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_69, 0.0, False);  softmax_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_139: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_219, slice_731);  dropout_219 = slice_731 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_297: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_139, 1, 2);  matmul_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_75: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_297, [1, 1, 512]);  transpose_297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_306: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_75, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_220: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_306, 0.1, False);  linear_306 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_204: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_105, dropout_220);  layer_norm_105 = dropout_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_106: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_204, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_307: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_106, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_37: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_307);  linear_307 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_221: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_37, 0.0, False);  silu_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_308: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_221, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_222: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_308, 0.1, False);  linear_308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_205: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_106, dropout_222);  layer_norm_106 = dropout_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_107: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_205, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_309: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_107, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_91: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_309, 0.125);  linear_309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_165: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_91, [1, 1, 8, 64]);  mul_91 = None
        transpose_298: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_165, 1, 2);  view_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_310: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_107, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_166: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_310, [1, -1, 8, 64]);  linear_310 = None
        transpose_299: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_166, 1, 2);  view_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_311: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_107, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_167: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_311, [1, -1, 8, 64]);  linear_311 = None
        transpose_300: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_167, 1, 2);  view_167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_113: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_299, torch.float32);  transpose_299 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_114: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_300, torch.float32);  transpose_300 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_735: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__76: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_735, 2, add_192, to_113);  slice_735 = to_113 = index_copy__76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_736: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__77: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_736, 2, add_192, to_114);  slice_736 = to_114 = index_copy__77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_737: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_738: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_737, 2, 0, 9223372036854775807);  slice_737 = None
        slice_739: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_738, 3, 0, 9223372036854775807);  slice_738 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_740: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_741: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_740, 2, 0, 9223372036854775807);  slice_740 = None
        slice_742: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_741, 3, 0, 9223372036854775807);  slice_741 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_301: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_739, 2, 3);  slice_739 = None
        matmul_140: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_298, transpose_301);  transpose_298 = transpose_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_743: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_12, 0, 0, 9223372036854775807)
        slice_744: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_743, 1, 0, 9223372036854775807);  slice_743 = None
        slice_745: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_744, 2, 0, 9223372036854775807);  slice_744 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_206: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_140, slice_745);  matmul_140 = slice_745 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_70: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_206, -1);  add_206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_223: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_70, 0.0, False);  softmax_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_141: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_223, slice_742);  dropout_223 = slice_742 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_302: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_141, 1, 2);  matmul_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_76: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_302, [1, 1, 512]);  transpose_302 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_312: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_76, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_224: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_312, 0.1, False);  linear_312 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_207: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_107, dropout_224);  layer_norm_107 = dropout_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_108: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_207, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_313: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_108, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_92: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_313, 0.125);  linear_313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_168: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_92, [1, 1, 8, 64]);  mul_92 = None
        transpose_303: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_168, 1, 2);  view_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_746: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_747: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_746, 2, 0, 23);  slice_746 = None
        slice_748: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_747, 3, 0, 9223372036854775807);  slice_747 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_749: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_750: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_749, 2, 0, 23);  slice_749 = None
        slice_751: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_750, 3, 0, 9223372036854775807);  slice_750 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_304: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_748, 2, 3);  slice_748 = None
        matmul_142: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_303, transpose_304);  transpose_303 = transpose_304 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_752: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_6, 0, 0, 9223372036854775807)
        slice_753: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_752, 1, 0, 9223372036854775807);  slice_752 = None
        slice_754: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_753, 2, 0, 9223372036854775807);  slice_753 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_208: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_142, slice_754);  matmul_142 = slice_754 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_71: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_208, -1);  add_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_225: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_71, 0.0, False);  softmax_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_143: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_225, slice_751);  dropout_225 = slice_751 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_305: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_143, 1, 2);  matmul_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_77: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_305, [1, 1, 512]);  transpose_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_314: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_77, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_226: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_314, 0.1, False);  linear_314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_209: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_108, dropout_226);  layer_norm_108 = dropout_226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_109: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_209, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_315: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_109, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_38: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_315);  linear_315 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_227: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_38, 0.0, False);  silu_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_316: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_227, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_228: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_316, 0.1, False);  linear_316 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_210: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_109, dropout_228);  layer_norm_109 = dropout_228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_110: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_210, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_317: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_110, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_93: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_317, 0.125);  linear_317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_169: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_93, [1, 1, 8, 64]);  mul_93 = None
        transpose_306: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_169, 1, 2);  view_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_318: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_110, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_170: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_318, [1, -1, 8, 64]);  linear_318 = None
        transpose_307: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_170, 1, 2);  view_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_319: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_110, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_171: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_319, [1, -1, 8, 64]);  linear_319 = None
        transpose_308: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_171, 1, 2);  view_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_115: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_307, torch.float32);  transpose_307 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_116: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_308, torch.float32);  transpose_308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_755: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__78: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_755, 2, add_192, to_115);  slice_755 = to_115 = index_copy__78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_756: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__79: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_756, 2, add_192, to_116);  slice_756 = to_116 = index_copy__79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_757: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_758: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_757, 2, 0, 9223372036854775807);  slice_757 = None
        slice_759: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_758, 3, 0, 9223372036854775807);  slice_758 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_760: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_761: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_760, 2, 0, 9223372036854775807);  slice_760 = None
        slice_762: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_761, 3, 0, 9223372036854775807);  slice_761 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_309: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_759, 2, 3);  slice_759 = None
        matmul_144: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_306, transpose_309);  transpose_306 = transpose_309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_763: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_12, 0, 0, 9223372036854775807)
        slice_764: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_763, 1, 0, 9223372036854775807);  slice_763 = None
        slice_765: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_764, 2, 0, 9223372036854775807);  slice_764 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_211: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_144, slice_765);  matmul_144 = slice_765 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_72: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_211, -1);  add_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_229: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_72, 0.0, False);  softmax_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_145: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_229, slice_762);  dropout_229 = slice_762 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_310: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_145, 1, 2);  matmul_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_78: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_310, [1, 1, 512]);  transpose_310 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_320: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_78, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_230: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_320, 0.1, False);  linear_320 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_212: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_110, dropout_230);  layer_norm_110 = dropout_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_111: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_212, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_321: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_111, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_94: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_321, 0.125);  linear_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_172: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_94, [1, 1, 8, 64]);  mul_94 = None
        transpose_311: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_172, 1, 2);  view_172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_766: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_767: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_766, 2, 0, 23);  slice_766 = None
        slice_768: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_767, 3, 0, 9223372036854775807);  slice_767 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_769: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_770: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_769, 2, 0, 23);  slice_769 = None
        slice_771: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_770, 3, 0, 9223372036854775807);  slice_770 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_312: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_768, 2, 3);  slice_768 = None
        matmul_146: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_311, transpose_312);  transpose_311 = transpose_312 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_772: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_6, 0, 0, 9223372036854775807)
        slice_773: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_772, 1, 0, 9223372036854775807);  slice_772 = None
        slice_774: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_773, 2, 0, 9223372036854775807);  slice_773 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_213: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_146, slice_774);  matmul_146 = slice_774 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_73: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_213, -1);  add_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_231: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_73, 0.0, False);  softmax_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_147: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_231, slice_771);  dropout_231 = slice_771 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_313: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_147, 1, 2);  matmul_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_79: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_313, [1, 1, 512]);  transpose_313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_322: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_79, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_232: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_322, 0.1, False);  linear_322 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_214: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_111, dropout_232);  layer_norm_111 = dropout_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_112: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_214, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_323: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_112, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_39: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_323);  linear_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_233: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_39, 0.0, False);  silu_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_324: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_233, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_234: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_324, 0.1, False);  linear_324 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_215: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_112, dropout_234);  layer_norm_112 = dropout_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_113: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_215, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_325: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_113, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_95: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_325, 0.125);  linear_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_173: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_95, [1, 1, 8, 64]);  mul_95 = None
        transpose_314: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_173, 1, 2);  view_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_326: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_113, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_174: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_326, [1, -1, 8, 64]);  linear_326 = None
        transpose_315: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_174, 1, 2);  view_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_327: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_113, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_175: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_327, [1, -1, 8, 64]);  linear_327 = None
        transpose_316: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_175, 1, 2);  view_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_117: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_315, torch.float32);  transpose_315 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_118: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_316, torch.float32);  transpose_316 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_775: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__80: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_775, 2, add_192, to_117);  slice_775 = to_117 = index_copy__80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_776: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__81: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_776, 2, add_192, to_118);  slice_776 = to_118 = index_copy__81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_777: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_778: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_777, 2, 0, 9223372036854775807);  slice_777 = None
        slice_779: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_778, 3, 0, 9223372036854775807);  slice_778 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_780: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_781: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_780, 2, 0, 9223372036854775807);  slice_780 = None
        slice_782: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_781, 3, 0, 9223372036854775807);  slice_781 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_317: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_779, 2, 3);  slice_779 = None
        matmul_148: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_314, transpose_317);  transpose_314 = transpose_317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_783: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_12, 0, 0, 9223372036854775807)
        slice_784: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_783, 1, 0, 9223372036854775807);  slice_783 = None
        slice_785: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_784, 2, 0, 9223372036854775807);  slice_784 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_216: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_148, slice_785);  matmul_148 = slice_785 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_74: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_216, -1);  add_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_235: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_74, 0.0, False);  softmax_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_149: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_235, slice_782);  dropout_235 = slice_782 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_318: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_149, 1, 2);  matmul_149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_80: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_318, [1, 1, 512]);  transpose_318 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_328: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_80, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_236: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_328, 0.1, False);  linear_328 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_217: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_113, dropout_236);  layer_norm_113 = dropout_236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_114: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_217, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_329: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_114, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_96: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_329, 0.125);  linear_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_176: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_96, [1, 1, 8, 64]);  mul_96 = None
        transpose_319: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_176, 1, 2);  view_176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_786: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_787: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_786, 2, 0, 23);  slice_786 = None
        slice_788: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_787, 3, 0, 9223372036854775807);  slice_787 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_789: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_790: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_789, 2, 0, 23);  slice_789 = None
        slice_791: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_790, 3, 0, 9223372036854775807);  slice_790 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_320: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_788, 2, 3);  slice_788 = None
        matmul_150: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_319, transpose_320);  transpose_319 = transpose_320 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_792: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_6, 0, 0, 9223372036854775807)
        slice_793: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_792, 1, 0, 9223372036854775807);  slice_792 = None
        slice_794: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_793, 2, 0, 9223372036854775807);  slice_793 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_218: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_150, slice_794);  matmul_150 = slice_794 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_75: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_218, -1);  add_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_237: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_75, 0.0, False);  softmax_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_151: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_237, slice_791);  dropout_237 = slice_791 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_321: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_151, 1, 2);  matmul_151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_81: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_321, [1, 1, 512]);  transpose_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_330: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_81, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_238: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_330, 0.1, False);  linear_330 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_219: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_114, dropout_238);  layer_norm_114 = dropout_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_115: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_219, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_331: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_115, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_40: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_331);  linear_331 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_239: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_40, 0.0, False);  silu_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_332: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_239, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_240: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_332, 0.1, False);  linear_332 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_220: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_115, dropout_240);  layer_norm_115 = dropout_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_116: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_220, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_333: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_116, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_97: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_333, 0.125);  linear_333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_177: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_97, [1, 1, 8, 64]);  mul_97 = None
        transpose_322: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_177, 1, 2);  view_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_334: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_116, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_178: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_334, [1, -1, 8, 64]);  linear_334 = None
        transpose_323: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_178, 1, 2);  view_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_335: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_116, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_179: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_335, [1, -1, 8, 64]);  linear_335 = None
        transpose_324: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_179, 1, 2);  view_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_119: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_323, torch.float32);  transpose_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_120: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_324, torch.float32);  transpose_324 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_795: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__82: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_795, 2, add_192, to_119);  slice_795 = to_119 = index_copy__82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_796: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__83: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_796, 2, add_192, to_120);  slice_796 = to_120 = index_copy__83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_797: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_798: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_797, 2, 0, 9223372036854775807);  slice_797 = None
        slice_799: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_798, 3, 0, 9223372036854775807);  slice_798 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_800: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_801: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_800, 2, 0, 9223372036854775807);  slice_800 = None
        slice_802: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_801, 3, 0, 9223372036854775807);  slice_801 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_325: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_799, 2, 3);  slice_799 = None
        matmul_152: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_322, transpose_325);  transpose_322 = transpose_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_803: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_12, 0, 0, 9223372036854775807);  expand_12 = None
        slice_804: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_803, 1, 0, 9223372036854775807);  slice_803 = None
        slice_805: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_804, 2, 0, 9223372036854775807);  slice_804 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_221: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_152, slice_805);  matmul_152 = slice_805 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_76: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_221, -1);  add_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_241: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_76, 0.0, False);  softmax_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_153: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_241, slice_802);  dropout_241 = slice_802 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_326: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_153, 1, 2);  matmul_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_82: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_326, [1, 1, 512]);  transpose_326 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_336: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_82, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_242: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_336, 0.1, False);  linear_336 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_222: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_116, dropout_242);  layer_norm_116 = dropout_242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_117: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_222, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_337: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_117, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_98: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_337, 0.125);  linear_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_180: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_98, [1, 1, 8, 64]);  mul_98 = None
        transpose_327: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_180, 1, 2);  view_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_806: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_807: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_806, 2, 0, 23);  slice_806 = None
        slice_808: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_807, 3, 0, 9223372036854775807);  slice_807 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_809: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_810: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_809, 2, 0, 23);  slice_809 = None
        slice_811: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_810, 3, 0, 9223372036854775807);  slice_810 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_328: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_808, 2, 3);  slice_808 = None
        matmul_154: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_327, transpose_328);  transpose_327 = transpose_328 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_812: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_6, 0, 0, 9223372036854775807);  masked_fill_6 = None
        slice_813: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_812, 1, 0, 9223372036854775807);  slice_812 = None
        slice_814: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_813, 2, 0, 9223372036854775807);  slice_813 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_223: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_154, slice_814);  matmul_154 = slice_814 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_77: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_223, -1);  add_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_243: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_77, 0.0, False);  softmax_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_155: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_243, slice_811);  dropout_243 = slice_811 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_329: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_155, 1, 2);  matmul_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_83: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_329, [1, 1, 512]);  transpose_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_338: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_83, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_244: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_338, 0.1, False);  linear_338 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_224: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_117, dropout_244);  layer_norm_117 = dropout_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_118: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_224, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_339: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_118, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_41: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_339);  linear_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_245: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_41, 0.0, False);  silu_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_340: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_245, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_246: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_340, 0.1, False);  linear_340 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_225: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_118, dropout_246);  layer_norm_118 = dropout_246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_119: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_225, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_341: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_119, p_model_lm_head_weight);  layer_norm_119 = None
        add_226: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_341, b_model_final_logits_bias);  linear_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_815: "i64[1]" = torch.ops.aten.slice.Tensor(add_192, 0, -1, 9223372036854775807);  add_192 = None
        add_227: "i64[1]" = torch.ops.aten.add.Tensor(slice_815, 1);  slice_815 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_816: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_226, 0, 0, 9223372036854775807);  add_226 = None
        select_28: "f32[1, 59514]" = torch.ops.aten.select.int(slice_816, 1, -1);  slice_816 = None
        slice_817: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_28, 1, 0, 9223372036854775807);  select_28 = None
        clone_11: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_817);  slice_817 = None
        to_121: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_11, torch.float32);  clone_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_122: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_121, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_5: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_122, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__5: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_5, to_32);  zeros_like_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_228: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_122, add__5);  to_122 = add__5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_5: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_228, -1);  add_228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_5: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_5, -1);  log_softmax_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_99: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_5, and_5);  argmax_5 = None
        rsub_12: "i64[1]" = torch.ops.aten.rsub.Scalar(and_5, 1)
        mul_100: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_12);  rsub_12 = None
        add_229: "i64[1]" = torch.ops.aten.add.Tensor(mul_99, mul_100);  mul_99 = mul_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_818: "i64[1]" = torch.ops.aten.slice.Tensor(add_229, 0, 0, 9223372036854775807);  add_229 = None
        unsqueeze_38: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_818, 1);  slice_818 = None
        cat_5: "i64[1, 7]" = torch.ops.aten.cat.default([cat_4, unsqueeze_38], -1);  cat_4 = unsqueeze_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_16: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_17: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_11: "b8[1]" = torch.ops.aten.__or__.Tensor(full_16, full_17);  full_16 = full_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_123: "i64[1]" = torch.ops.aten.to.dtype_layout(to_105, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_819: "i64[1, 7]" = torch.ops.aten.slice.Tensor(cat_5, 0, 0, 9223372036854775807)
        select_29: "i64[1]" = torch.ops.aten.select.int(slice_819, 1, -1);  slice_819 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_7: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_29, to_123);  select_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_12: "b8[1]" = torch.ops.aten.__or__.Tensor(or_11, isin_7);  or_11 = isin_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_7: "b8[1]" = torch.ops.aten.bitwise_not.default(or_12);  or_12 = None
        and_6: "i64[1]" = torch.ops.aten.__and__.Tensor(and_5, bitwise_not_7);  and_5 = bitwise_not_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_6: "i64[]" = torch.ops.aten.max.default(and_6)
        eq_5: "b8[]" = torch.ops.aten.eq.Scalar(max_6, 0);  max_6 = eq_5 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_820: "i64[1, 7]" = torch.ops.aten.slice.Tensor(cat_5, 0, 0, 9223372036854775807)
        slice_821: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_820, 1, -1, 9223372036854775807);  slice_820 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_12: "i64[1, 1]" = torch.ops.aten.clone.default(slice_821, memory_format = torch.contiguous_format);  slice_821 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_181: "i64[1, 1]" = torch.ops.aten.view.default(clone_12, [-1, 1]);  clone_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_14: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_181, 59513);  view_181 = None
        mul_101: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_14, 22.627416997969522);  embedding_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_39: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_227, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_822: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_40: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_822, 1);  slice_822 = None
        unsqueeze_41: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_40, 2);  unsqueeze_40 = None
        slice_823: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_41, 3, 0, 9223372036854775807);  unsqueeze_41 = None
        expand_13: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_823, [1, 1, 1, 23]);  slice_823 = None
        to_124: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_13, torch.float32);  expand_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_13: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_124, 1.0);  to_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_125: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_13, torch.bool)
        masked_fill_7: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_13, to_125, -3.4028234663852886e+38);  rsub_13 = to_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_15: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_39);  unsqueeze_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_126: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_15, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_15 = None
        add_230: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_101, to_126);  mul_101 = to_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_247: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_230, 0.1, False);  add_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_30: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_31: "f32[20, 64]" = torch.ops.aten.select.int(select_30, 0, 0);  select_30 = None
        any_11: "b8[20]" = torch.ops.aten.any.dim(select_31, -1);  select_31 = None
        sum_9: "i64[]" = torch.ops.aten.sum.default(any_11);  any_11 = sum_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_18: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_13: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_84: "i64[1, 1]" = torch.ops.aten.reshape.default(add_227, [-1, 1])
        gt_6: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_13, reshape_84);  arange_13 = reshape_84 = None
        mul__6: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_18, gt_6);  full_18 = gt_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_42: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__6, 0);  mul__6 = None
        unsqueeze_43: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_42, 1);  unsqueeze_42 = None
        slice_824: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_43, 2, 0, 9223372036854775807);  unsqueeze_43 = None
        slice_825: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_824, 3, 0, 9223372036854775807);  slice_824 = None
        expand_14: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_825, [1, 1, -1, -1]);  slice_825 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_342: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_247, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_102: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_342, 0.125);  linear_342 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_182: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_102, [1, 1, 8, 64]);  mul_102 = None
        transpose_330: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_182, 1, 2);  view_182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_343: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_247, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_183: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_343, [1, -1, 8, 64]);  linear_343 = None
        transpose_331: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_183, 1, 2);  view_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_344: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_247, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_184: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_344, [1, -1, 8, 64]);  linear_344 = None
        transpose_332: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_184, 1, 2);  view_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_127: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_331, torch.float32);  transpose_331 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_128: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_332, torch.float32);  transpose_332 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_826: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__84: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_826, 2, add_227, to_127);  slice_826 = to_127 = index_copy__84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_827: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__85: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_827, 2, add_227, to_128);  slice_827 = to_128 = index_copy__85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_828: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_829: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_828, 2, 0, 9223372036854775807);  slice_828 = None
        slice_830: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_829, 3, 0, 9223372036854775807);  slice_829 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_831: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_832: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_831, 2, 0, 9223372036854775807);  slice_831 = None
        slice_833: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_832, 3, 0, 9223372036854775807);  slice_832 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_333: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_830, 2, 3);  slice_830 = None
        matmul_156: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_330, transpose_333);  transpose_330 = transpose_333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_834: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_14, 0, 0, 9223372036854775807)
        slice_835: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_834, 1, 0, 9223372036854775807);  slice_834 = None
        slice_836: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_835, 2, 0, 9223372036854775807);  slice_835 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_231: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_156, slice_836);  matmul_156 = slice_836 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_78: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_231, -1);  add_231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_248: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_78, 0.0, False);  softmax_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_157: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_248, slice_833);  dropout_248 = slice_833 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_334: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_157, 1, 2);  matmul_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_85: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_334, [1, 1, 512]);  transpose_334 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_345: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_85, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_249: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_345, 0.1, False);  linear_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_232: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_247, dropout_249);  dropout_247 = dropout_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_120: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_232, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_346: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_120, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_103: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_346, 0.125);  linear_346 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_185: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_103, [1, 1, 8, 64]);  mul_103 = None
        transpose_335: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_185, 1, 2);  view_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_837: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_838: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_837, 2, 0, 23);  slice_837 = None
        slice_839: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_838, 3, 0, 9223372036854775807);  slice_838 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_840: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_841: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_840, 2, 0, 23);  slice_840 = None
        slice_842: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_841, 3, 0, 9223372036854775807);  slice_841 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_336: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_839, 2, 3);  slice_839 = None
        matmul_158: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_335, transpose_336);  transpose_335 = transpose_336 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_843: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_7, 0, 0, 9223372036854775807)
        slice_844: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_843, 1, 0, 9223372036854775807);  slice_843 = None
        slice_845: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_844, 2, 0, 9223372036854775807);  slice_844 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_233: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_158, slice_845);  matmul_158 = slice_845 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_79: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_233, -1);  add_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_250: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_79, 0.0, False);  softmax_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_159: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_250, slice_842);  dropout_250 = slice_842 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_337: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_159, 1, 2);  matmul_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_86: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_337, [1, 1, 512]);  transpose_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_347: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_86, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_251: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_347, 0.1, False);  linear_347 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_234: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_120, dropout_251);  layer_norm_120 = dropout_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_121: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_234, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_348: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_121, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_42: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_348);  linear_348 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_252: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_42, 0.0, False);  silu_42 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_349: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_252, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_253: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_349, 0.1, False);  linear_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_235: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_121, dropout_253);  layer_norm_121 = dropout_253 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_122: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_235, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_350: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_122, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_104: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_350, 0.125);  linear_350 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_186: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_104, [1, 1, 8, 64]);  mul_104 = None
        transpose_338: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_186, 1, 2);  view_186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_351: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_122, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_187: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_351, [1, -1, 8, 64]);  linear_351 = None
        transpose_339: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_187, 1, 2);  view_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_352: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_122, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_188: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_352, [1, -1, 8, 64]);  linear_352 = None
        transpose_340: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_188, 1, 2);  view_188 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_129: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_339, torch.float32);  transpose_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_130: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_340, torch.float32);  transpose_340 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_846: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__86: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_846, 2, add_227, to_129);  slice_846 = to_129 = index_copy__86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_847: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__87: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_847, 2, add_227, to_130);  slice_847 = to_130 = index_copy__87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_848: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_849: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_848, 2, 0, 9223372036854775807);  slice_848 = None
        slice_850: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_849, 3, 0, 9223372036854775807);  slice_849 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_851: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_852: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_851, 2, 0, 9223372036854775807);  slice_851 = None
        slice_853: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_852, 3, 0, 9223372036854775807);  slice_852 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_341: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_850, 2, 3);  slice_850 = None
        matmul_160: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_338, transpose_341);  transpose_338 = transpose_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_854: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_14, 0, 0, 9223372036854775807)
        slice_855: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_854, 1, 0, 9223372036854775807);  slice_854 = None
        slice_856: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_855, 2, 0, 9223372036854775807);  slice_855 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_236: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_160, slice_856);  matmul_160 = slice_856 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_80: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_236, -1);  add_236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_254: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_80, 0.0, False);  softmax_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_161: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_254, slice_853);  dropout_254 = slice_853 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_342: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_161, 1, 2);  matmul_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_87: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_342, [1, 1, 512]);  transpose_342 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_353: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_87, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_255: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_353, 0.1, False);  linear_353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_237: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_122, dropout_255);  layer_norm_122 = dropout_255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_123: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_237, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_354: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_123, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_105: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_354, 0.125);  linear_354 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_189: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_105, [1, 1, 8, 64]);  mul_105 = None
        transpose_343: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_189, 1, 2);  view_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_857: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_858: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_857, 2, 0, 23);  slice_857 = None
        slice_859: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_858, 3, 0, 9223372036854775807);  slice_858 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_860: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_861: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_860, 2, 0, 23);  slice_860 = None
        slice_862: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_861, 3, 0, 9223372036854775807);  slice_861 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_344: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_859, 2, 3);  slice_859 = None
        matmul_162: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_343, transpose_344);  transpose_343 = transpose_344 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_863: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_7, 0, 0, 9223372036854775807)
        slice_864: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_863, 1, 0, 9223372036854775807);  slice_863 = None
        slice_865: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_864, 2, 0, 9223372036854775807);  slice_864 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_238: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_162, slice_865);  matmul_162 = slice_865 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_81: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_238, -1);  add_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_256: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_81, 0.0, False);  softmax_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_163: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_256, slice_862);  dropout_256 = slice_862 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_345: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_163, 1, 2);  matmul_163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_88: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_345, [1, 1, 512]);  transpose_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_355: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_88, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_257: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_355, 0.1, False);  linear_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_239: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_123, dropout_257);  layer_norm_123 = dropout_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_124: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_239, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_356: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_124, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_43: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_356);  linear_356 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_258: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_43, 0.0, False);  silu_43 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_357: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_258, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_258 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_259: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_357, 0.1, False);  linear_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_240: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_124, dropout_259);  layer_norm_124 = dropout_259 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_125: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_240, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_358: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_125, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_106: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_358, 0.125);  linear_358 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_190: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_106, [1, 1, 8, 64]);  mul_106 = None
        transpose_346: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_190, 1, 2);  view_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_359: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_125, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_191: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_359, [1, -1, 8, 64]);  linear_359 = None
        transpose_347: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_191, 1, 2);  view_191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_360: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_125, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_192: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_360, [1, -1, 8, 64]);  linear_360 = None
        transpose_348: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_192, 1, 2);  view_192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_131: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_347, torch.float32);  transpose_347 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_132: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_348, torch.float32);  transpose_348 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_866: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__88: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_866, 2, add_227, to_131);  slice_866 = to_131 = index_copy__88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_867: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__89: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_867, 2, add_227, to_132);  slice_867 = to_132 = index_copy__89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_868: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_869: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_868, 2, 0, 9223372036854775807);  slice_868 = None
        slice_870: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_869, 3, 0, 9223372036854775807);  slice_869 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_871: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_872: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_871, 2, 0, 9223372036854775807);  slice_871 = None
        slice_873: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_872, 3, 0, 9223372036854775807);  slice_872 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_349: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_870, 2, 3);  slice_870 = None
        matmul_164: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_346, transpose_349);  transpose_346 = transpose_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_874: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_14, 0, 0, 9223372036854775807)
        slice_875: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_874, 1, 0, 9223372036854775807);  slice_874 = None
        slice_876: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_875, 2, 0, 9223372036854775807);  slice_875 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_241: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_164, slice_876);  matmul_164 = slice_876 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_82: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_241, -1);  add_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_260: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_82, 0.0, False);  softmax_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_165: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_260, slice_873);  dropout_260 = slice_873 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_350: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_165, 1, 2);  matmul_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_89: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_350, [1, 1, 512]);  transpose_350 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_361: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_89, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_261: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_361, 0.1, False);  linear_361 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_242: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_125, dropout_261);  layer_norm_125 = dropout_261 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_126: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_242, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_362: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_126, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_107: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_362, 0.125);  linear_362 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_193: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_107, [1, 1, 8, 64]);  mul_107 = None
        transpose_351: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_193, 1, 2);  view_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_877: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_878: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_877, 2, 0, 23);  slice_877 = None
        slice_879: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_878, 3, 0, 9223372036854775807);  slice_878 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_880: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_881: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_880, 2, 0, 23);  slice_880 = None
        slice_882: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_881, 3, 0, 9223372036854775807);  slice_881 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_352: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_879, 2, 3);  slice_879 = None
        matmul_166: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_351, transpose_352);  transpose_351 = transpose_352 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_883: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_7, 0, 0, 9223372036854775807)
        slice_884: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_883, 1, 0, 9223372036854775807);  slice_883 = None
        slice_885: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_884, 2, 0, 9223372036854775807);  slice_884 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_243: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_166, slice_885);  matmul_166 = slice_885 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_83: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_243, -1);  add_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_262: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_83, 0.0, False);  softmax_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_167: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_262, slice_882);  dropout_262 = slice_882 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_353: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_167, 1, 2);  matmul_167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_90: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_353, [1, 1, 512]);  transpose_353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_363: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_90, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_263: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_363, 0.1, False);  linear_363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_244: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_126, dropout_263);  layer_norm_126 = dropout_263 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_127: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_244, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_364: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_127, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_44: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_364);  linear_364 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_264: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_44, 0.0, False);  silu_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_365: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_264, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_264 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_265: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_365, 0.1, False);  linear_365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_245: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_127, dropout_265);  layer_norm_127 = dropout_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_128: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_245, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_366: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_128, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_108: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_366, 0.125);  linear_366 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_194: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_108, [1, 1, 8, 64]);  mul_108 = None
        transpose_354: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_194, 1, 2);  view_194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_367: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_128, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_195: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_367, [1, -1, 8, 64]);  linear_367 = None
        transpose_355: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_195, 1, 2);  view_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_368: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_128, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_196: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_368, [1, -1, 8, 64]);  linear_368 = None
        transpose_356: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_196, 1, 2);  view_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_133: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_355, torch.float32);  transpose_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_134: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_356, torch.float32);  transpose_356 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_886: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__90: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_886, 2, add_227, to_133);  slice_886 = to_133 = index_copy__90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_887: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__91: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_887, 2, add_227, to_134);  slice_887 = to_134 = index_copy__91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_888: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_889: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_888, 2, 0, 9223372036854775807);  slice_888 = None
        slice_890: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_889, 3, 0, 9223372036854775807);  slice_889 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_891: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_892: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_891, 2, 0, 9223372036854775807);  slice_891 = None
        slice_893: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_892, 3, 0, 9223372036854775807);  slice_892 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_357: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_890, 2, 3);  slice_890 = None
        matmul_168: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_354, transpose_357);  transpose_354 = transpose_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_894: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_14, 0, 0, 9223372036854775807)
        slice_895: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_894, 1, 0, 9223372036854775807);  slice_894 = None
        slice_896: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_895, 2, 0, 9223372036854775807);  slice_895 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_246: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_168, slice_896);  matmul_168 = slice_896 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_84: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_246, -1);  add_246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_266: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_84, 0.0, False);  softmax_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_169: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_266, slice_893);  dropout_266 = slice_893 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_358: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_169, 1, 2);  matmul_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_91: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_358, [1, 1, 512]);  transpose_358 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_369: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_91, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_267: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_369, 0.1, False);  linear_369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_247: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_128, dropout_267);  layer_norm_128 = dropout_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_129: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_247, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_370: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_129, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_109: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_370, 0.125);  linear_370 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_197: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_109, [1, 1, 8, 64]);  mul_109 = None
        transpose_359: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_197, 1, 2);  view_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_897: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_898: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_897, 2, 0, 23);  slice_897 = None
        slice_899: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_898, 3, 0, 9223372036854775807);  slice_898 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_900: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_901: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_900, 2, 0, 23);  slice_900 = None
        slice_902: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_901, 3, 0, 9223372036854775807);  slice_901 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_360: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_899, 2, 3);  slice_899 = None
        matmul_170: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_359, transpose_360);  transpose_359 = transpose_360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_903: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_7, 0, 0, 9223372036854775807)
        slice_904: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_903, 1, 0, 9223372036854775807);  slice_903 = None
        slice_905: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_904, 2, 0, 9223372036854775807);  slice_904 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_248: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_170, slice_905);  matmul_170 = slice_905 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_85: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_248, -1);  add_248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_268: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_85, 0.0, False);  softmax_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_171: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_268, slice_902);  dropout_268 = slice_902 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_361: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_171, 1, 2);  matmul_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_92: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_361, [1, 1, 512]);  transpose_361 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_371: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_92, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_269: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_371, 0.1, False);  linear_371 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_249: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_129, dropout_269);  layer_norm_129 = dropout_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_130: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_249, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_372: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_130, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_45: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_372);  linear_372 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_270: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_45, 0.0, False);  silu_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_373: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_270, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_271: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_373, 0.1, False);  linear_373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_250: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_130, dropout_271);  layer_norm_130 = dropout_271 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_131: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_250, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_374: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_131, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_110: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_374, 0.125);  linear_374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_198: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_110, [1, 1, 8, 64]);  mul_110 = None
        transpose_362: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_198, 1, 2);  view_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_375: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_131, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_199: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_375, [1, -1, 8, 64]);  linear_375 = None
        transpose_363: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_199, 1, 2);  view_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_376: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_131, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_200: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_376, [1, -1, 8, 64]);  linear_376 = None
        transpose_364: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_200, 1, 2);  view_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_135: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_363, torch.float32);  transpose_363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_136: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_364, torch.float32);  transpose_364 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_906: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__92: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_906, 2, add_227, to_135);  slice_906 = to_135 = index_copy__92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_907: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__93: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_907, 2, add_227, to_136);  slice_907 = to_136 = index_copy__93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_908: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_909: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_908, 2, 0, 9223372036854775807);  slice_908 = None
        slice_910: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_909, 3, 0, 9223372036854775807);  slice_909 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_911: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_912: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_911, 2, 0, 9223372036854775807);  slice_911 = None
        slice_913: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_912, 3, 0, 9223372036854775807);  slice_912 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_365: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_910, 2, 3);  slice_910 = None
        matmul_172: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_362, transpose_365);  transpose_362 = transpose_365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_914: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_14, 0, 0, 9223372036854775807)
        slice_915: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_914, 1, 0, 9223372036854775807);  slice_914 = None
        slice_916: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_915, 2, 0, 9223372036854775807);  slice_915 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_251: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_172, slice_916);  matmul_172 = slice_916 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_86: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_251, -1);  add_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_272: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_86, 0.0, False);  softmax_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_173: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_272, slice_913);  dropout_272 = slice_913 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_366: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_173, 1, 2);  matmul_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_93: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_366, [1, 1, 512]);  transpose_366 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_377: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_93, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_273: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_377, 0.1, False);  linear_377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_252: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_131, dropout_273);  layer_norm_131 = dropout_273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_132: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_252, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_378: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_132, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_111: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_378, 0.125);  linear_378 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_201: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_111, [1, 1, 8, 64]);  mul_111 = None
        transpose_367: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_201, 1, 2);  view_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_917: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_918: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_917, 2, 0, 23);  slice_917 = None
        slice_919: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_918, 3, 0, 9223372036854775807);  slice_918 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_920: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_921: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_920, 2, 0, 23);  slice_920 = None
        slice_922: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_921, 3, 0, 9223372036854775807);  slice_921 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_368: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_919, 2, 3);  slice_919 = None
        matmul_174: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_367, transpose_368);  transpose_367 = transpose_368 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_923: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_7, 0, 0, 9223372036854775807)
        slice_924: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_923, 1, 0, 9223372036854775807);  slice_923 = None
        slice_925: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_924, 2, 0, 9223372036854775807);  slice_924 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_253: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_174, slice_925);  matmul_174 = slice_925 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_87: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_253, -1);  add_253 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_274: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_87, 0.0, False);  softmax_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_175: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_274, slice_922);  dropout_274 = slice_922 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_369: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_175, 1, 2);  matmul_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_94: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_369, [1, 1, 512]);  transpose_369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_379: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_94, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_275: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_379, 0.1, False);  linear_379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_254: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_132, dropout_275);  layer_norm_132 = dropout_275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_133: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_254, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_254 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_380: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_133, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_46: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_380);  linear_380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_276: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_46, 0.0, False);  silu_46 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_381: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_276, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_276 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_277: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_381, 0.1, False);  linear_381 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_255: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_133, dropout_277);  layer_norm_133 = dropout_277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_134: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_255, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_382: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_134, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_112: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_382, 0.125);  linear_382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_202: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_112, [1, 1, 8, 64]);  mul_112 = None
        transpose_370: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_202, 1, 2);  view_202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_383: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_134, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_203: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_383, [1, -1, 8, 64]);  linear_383 = None
        transpose_371: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_203, 1, 2);  view_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_384: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_134, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_204: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_384, [1, -1, 8, 64]);  linear_384 = None
        transpose_372: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_204, 1, 2);  view_204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_137: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_371, torch.float32);  transpose_371 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_138: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_372, torch.float32);  transpose_372 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_926: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__94: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_926, 2, add_227, to_137);  slice_926 = to_137 = index_copy__94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_927: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__95: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_927, 2, add_227, to_138);  slice_927 = to_138 = index_copy__95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_928: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_929: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_928, 2, 0, 9223372036854775807);  slice_928 = None
        slice_930: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_929, 3, 0, 9223372036854775807);  slice_929 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_931: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_932: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_931, 2, 0, 9223372036854775807);  slice_931 = None
        slice_933: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_932, 3, 0, 9223372036854775807);  slice_932 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_373: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_930, 2, 3);  slice_930 = None
        matmul_176: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_370, transpose_373);  transpose_370 = transpose_373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_934: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_14, 0, 0, 9223372036854775807);  expand_14 = None
        slice_935: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_934, 1, 0, 9223372036854775807);  slice_934 = None
        slice_936: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_935, 2, 0, 9223372036854775807);  slice_935 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_256: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_176, slice_936);  matmul_176 = slice_936 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_88: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_256, -1);  add_256 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_278: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_88, 0.0, False);  softmax_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_177: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_278, slice_933);  dropout_278 = slice_933 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_374: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_177, 1, 2);  matmul_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_95: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_374, [1, 1, 512]);  transpose_374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_385: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_95, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_279: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_385, 0.1, False);  linear_385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_257: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_134, dropout_279);  layer_norm_134 = dropout_279 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_135: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_257, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_386: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_135, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_113: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_386, 0.125);  linear_386 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_205: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_113, [1, 1, 8, 64]);  mul_113 = None
        transpose_375: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_205, 1, 2);  view_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_937: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_938: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_937, 2, 0, 23);  slice_937 = None
        slice_939: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_938, 3, 0, 9223372036854775807);  slice_938 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_940: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_941: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_940, 2, 0, 23);  slice_940 = None
        slice_942: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_941, 3, 0, 9223372036854775807);  slice_941 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_376: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_939, 2, 3);  slice_939 = None
        matmul_178: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_375, transpose_376);  transpose_375 = transpose_376 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_943: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_7, 0, 0, 9223372036854775807);  masked_fill_7 = None
        slice_944: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_943, 1, 0, 9223372036854775807);  slice_943 = None
        slice_945: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_944, 2, 0, 9223372036854775807);  slice_944 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_258: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_178, slice_945);  matmul_178 = slice_945 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_89: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_258, -1);  add_258 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_280: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_89, 0.0, False);  softmax_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_179: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_280, slice_942);  dropout_280 = slice_942 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_377: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_179, 1, 2);  matmul_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_96: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_377, [1, 1, 512]);  transpose_377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_387: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_96, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_281: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_387, 0.1, False);  linear_387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_259: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_135, dropout_281);  layer_norm_135 = dropout_281 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_136: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_259, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_259 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_388: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_136, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_47: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_388);  linear_388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_282: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_47, 0.0, False);  silu_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_389: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_282, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_282 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_283: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_389, 0.1, False);  linear_389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_260: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_136, dropout_283);  layer_norm_136 = dropout_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_137: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_260, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_260 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_390: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_137, p_model_lm_head_weight);  layer_norm_137 = None
        add_261: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_390, b_model_final_logits_bias);  linear_390 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_946: "i64[1]" = torch.ops.aten.slice.Tensor(add_227, 0, -1, 9223372036854775807);  add_227 = None
        add_262: "i64[1]" = torch.ops.aten.add.Tensor(slice_946, 1);  slice_946 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_947: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_261, 0, 0, 9223372036854775807);  add_261 = None
        select_32: "f32[1, 59514]" = torch.ops.aten.select.int(slice_947, 1, -1);  slice_947 = None
        slice_948: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_32, 1, 0, 9223372036854775807);  select_32 = None
        clone_13: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_948);  slice_948 = None
        to_139: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_13, torch.float32);  clone_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_140: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_139, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_6: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_140, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__6: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_6, to_32);  zeros_like_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_263: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_140, add__6);  to_140 = add__6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_6: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_263, -1);  add_263 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_6: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_6, -1);  log_softmax_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_114: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_6, and_6);  argmax_6 = None
        rsub_14: "i64[1]" = torch.ops.aten.rsub.Scalar(and_6, 1)
        mul_115: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_14);  rsub_14 = None
        add_264: "i64[1]" = torch.ops.aten.add.Tensor(mul_114, mul_115);  mul_114 = mul_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_949: "i64[1]" = torch.ops.aten.slice.Tensor(add_264, 0, 0, 9223372036854775807);  add_264 = None
        unsqueeze_44: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_949, 1);  slice_949 = None
        cat_6: "i64[1, 8]" = torch.ops.aten.cat.default([cat_5, unsqueeze_44], -1);  cat_5 = unsqueeze_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_19: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_20: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_13: "b8[1]" = torch.ops.aten.__or__.Tensor(full_19, full_20);  full_19 = full_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_141: "i64[1]" = torch.ops.aten.to.dtype_layout(to_123, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_950: "i64[1, 8]" = torch.ops.aten.slice.Tensor(cat_6, 0, 0, 9223372036854775807)
        select_33: "i64[1]" = torch.ops.aten.select.int(slice_950, 1, -1);  slice_950 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_8: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_33, to_141);  select_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_14: "b8[1]" = torch.ops.aten.__or__.Tensor(or_13, isin_8);  or_13 = isin_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_8: "b8[1]" = torch.ops.aten.bitwise_not.default(or_14);  or_14 = None
        and_7: "i64[1]" = torch.ops.aten.__and__.Tensor(and_6, bitwise_not_8);  and_6 = bitwise_not_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_7: "i64[]" = torch.ops.aten.max.default(and_7)
        eq_6: "b8[]" = torch.ops.aten.eq.Scalar(max_7, 0);  max_7 = eq_6 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_951: "i64[1, 8]" = torch.ops.aten.slice.Tensor(cat_6, 0, 0, 9223372036854775807)
        slice_952: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_951, 1, -1, 9223372036854775807);  slice_951 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_14: "i64[1, 1]" = torch.ops.aten.clone.default(slice_952, memory_format = torch.contiguous_format);  slice_952 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_206: "i64[1, 1]" = torch.ops.aten.view.default(clone_14, [-1, 1]);  clone_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_16: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_206, 59513);  view_206 = None
        mul_116: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_16, 22.627416997969522);  embedding_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_45: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_262, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_953: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_46: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_953, 1);  slice_953 = None
        unsqueeze_47: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_46, 2);  unsqueeze_46 = None
        slice_954: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_47, 3, 0, 9223372036854775807);  unsqueeze_47 = None
        expand_15: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_954, [1, 1, 1, 23]);  slice_954 = None
        to_142: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_15, torch.float32);  expand_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_15: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_142, 1.0);  to_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_143: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_15, torch.bool)
        masked_fill_8: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_15, to_143, -3.4028234663852886e+38);  rsub_15 = to_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_17: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_45);  unsqueeze_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_144: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_17, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_17 = None
        add_265: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_116, to_144);  mul_116 = to_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_284: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_265, 0.1, False);  add_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_34: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_35: "f32[20, 64]" = torch.ops.aten.select.int(select_34, 0, 0);  select_34 = None
        any_12: "b8[20]" = torch.ops.aten.any.dim(select_35, -1);  select_35 = None
        sum_10: "i64[]" = torch.ops.aten.sum.default(any_12);  any_12 = sum_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_21: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_14: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_97: "i64[1, 1]" = torch.ops.aten.reshape.default(add_262, [-1, 1])
        gt_7: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_14, reshape_97);  arange_14 = reshape_97 = None
        mul__7: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_21, gt_7);  full_21 = gt_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_48: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__7, 0);  mul__7 = None
        unsqueeze_49: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_48, 1);  unsqueeze_48 = None
        slice_955: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_49, 2, 0, 9223372036854775807);  unsqueeze_49 = None
        slice_956: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_955, 3, 0, 9223372036854775807);  slice_955 = None
        expand_16: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_956, [1, 1, -1, -1]);  slice_956 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_391: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_284, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_117: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_391, 0.125);  linear_391 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_207: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_117, [1, 1, 8, 64]);  mul_117 = None
        transpose_378: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_207, 1, 2);  view_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_392: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_284, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_208: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_392, [1, -1, 8, 64]);  linear_392 = None
        transpose_379: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_208, 1, 2);  view_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_393: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_284, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_209: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_393, [1, -1, 8, 64]);  linear_393 = None
        transpose_380: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_209, 1, 2);  view_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_145: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_379, torch.float32);  transpose_379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_146: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_380, torch.float32);  transpose_380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_957: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__96: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_957, 2, add_262, to_145);  slice_957 = to_145 = index_copy__96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_958: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__97: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_958, 2, add_262, to_146);  slice_958 = to_146 = index_copy__97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_959: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_960: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_959, 2, 0, 9223372036854775807);  slice_959 = None
        slice_961: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_960, 3, 0, 9223372036854775807);  slice_960 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_962: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_963: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_962, 2, 0, 9223372036854775807);  slice_962 = None
        slice_964: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_963, 3, 0, 9223372036854775807);  slice_963 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_381: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_961, 2, 3);  slice_961 = None
        matmul_180: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_378, transpose_381);  transpose_378 = transpose_381 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_965: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_16, 0, 0, 9223372036854775807)
        slice_966: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_965, 1, 0, 9223372036854775807);  slice_965 = None
        slice_967: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_966, 2, 0, 9223372036854775807);  slice_966 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_266: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_180, slice_967);  matmul_180 = slice_967 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_90: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_266, -1);  add_266 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_285: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_90, 0.0, False);  softmax_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_181: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_285, slice_964);  dropout_285 = slice_964 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_382: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_181, 1, 2);  matmul_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_98: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_382, [1, 1, 512]);  transpose_382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_394: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_98, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_286: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_394, 0.1, False);  linear_394 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_267: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_284, dropout_286);  dropout_284 = dropout_286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_138: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_267, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_395: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_138, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_118: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_395, 0.125);  linear_395 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_210: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_118, [1, 1, 8, 64]);  mul_118 = None
        transpose_383: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_210, 1, 2);  view_210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_968: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_969: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_968, 2, 0, 23);  slice_968 = None
        slice_970: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_969, 3, 0, 9223372036854775807);  slice_969 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_971: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_972: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_971, 2, 0, 23);  slice_971 = None
        slice_973: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_972, 3, 0, 9223372036854775807);  slice_972 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_384: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_970, 2, 3);  slice_970 = None
        matmul_182: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_383, transpose_384);  transpose_383 = transpose_384 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_974: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_8, 0, 0, 9223372036854775807)
        slice_975: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_974, 1, 0, 9223372036854775807);  slice_974 = None
        slice_976: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_975, 2, 0, 9223372036854775807);  slice_975 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_268: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_182, slice_976);  matmul_182 = slice_976 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_91: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_268, -1);  add_268 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_287: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_91, 0.0, False);  softmax_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_183: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_287, slice_973);  dropout_287 = slice_973 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_385: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_183, 1, 2);  matmul_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_99: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_385, [1, 1, 512]);  transpose_385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_396: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_99, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_288: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_396, 0.1, False);  linear_396 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_269: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_138, dropout_288);  layer_norm_138 = dropout_288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_139: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_269, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_397: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_139, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_48: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_397);  linear_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_289: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_48, 0.0, False);  silu_48 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_398: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_289, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_290: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_398, 0.1, False);  linear_398 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_270: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_139, dropout_290);  layer_norm_139 = dropout_290 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_140: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_270, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_399: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_140, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_119: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_399, 0.125);  linear_399 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_211: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_119, [1, 1, 8, 64]);  mul_119 = None
        transpose_386: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_211, 1, 2);  view_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_400: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_140, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_212: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_400, [1, -1, 8, 64]);  linear_400 = None
        transpose_387: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_212, 1, 2);  view_212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_401: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_140, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_213: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_401, [1, -1, 8, 64]);  linear_401 = None
        transpose_388: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_213, 1, 2);  view_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_147: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_387, torch.float32);  transpose_387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_148: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_388, torch.float32);  transpose_388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_977: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__98: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_977, 2, add_262, to_147);  slice_977 = to_147 = index_copy__98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_978: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__99: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_978, 2, add_262, to_148);  slice_978 = to_148 = index_copy__99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_979: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_980: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_979, 2, 0, 9223372036854775807);  slice_979 = None
        slice_981: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_980, 3, 0, 9223372036854775807);  slice_980 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_982: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_983: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_982, 2, 0, 9223372036854775807);  slice_982 = None
        slice_984: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_983, 3, 0, 9223372036854775807);  slice_983 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_389: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_981, 2, 3);  slice_981 = None
        matmul_184: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_386, transpose_389);  transpose_386 = transpose_389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_985: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_16, 0, 0, 9223372036854775807)
        slice_986: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_985, 1, 0, 9223372036854775807);  slice_985 = None
        slice_987: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_986, 2, 0, 9223372036854775807);  slice_986 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_271: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_184, slice_987);  matmul_184 = slice_987 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_92: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_271, -1);  add_271 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_291: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_92, 0.0, False);  softmax_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_185: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_291, slice_984);  dropout_291 = slice_984 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_390: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_185, 1, 2);  matmul_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_100: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_390, [1, 1, 512]);  transpose_390 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_402: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_100, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_292: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_402, 0.1, False);  linear_402 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_272: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_140, dropout_292);  layer_norm_140 = dropout_292 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_141: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_272, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_272 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_403: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_141, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_120: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_403, 0.125);  linear_403 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_214: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_120, [1, 1, 8, 64]);  mul_120 = None
        transpose_391: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_214, 1, 2);  view_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_988: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_989: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_988, 2, 0, 23);  slice_988 = None
        slice_990: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_989, 3, 0, 9223372036854775807);  slice_989 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_991: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_992: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_991, 2, 0, 23);  slice_991 = None
        slice_993: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_992, 3, 0, 9223372036854775807);  slice_992 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_392: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_990, 2, 3);  slice_990 = None
        matmul_186: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_391, transpose_392);  transpose_391 = transpose_392 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_994: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_8, 0, 0, 9223372036854775807)
        slice_995: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_994, 1, 0, 9223372036854775807);  slice_994 = None
        slice_996: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_995, 2, 0, 9223372036854775807);  slice_995 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_273: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_186, slice_996);  matmul_186 = slice_996 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_93: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_273, -1);  add_273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_293: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_93, 0.0, False);  softmax_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_187: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_293, slice_993);  dropout_293 = slice_993 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_393: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_187, 1, 2);  matmul_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_101: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_393, [1, 1, 512]);  transpose_393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_404: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_101, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_294: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_404, 0.1, False);  linear_404 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_274: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_141, dropout_294);  layer_norm_141 = dropout_294 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_142: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_274, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_274 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_405: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_142, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_49: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_405);  linear_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_295: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_49, 0.0, False);  silu_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_406: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_295, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_296: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_406, 0.1, False);  linear_406 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_275: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_142, dropout_296);  layer_norm_142 = dropout_296 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_143: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_275, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_407: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_143, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_121: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_407, 0.125);  linear_407 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_215: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_121, [1, 1, 8, 64]);  mul_121 = None
        transpose_394: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_215, 1, 2);  view_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_408: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_143, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_216: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_408, [1, -1, 8, 64]);  linear_408 = None
        transpose_395: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_216, 1, 2);  view_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_409: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_143, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_217: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_409, [1, -1, 8, 64]);  linear_409 = None
        transpose_396: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_217, 1, 2);  view_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_149: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_395, torch.float32);  transpose_395 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_150: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_396, torch.float32);  transpose_396 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_997: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__100: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_997, 2, add_262, to_149);  slice_997 = to_149 = index_copy__100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_998: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__101: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_998, 2, add_262, to_150);  slice_998 = to_150 = index_copy__101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_999: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1000: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_999, 2, 0, 9223372036854775807);  slice_999 = None
        slice_1001: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1000, 3, 0, 9223372036854775807);  slice_1000 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1002: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1003: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1002, 2, 0, 9223372036854775807);  slice_1002 = None
        slice_1004: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1003, 3, 0, 9223372036854775807);  slice_1003 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_397: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1001, 2, 3);  slice_1001 = None
        matmul_188: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_394, transpose_397);  transpose_394 = transpose_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1005: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_16, 0, 0, 9223372036854775807)
        slice_1006: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1005, 1, 0, 9223372036854775807);  slice_1005 = None
        slice_1007: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1006, 2, 0, 9223372036854775807);  slice_1006 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_276: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_188, slice_1007);  matmul_188 = slice_1007 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_94: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_276, -1);  add_276 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_297: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_94, 0.0, False);  softmax_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_189: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_297, slice_1004);  dropout_297 = slice_1004 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_398: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_189, 1, 2);  matmul_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_102: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_398, [1, 1, 512]);  transpose_398 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_410: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_102, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_298: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_410, 0.1, False);  linear_410 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_277: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_143, dropout_298);  layer_norm_143 = dropout_298 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_144: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_277, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_411: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_144, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_122: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_411, 0.125);  linear_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_218: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_122, [1, 1, 8, 64]);  mul_122 = None
        transpose_399: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_218, 1, 2);  view_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1008: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1009: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1008, 2, 0, 23);  slice_1008 = None
        slice_1010: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1009, 3, 0, 9223372036854775807);  slice_1009 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1011: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1012: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1011, 2, 0, 23);  slice_1011 = None
        slice_1013: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1012, 3, 0, 9223372036854775807);  slice_1012 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_400: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1010, 2, 3);  slice_1010 = None
        matmul_190: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_399, transpose_400);  transpose_399 = transpose_400 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1014: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_8, 0, 0, 9223372036854775807)
        slice_1015: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1014, 1, 0, 9223372036854775807);  slice_1014 = None
        slice_1016: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1015, 2, 0, 9223372036854775807);  slice_1015 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_278: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_190, slice_1016);  matmul_190 = slice_1016 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_95: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_278, -1);  add_278 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_299: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_95, 0.0, False);  softmax_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_191: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_299, slice_1013);  dropout_299 = slice_1013 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_401: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_191, 1, 2);  matmul_191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_103: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_401, [1, 1, 512]);  transpose_401 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_412: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_103, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_300: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_412, 0.1, False);  linear_412 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_279: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_144, dropout_300);  layer_norm_144 = dropout_300 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_145: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_279, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_279 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_413: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_145, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_50: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_413);  linear_413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_301: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_50, 0.0, False);  silu_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_414: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_301, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_302: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_414, 0.1, False);  linear_414 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_280: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_145, dropout_302);  layer_norm_145 = dropout_302 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_146: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_280, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_280 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_415: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_146, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_123: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_415, 0.125);  linear_415 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_219: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_123, [1, 1, 8, 64]);  mul_123 = None
        transpose_402: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_219, 1, 2);  view_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_416: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_146, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_220: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_416, [1, -1, 8, 64]);  linear_416 = None
        transpose_403: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_220, 1, 2);  view_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_417: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_146, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_221: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_417, [1, -1, 8, 64]);  linear_417 = None
        transpose_404: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_221, 1, 2);  view_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_151: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_403, torch.float32);  transpose_403 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_152: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_404, torch.float32);  transpose_404 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1017: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__102: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1017, 2, add_262, to_151);  slice_1017 = to_151 = index_copy__102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1018: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__103: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1018, 2, add_262, to_152);  slice_1018 = to_152 = index_copy__103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1019: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1020: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1019, 2, 0, 9223372036854775807);  slice_1019 = None
        slice_1021: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1020, 3, 0, 9223372036854775807);  slice_1020 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1022: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1023: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1022, 2, 0, 9223372036854775807);  slice_1022 = None
        slice_1024: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1023, 3, 0, 9223372036854775807);  slice_1023 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_405: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1021, 2, 3);  slice_1021 = None
        matmul_192: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_402, transpose_405);  transpose_402 = transpose_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1025: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_16, 0, 0, 9223372036854775807)
        slice_1026: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1025, 1, 0, 9223372036854775807);  slice_1025 = None
        slice_1027: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1026, 2, 0, 9223372036854775807);  slice_1026 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_281: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_192, slice_1027);  matmul_192 = slice_1027 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_96: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_281, -1);  add_281 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_303: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_96, 0.0, False);  softmax_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_193: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_303, slice_1024);  dropout_303 = slice_1024 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_406: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_193, 1, 2);  matmul_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_104: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_406, [1, 1, 512]);  transpose_406 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_418: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_104, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_304: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_418, 0.1, False);  linear_418 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_282: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_146, dropout_304);  layer_norm_146 = dropout_304 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_147: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_282, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_282 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_419: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_147, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_124: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_419, 0.125);  linear_419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_222: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_124, [1, 1, 8, 64]);  mul_124 = None
        transpose_407: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_222, 1, 2);  view_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1028: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1029: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1028, 2, 0, 23);  slice_1028 = None
        slice_1030: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1029, 3, 0, 9223372036854775807);  slice_1029 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1031: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1032: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1031, 2, 0, 23);  slice_1031 = None
        slice_1033: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1032, 3, 0, 9223372036854775807);  slice_1032 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_408: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1030, 2, 3);  slice_1030 = None
        matmul_194: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_407, transpose_408);  transpose_407 = transpose_408 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1034: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_8, 0, 0, 9223372036854775807)
        slice_1035: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1034, 1, 0, 9223372036854775807);  slice_1034 = None
        slice_1036: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1035, 2, 0, 9223372036854775807);  slice_1035 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_283: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_194, slice_1036);  matmul_194 = slice_1036 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_97: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_283, -1);  add_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_305: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_97, 0.0, False);  softmax_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_195: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_305, slice_1033);  dropout_305 = slice_1033 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_409: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_195, 1, 2);  matmul_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_105: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_409, [1, 1, 512]);  transpose_409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_420: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_105, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_306: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_420, 0.1, False);  linear_420 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_284: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_147, dropout_306);  layer_norm_147 = dropout_306 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_148: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_284, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_284 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_421: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_148, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_51: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_421);  linear_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_307: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_51, 0.0, False);  silu_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_422: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_307, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_307 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_308: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_422, 0.1, False);  linear_422 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_285: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_148, dropout_308);  layer_norm_148 = dropout_308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_149: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_285, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_423: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_149, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_125: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_423, 0.125);  linear_423 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_223: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_125, [1, 1, 8, 64]);  mul_125 = None
        transpose_410: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_223, 1, 2);  view_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_424: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_149, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_224: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_424, [1, -1, 8, 64]);  linear_424 = None
        transpose_411: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_224, 1, 2);  view_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_425: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_149, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_225: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_425, [1, -1, 8, 64]);  linear_425 = None
        transpose_412: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_225, 1, 2);  view_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_153: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_411, torch.float32);  transpose_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_154: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_412, torch.float32);  transpose_412 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1037: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__104: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1037, 2, add_262, to_153);  slice_1037 = to_153 = index_copy__104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1038: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__105: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1038, 2, add_262, to_154);  slice_1038 = to_154 = index_copy__105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1039: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1040: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1039, 2, 0, 9223372036854775807);  slice_1039 = None
        slice_1041: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1040, 3, 0, 9223372036854775807);  slice_1040 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1042: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1043: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1042, 2, 0, 9223372036854775807);  slice_1042 = None
        slice_1044: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1043, 3, 0, 9223372036854775807);  slice_1043 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_413: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1041, 2, 3);  slice_1041 = None
        matmul_196: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_410, transpose_413);  transpose_410 = transpose_413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1045: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_16, 0, 0, 9223372036854775807)
        slice_1046: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1045, 1, 0, 9223372036854775807);  slice_1045 = None
        slice_1047: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1046, 2, 0, 9223372036854775807);  slice_1046 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_286: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_196, slice_1047);  matmul_196 = slice_1047 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_98: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_286, -1);  add_286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_309: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_98, 0.0, False);  softmax_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_197: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_309, slice_1044);  dropout_309 = slice_1044 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_414: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_197, 1, 2);  matmul_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_106: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_414, [1, 1, 512]);  transpose_414 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_426: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_106, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_310: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_426, 0.1, False);  linear_426 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_287: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_149, dropout_310);  layer_norm_149 = dropout_310 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_150: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_287, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_287 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_427: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_150, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_126: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_427, 0.125);  linear_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_226: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_126, [1, 1, 8, 64]);  mul_126 = None
        transpose_415: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_226, 1, 2);  view_226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1048: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1049: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1048, 2, 0, 23);  slice_1048 = None
        slice_1050: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1049, 3, 0, 9223372036854775807);  slice_1049 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1051: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1052: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1051, 2, 0, 23);  slice_1051 = None
        slice_1053: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1052, 3, 0, 9223372036854775807);  slice_1052 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_416: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1050, 2, 3);  slice_1050 = None
        matmul_198: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_415, transpose_416);  transpose_415 = transpose_416 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1054: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_8, 0, 0, 9223372036854775807)
        slice_1055: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1054, 1, 0, 9223372036854775807);  slice_1054 = None
        slice_1056: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1055, 2, 0, 9223372036854775807);  slice_1055 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_288: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_198, slice_1056);  matmul_198 = slice_1056 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_99: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_288, -1);  add_288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_311: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_99, 0.0, False);  softmax_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_199: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_311, slice_1053);  dropout_311 = slice_1053 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_417: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_199, 1, 2);  matmul_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_107: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_417, [1, 1, 512]);  transpose_417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_428: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_107, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_312: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_428, 0.1, False);  linear_428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_289: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_150, dropout_312);  layer_norm_150 = dropout_312 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_151: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_289, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_429: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_151, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_52: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_429);  linear_429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_313: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_52, 0.0, False);  silu_52 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_430: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_313, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_314: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_430, 0.1, False);  linear_430 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_290: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_151, dropout_314);  layer_norm_151 = dropout_314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_152: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_290, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_290 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_431: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_152, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_127: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_431, 0.125);  linear_431 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_227: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_127, [1, 1, 8, 64]);  mul_127 = None
        transpose_418: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_227, 1, 2);  view_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_432: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_152, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_228: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_432, [1, -1, 8, 64]);  linear_432 = None
        transpose_419: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_228, 1, 2);  view_228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_433: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_152, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_229: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_433, [1, -1, 8, 64]);  linear_433 = None
        transpose_420: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_229, 1, 2);  view_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_155: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_419, torch.float32);  transpose_419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_156: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_420, torch.float32);  transpose_420 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1057: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__106: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1057, 2, add_262, to_155);  slice_1057 = to_155 = index_copy__106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1058: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__107: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1058, 2, add_262, to_156);  slice_1058 = to_156 = index_copy__107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1059: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1060: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1059, 2, 0, 9223372036854775807);  slice_1059 = None
        slice_1061: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1060, 3, 0, 9223372036854775807);  slice_1060 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1062: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1063: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1062, 2, 0, 9223372036854775807);  slice_1062 = None
        slice_1064: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1063, 3, 0, 9223372036854775807);  slice_1063 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_421: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1061, 2, 3);  slice_1061 = None
        matmul_200: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_418, transpose_421);  transpose_418 = transpose_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1065: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_16, 0, 0, 9223372036854775807);  expand_16 = None
        slice_1066: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1065, 1, 0, 9223372036854775807);  slice_1065 = None
        slice_1067: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1066, 2, 0, 9223372036854775807);  slice_1066 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_291: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_200, slice_1067);  matmul_200 = slice_1067 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_100: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_291, -1);  add_291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_315: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_100, 0.0, False);  softmax_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_201: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_315, slice_1064);  dropout_315 = slice_1064 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_422: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_201, 1, 2);  matmul_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_108: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_422, [1, 1, 512]);  transpose_422 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_434: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_108, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_316: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_434, 0.1, False);  linear_434 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_292: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_152, dropout_316);  layer_norm_152 = dropout_316 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_153: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_292, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_292 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_435: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_153, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_128: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_435, 0.125);  linear_435 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_230: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_128, [1, 1, 8, 64]);  mul_128 = None
        transpose_423: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_230, 1, 2);  view_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1068: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1069: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1068, 2, 0, 23);  slice_1068 = None
        slice_1070: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1069, 3, 0, 9223372036854775807);  slice_1069 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1071: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1072: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1071, 2, 0, 23);  slice_1071 = None
        slice_1073: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1072, 3, 0, 9223372036854775807);  slice_1072 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_424: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1070, 2, 3);  slice_1070 = None
        matmul_202: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_423, transpose_424);  transpose_423 = transpose_424 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1074: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_8, 0, 0, 9223372036854775807);  masked_fill_8 = None
        slice_1075: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1074, 1, 0, 9223372036854775807);  slice_1074 = None
        slice_1076: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1075, 2, 0, 9223372036854775807);  slice_1075 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_293: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_202, slice_1076);  matmul_202 = slice_1076 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_101: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_293, -1);  add_293 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_317: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_101, 0.0, False);  softmax_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_203: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_317, slice_1073);  dropout_317 = slice_1073 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_425: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_203, 1, 2);  matmul_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_109: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_425, [1, 1, 512]);  transpose_425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_436: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_109, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_318: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_436, 0.1, False);  linear_436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_294: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_153, dropout_318);  layer_norm_153 = dropout_318 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_154: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_294, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_294 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_437: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_154, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_53: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_437);  linear_437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_319: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_53, 0.0, False);  silu_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_438: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_319, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_319 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_320: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_438, 0.1, False);  linear_438 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_295: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_154, dropout_320);  layer_norm_154 = dropout_320 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_155: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_295, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_439: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_155, p_model_lm_head_weight);  layer_norm_155 = None
        add_296: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_439, b_model_final_logits_bias);  linear_439 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1077: "i64[1]" = torch.ops.aten.slice.Tensor(add_262, 0, -1, 9223372036854775807);  add_262 = None
        add_297: "i64[1]" = torch.ops.aten.add.Tensor(slice_1077, 1);  slice_1077 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1078: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_296, 0, 0, 9223372036854775807);  add_296 = None
        select_36: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1078, 1, -1);  slice_1078 = None
        slice_1079: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_36, 1, 0, 9223372036854775807);  select_36 = None
        clone_15: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1079);  slice_1079 = None
        to_157: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_15, torch.float32);  clone_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_158: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_157, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_7: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_158, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__7: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_7, to_32);  zeros_like_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_298: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_158, add__7);  to_158 = add__7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_7: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_298, -1);  add_298 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_7: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_7, -1);  log_softmax_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_129: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_7, and_7);  argmax_7 = None
        rsub_16: "i64[1]" = torch.ops.aten.rsub.Scalar(and_7, 1)
        mul_130: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_16);  rsub_16 = None
        add_299: "i64[1]" = torch.ops.aten.add.Tensor(mul_129, mul_130);  mul_129 = mul_130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1080: "i64[1]" = torch.ops.aten.slice.Tensor(add_299, 0, 0, 9223372036854775807);  add_299 = None
        unsqueeze_50: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1080, 1);  slice_1080 = None
        cat_7: "i64[1, 9]" = torch.ops.aten.cat.default([cat_6, unsqueeze_50], -1);  cat_6 = unsqueeze_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_22: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_23: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_15: "b8[1]" = torch.ops.aten.__or__.Tensor(full_22, full_23);  full_22 = full_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_159: "i64[1]" = torch.ops.aten.to.dtype_layout(to_141, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1081: "i64[1, 9]" = torch.ops.aten.slice.Tensor(cat_7, 0, 0, 9223372036854775807)
        select_37: "i64[1]" = torch.ops.aten.select.int(slice_1081, 1, -1);  slice_1081 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_9: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_37, to_159);  select_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_16: "b8[1]" = torch.ops.aten.__or__.Tensor(or_15, isin_9);  or_15 = isin_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_9: "b8[1]" = torch.ops.aten.bitwise_not.default(or_16);  or_16 = None
        and_8: "i64[1]" = torch.ops.aten.__and__.Tensor(and_7, bitwise_not_9);  and_7 = bitwise_not_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_8: "i64[]" = torch.ops.aten.max.default(and_8)
        eq_7: "b8[]" = torch.ops.aten.eq.Scalar(max_8, 0);  max_8 = eq_7 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1082: "i64[1, 9]" = torch.ops.aten.slice.Tensor(cat_7, 0, 0, 9223372036854775807)
        slice_1083: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1082, 1, -1, 9223372036854775807);  slice_1082 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_16: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1083, memory_format = torch.contiguous_format);  slice_1083 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_231: "i64[1, 1]" = torch.ops.aten.view.default(clone_16, [-1, 1]);  clone_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_18: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_231, 59513);  view_231 = None
        mul_131: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_18, 22.627416997969522);  embedding_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_51: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_297, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1084: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_52: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1084, 1);  slice_1084 = None
        unsqueeze_53: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_52, 2);  unsqueeze_52 = None
        slice_1085: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_53, 3, 0, 9223372036854775807);  unsqueeze_53 = None
        expand_17: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1085, [1, 1, 1, 23]);  slice_1085 = None
        to_160: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_17, torch.float32);  expand_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_17: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_160, 1.0);  to_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_161: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_17, torch.bool)
        masked_fill_9: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_17, to_161, -3.4028234663852886e+38);  rsub_17 = to_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_19: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_51);  unsqueeze_51 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_162: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_19, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_19 = None
        add_300: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_131, to_162);  mul_131 = to_162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_321: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_300, 0.1, False);  add_300 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_38: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_39: "f32[20, 64]" = torch.ops.aten.select.int(select_38, 0, 0);  select_38 = None
        any_13: "b8[20]" = torch.ops.aten.any.dim(select_39, -1);  select_39 = None
        sum_11: "i64[]" = torch.ops.aten.sum.default(any_13);  any_13 = sum_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_24: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_15: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_110: "i64[1, 1]" = torch.ops.aten.reshape.default(add_297, [-1, 1])
        gt_8: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_15, reshape_110);  arange_15 = reshape_110 = None
        mul__8: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_24, gt_8);  full_24 = gt_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_54: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__8, 0);  mul__8 = None
        unsqueeze_55: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_54, 1);  unsqueeze_54 = None
        slice_1086: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_55, 2, 0, 9223372036854775807);  unsqueeze_55 = None
        slice_1087: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1086, 3, 0, 9223372036854775807);  slice_1086 = None
        expand_18: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1087, [1, 1, -1, -1]);  slice_1087 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_440: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_321, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_132: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_440, 0.125);  linear_440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_232: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_132, [1, 1, 8, 64]);  mul_132 = None
        transpose_426: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_232, 1, 2);  view_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_441: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_321, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_233: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_441, [1, -1, 8, 64]);  linear_441 = None
        transpose_427: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_233, 1, 2);  view_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_442: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_321, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_234: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_442, [1, -1, 8, 64]);  linear_442 = None
        transpose_428: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_234, 1, 2);  view_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_163: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_427, torch.float32);  transpose_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_164: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_428, torch.float32);  transpose_428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1088: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__108: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1088, 2, add_297, to_163);  slice_1088 = to_163 = index_copy__108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1089: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__109: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1089, 2, add_297, to_164);  slice_1089 = to_164 = index_copy__109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1090: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1091: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1090, 2, 0, 9223372036854775807);  slice_1090 = None
        slice_1092: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1091, 3, 0, 9223372036854775807);  slice_1091 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1093: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1094: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1093, 2, 0, 9223372036854775807);  slice_1093 = None
        slice_1095: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1094, 3, 0, 9223372036854775807);  slice_1094 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_429: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1092, 2, 3);  slice_1092 = None
        matmul_204: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_426, transpose_429);  transpose_426 = transpose_429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1096: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_18, 0, 0, 9223372036854775807)
        slice_1097: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1096, 1, 0, 9223372036854775807);  slice_1096 = None
        slice_1098: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1097, 2, 0, 9223372036854775807);  slice_1097 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_301: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_204, slice_1098);  matmul_204 = slice_1098 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_102: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_301, -1);  add_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_322: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_102, 0.0, False);  softmax_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_205: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_322, slice_1095);  dropout_322 = slice_1095 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_430: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_205, 1, 2);  matmul_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_111: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_430, [1, 1, 512]);  transpose_430 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_443: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_111, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_323: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_443, 0.1, False);  linear_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_302: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_321, dropout_323);  dropout_321 = dropout_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_156: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_302, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_302 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_444: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_156, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_133: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_444, 0.125);  linear_444 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_235: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_133, [1, 1, 8, 64]);  mul_133 = None
        transpose_431: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_235, 1, 2);  view_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1099: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1100: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1099, 2, 0, 23);  slice_1099 = None
        slice_1101: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1100, 3, 0, 9223372036854775807);  slice_1100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1102: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1103: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1102, 2, 0, 23);  slice_1102 = None
        slice_1104: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1103, 3, 0, 9223372036854775807);  slice_1103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_432: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1101, 2, 3);  slice_1101 = None
        matmul_206: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_431, transpose_432);  transpose_431 = transpose_432 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1105: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_9, 0, 0, 9223372036854775807)
        slice_1106: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1105, 1, 0, 9223372036854775807);  slice_1105 = None
        slice_1107: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1106, 2, 0, 9223372036854775807);  slice_1106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_303: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_206, slice_1107);  matmul_206 = slice_1107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_103: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_303, -1);  add_303 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_324: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_103, 0.0, False);  softmax_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_207: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_324, slice_1104);  dropout_324 = slice_1104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_433: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_207, 1, 2);  matmul_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_112: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_433, [1, 1, 512]);  transpose_433 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_445: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_112, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_325: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_445, 0.1, False);  linear_445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_304: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_156, dropout_325);  layer_norm_156 = dropout_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_157: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_304, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_304 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_446: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_157, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_54: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_446);  linear_446 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_326: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_54, 0.0, False);  silu_54 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_447: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_326, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_326 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_327: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_447, 0.1, False);  linear_447 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_305: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_157, dropout_327);  layer_norm_157 = dropout_327 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_158: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_305, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_448: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_158, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_134: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_448, 0.125);  linear_448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_236: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_134, [1, 1, 8, 64]);  mul_134 = None
        transpose_434: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_236, 1, 2);  view_236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_449: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_158, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_237: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_449, [1, -1, 8, 64]);  linear_449 = None
        transpose_435: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_237, 1, 2);  view_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_450: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_158, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_238: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_450, [1, -1, 8, 64]);  linear_450 = None
        transpose_436: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_238, 1, 2);  view_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_165: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_435, torch.float32);  transpose_435 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_166: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_436, torch.float32);  transpose_436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1108: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__110: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1108, 2, add_297, to_165);  slice_1108 = to_165 = index_copy__110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1109: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__111: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1109, 2, add_297, to_166);  slice_1109 = to_166 = index_copy__111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1110: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1111: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1110, 2, 0, 9223372036854775807);  slice_1110 = None
        slice_1112: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1111, 3, 0, 9223372036854775807);  slice_1111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1113: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1114: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1113, 2, 0, 9223372036854775807);  slice_1113 = None
        slice_1115: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1114, 3, 0, 9223372036854775807);  slice_1114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_437: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1112, 2, 3);  slice_1112 = None
        matmul_208: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_434, transpose_437);  transpose_434 = transpose_437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1116: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_18, 0, 0, 9223372036854775807)
        slice_1117: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1116, 1, 0, 9223372036854775807);  slice_1116 = None
        slice_1118: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1117, 2, 0, 9223372036854775807);  slice_1117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_306: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_208, slice_1118);  matmul_208 = slice_1118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_104: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_306, -1);  add_306 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_328: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_104, 0.0, False);  softmax_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_209: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_328, slice_1115);  dropout_328 = slice_1115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_438: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_209, 1, 2);  matmul_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_113: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_438, [1, 1, 512]);  transpose_438 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_451: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_113, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_329: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_451, 0.1, False);  linear_451 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_307: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_158, dropout_329);  layer_norm_158 = dropout_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_159: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_307, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_307 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_452: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_159, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_135: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_452, 0.125);  linear_452 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_239: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_135, [1, 1, 8, 64]);  mul_135 = None
        transpose_439: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_239, 1, 2);  view_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1119: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1120: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1119, 2, 0, 23);  slice_1119 = None
        slice_1121: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1120, 3, 0, 9223372036854775807);  slice_1120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1122: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1123: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1122, 2, 0, 23);  slice_1122 = None
        slice_1124: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1123, 3, 0, 9223372036854775807);  slice_1123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_440: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1121, 2, 3);  slice_1121 = None
        matmul_210: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_439, transpose_440);  transpose_439 = transpose_440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1125: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_9, 0, 0, 9223372036854775807)
        slice_1126: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1125, 1, 0, 9223372036854775807);  slice_1125 = None
        slice_1127: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1126, 2, 0, 9223372036854775807);  slice_1126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_308: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_210, slice_1127);  matmul_210 = slice_1127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_105: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_308, -1);  add_308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_330: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_105, 0.0, False);  softmax_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_211: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_330, slice_1124);  dropout_330 = slice_1124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_441: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_211, 1, 2);  matmul_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_114: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_441, [1, 1, 512]);  transpose_441 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_453: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_114, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_331: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_453, 0.1, False);  linear_453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_309: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_159, dropout_331);  layer_norm_159 = dropout_331 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_160: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_309, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_454: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_160, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_55: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_454);  linear_454 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_332: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_55, 0.0, False);  silu_55 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_455: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_332, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_332 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_333: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_455, 0.1, False);  linear_455 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_310: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_160, dropout_333);  layer_norm_160 = dropout_333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_161: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_310, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_310 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_456: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_161, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_136: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_456, 0.125);  linear_456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_240: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_136, [1, 1, 8, 64]);  mul_136 = None
        transpose_442: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_240, 1, 2);  view_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_457: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_161, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_241: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_457, [1, -1, 8, 64]);  linear_457 = None
        transpose_443: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_241, 1, 2);  view_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_458: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_161, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_242: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_458, [1, -1, 8, 64]);  linear_458 = None
        transpose_444: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_242, 1, 2);  view_242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_167: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_443, torch.float32);  transpose_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_168: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_444, torch.float32);  transpose_444 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1128: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__112: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1128, 2, add_297, to_167);  slice_1128 = to_167 = index_copy__112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1129: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__113: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1129, 2, add_297, to_168);  slice_1129 = to_168 = index_copy__113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1130: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1131: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1130, 2, 0, 9223372036854775807);  slice_1130 = None
        slice_1132: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1131, 3, 0, 9223372036854775807);  slice_1131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1133: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1134: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1133, 2, 0, 9223372036854775807);  slice_1133 = None
        slice_1135: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1134, 3, 0, 9223372036854775807);  slice_1134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_445: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1132, 2, 3);  slice_1132 = None
        matmul_212: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_442, transpose_445);  transpose_442 = transpose_445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1136: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_18, 0, 0, 9223372036854775807)
        slice_1137: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1136, 1, 0, 9223372036854775807);  slice_1136 = None
        slice_1138: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1137, 2, 0, 9223372036854775807);  slice_1137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_311: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_212, slice_1138);  matmul_212 = slice_1138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_106: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_311, -1);  add_311 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_334: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_106, 0.0, False);  softmax_106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_213: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_334, slice_1135);  dropout_334 = slice_1135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_446: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_213, 1, 2);  matmul_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_115: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_446, [1, 1, 512]);  transpose_446 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_459: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_115, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_335: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_459, 0.1, False);  linear_459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_312: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_161, dropout_335);  layer_norm_161 = dropout_335 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_162: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_312, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_312 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_460: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_162, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_137: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_460, 0.125);  linear_460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_243: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_137, [1, 1, 8, 64]);  mul_137 = None
        transpose_447: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_243, 1, 2);  view_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1139: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1140: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1139, 2, 0, 23);  slice_1139 = None
        slice_1141: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1140, 3, 0, 9223372036854775807);  slice_1140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1142: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1143: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1142, 2, 0, 23);  slice_1142 = None
        slice_1144: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1143, 3, 0, 9223372036854775807);  slice_1143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_448: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1141, 2, 3);  slice_1141 = None
        matmul_214: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_447, transpose_448);  transpose_447 = transpose_448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1145: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_9, 0, 0, 9223372036854775807)
        slice_1146: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1145, 1, 0, 9223372036854775807);  slice_1145 = None
        slice_1147: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1146, 2, 0, 9223372036854775807);  slice_1146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_313: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_214, slice_1147);  matmul_214 = slice_1147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_107: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_313, -1);  add_313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_336: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_107, 0.0, False);  softmax_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_215: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_336, slice_1144);  dropout_336 = slice_1144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_449: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_215, 1, 2);  matmul_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_116: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_449, [1, 1, 512]);  transpose_449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_461: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_116, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_337: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_461, 0.1, False);  linear_461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_314: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_162, dropout_337);  layer_norm_162 = dropout_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_163: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_314, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_462: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_163, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_56: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_462);  linear_462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_338: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_56, 0.0, False);  silu_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_463: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_338, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_338 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_339: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_463, 0.1, False);  linear_463 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_315: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_163, dropout_339);  layer_norm_163 = dropout_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_164: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_315, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_315 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_464: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_164, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_138: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_464, 0.125);  linear_464 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_244: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_138, [1, 1, 8, 64]);  mul_138 = None
        transpose_450: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_244, 1, 2);  view_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_465: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_164, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_245: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_465, [1, -1, 8, 64]);  linear_465 = None
        transpose_451: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_245, 1, 2);  view_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_466: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_164, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_246: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_466, [1, -1, 8, 64]);  linear_466 = None
        transpose_452: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_246, 1, 2);  view_246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_169: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_451, torch.float32);  transpose_451 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_170: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_452, torch.float32);  transpose_452 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1148: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__114: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1148, 2, add_297, to_169);  slice_1148 = to_169 = index_copy__114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1149: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__115: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1149, 2, add_297, to_170);  slice_1149 = to_170 = index_copy__115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1150: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1151: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1150, 2, 0, 9223372036854775807);  slice_1150 = None
        slice_1152: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1151, 3, 0, 9223372036854775807);  slice_1151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1153: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1154: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1153, 2, 0, 9223372036854775807);  slice_1153 = None
        slice_1155: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1154, 3, 0, 9223372036854775807);  slice_1154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_453: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1152, 2, 3);  slice_1152 = None
        matmul_216: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_450, transpose_453);  transpose_450 = transpose_453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1156: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_18, 0, 0, 9223372036854775807)
        slice_1157: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1156, 1, 0, 9223372036854775807);  slice_1156 = None
        slice_1158: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1157, 2, 0, 9223372036854775807);  slice_1157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_316: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_216, slice_1158);  matmul_216 = slice_1158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_108: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_316, -1);  add_316 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_340: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_108, 0.0, False);  softmax_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_217: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_340, slice_1155);  dropout_340 = slice_1155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_454: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_217, 1, 2);  matmul_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_117: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_454, [1, 1, 512]);  transpose_454 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_467: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_117, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_341: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_467, 0.1, False);  linear_467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_317: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_164, dropout_341);  layer_norm_164 = dropout_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_165: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_317, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_468: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_165, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_139: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_468, 0.125);  linear_468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_247: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_139, [1, 1, 8, 64]);  mul_139 = None
        transpose_455: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_247, 1, 2);  view_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1159: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1160: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1159, 2, 0, 23);  slice_1159 = None
        slice_1161: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1160, 3, 0, 9223372036854775807);  slice_1160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1162: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1163: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1162, 2, 0, 23);  slice_1162 = None
        slice_1164: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1163, 3, 0, 9223372036854775807);  slice_1163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_456: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1161, 2, 3);  slice_1161 = None
        matmul_218: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_455, transpose_456);  transpose_455 = transpose_456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1165: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_9, 0, 0, 9223372036854775807)
        slice_1166: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1165, 1, 0, 9223372036854775807);  slice_1165 = None
        slice_1167: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1166, 2, 0, 9223372036854775807);  slice_1166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_318: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_218, slice_1167);  matmul_218 = slice_1167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_109: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_318, -1);  add_318 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_342: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_109, 0.0, False);  softmax_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_219: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_342, slice_1164);  dropout_342 = slice_1164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_457: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_219, 1, 2);  matmul_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_118: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_457, [1, 1, 512]);  transpose_457 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_469: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_118, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_343: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_469, 0.1, False);  linear_469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_319: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_165, dropout_343);  layer_norm_165 = dropout_343 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_166: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_319, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_319 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_470: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_166, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_57: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_470);  linear_470 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_344: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_57, 0.0, False);  silu_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_471: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_344, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_344 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_345: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_471, 0.1, False);  linear_471 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_320: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_166, dropout_345);  layer_norm_166 = dropout_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_167: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_320, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_320 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_472: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_167, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_140: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_472, 0.125);  linear_472 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_248: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_140, [1, 1, 8, 64]);  mul_140 = None
        transpose_458: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_248, 1, 2);  view_248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_473: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_167, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_249: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_473, [1, -1, 8, 64]);  linear_473 = None
        transpose_459: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_249, 1, 2);  view_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_474: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_167, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_250: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_474, [1, -1, 8, 64]);  linear_474 = None
        transpose_460: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_250, 1, 2);  view_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_171: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_459, torch.float32);  transpose_459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_172: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_460, torch.float32);  transpose_460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1168: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__116: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1168, 2, add_297, to_171);  slice_1168 = to_171 = index_copy__116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1169: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__117: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1169, 2, add_297, to_172);  slice_1169 = to_172 = index_copy__117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1170: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1171: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1170, 2, 0, 9223372036854775807);  slice_1170 = None
        slice_1172: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1171, 3, 0, 9223372036854775807);  slice_1171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1173: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1174: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1173, 2, 0, 9223372036854775807);  slice_1173 = None
        slice_1175: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1174, 3, 0, 9223372036854775807);  slice_1174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_461: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1172, 2, 3);  slice_1172 = None
        matmul_220: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_458, transpose_461);  transpose_458 = transpose_461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1176: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_18, 0, 0, 9223372036854775807)
        slice_1177: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1176, 1, 0, 9223372036854775807);  slice_1176 = None
        slice_1178: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1177, 2, 0, 9223372036854775807);  slice_1177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_321: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_220, slice_1178);  matmul_220 = slice_1178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_110: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_321, -1);  add_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_346: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_110, 0.0, False);  softmax_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_221: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_346, slice_1175);  dropout_346 = slice_1175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_462: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_221, 1, 2);  matmul_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_119: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_462, [1, 1, 512]);  transpose_462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_475: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_119, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_347: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_475, 0.1, False);  linear_475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_322: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_167, dropout_347);  layer_norm_167 = dropout_347 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_168: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_322, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_322 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_476: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_168, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_141: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_476, 0.125);  linear_476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_251: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_141, [1, 1, 8, 64]);  mul_141 = None
        transpose_463: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_251, 1, 2);  view_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1179: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1180: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1179, 2, 0, 23);  slice_1179 = None
        slice_1181: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1180, 3, 0, 9223372036854775807);  slice_1180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1182: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1183: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1182, 2, 0, 23);  slice_1182 = None
        slice_1184: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1183, 3, 0, 9223372036854775807);  slice_1183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_464: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1181, 2, 3);  slice_1181 = None
        matmul_222: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_463, transpose_464);  transpose_463 = transpose_464 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1185: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_9, 0, 0, 9223372036854775807)
        slice_1186: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1185, 1, 0, 9223372036854775807);  slice_1185 = None
        slice_1187: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1186, 2, 0, 9223372036854775807);  slice_1186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_323: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_222, slice_1187);  matmul_222 = slice_1187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_111: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_323, -1);  add_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_348: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_111, 0.0, False);  softmax_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_223: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_348, slice_1184);  dropout_348 = slice_1184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_465: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_223, 1, 2);  matmul_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_120: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_465, [1, 1, 512]);  transpose_465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_477: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_120, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_349: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_477, 0.1, False);  linear_477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_324: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_168, dropout_349);  layer_norm_168 = dropout_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_169: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_324, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_324 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_478: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_169, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_58: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_478);  linear_478 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_350: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_58, 0.0, False);  silu_58 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_479: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_350, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_350 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_351: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_479, 0.1, False);  linear_479 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_325: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_169, dropout_351);  layer_norm_169 = dropout_351 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_170: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_325, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_480: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_170, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_142: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_480, 0.125);  linear_480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_252: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_142, [1, 1, 8, 64]);  mul_142 = None
        transpose_466: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_252, 1, 2);  view_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_481: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_170, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_253: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_481, [1, -1, 8, 64]);  linear_481 = None
        transpose_467: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_253, 1, 2);  view_253 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_482: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_170, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_254: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_482, [1, -1, 8, 64]);  linear_482 = None
        transpose_468: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_254, 1, 2);  view_254 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_173: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_467, torch.float32);  transpose_467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_174: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_468, torch.float32);  transpose_468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1188: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__118: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1188, 2, add_297, to_173);  slice_1188 = to_173 = index_copy__118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1189: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__119: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1189, 2, add_297, to_174);  slice_1189 = to_174 = index_copy__119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1190: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1191: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1190, 2, 0, 9223372036854775807);  slice_1190 = None
        slice_1192: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1191, 3, 0, 9223372036854775807);  slice_1191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1193: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1194: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1193, 2, 0, 9223372036854775807);  slice_1193 = None
        slice_1195: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1194, 3, 0, 9223372036854775807);  slice_1194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_469: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1192, 2, 3);  slice_1192 = None
        matmul_224: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_466, transpose_469);  transpose_466 = transpose_469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1196: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_18, 0, 0, 9223372036854775807);  expand_18 = None
        slice_1197: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1196, 1, 0, 9223372036854775807);  slice_1196 = None
        slice_1198: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1197, 2, 0, 9223372036854775807);  slice_1197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_326: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_224, slice_1198);  matmul_224 = slice_1198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_112: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_326, -1);  add_326 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_352: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_112, 0.0, False);  softmax_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_225: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_352, slice_1195);  dropout_352 = slice_1195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_470: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_225, 1, 2);  matmul_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_121: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_470, [1, 1, 512]);  transpose_470 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_483: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_121, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_353: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_483, 0.1, False);  linear_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_327: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_170, dropout_353);  layer_norm_170 = dropout_353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_171: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_327, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_327 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_484: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_171, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_143: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_484, 0.125);  linear_484 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_255: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_143, [1, 1, 8, 64]);  mul_143 = None
        transpose_471: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_255, 1, 2);  view_255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1199: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1200: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1199, 2, 0, 23);  slice_1199 = None
        slice_1201: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1200, 3, 0, 9223372036854775807);  slice_1200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1202: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1203: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1202, 2, 0, 23);  slice_1202 = None
        slice_1204: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1203, 3, 0, 9223372036854775807);  slice_1203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_472: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1201, 2, 3);  slice_1201 = None
        matmul_226: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_471, transpose_472);  transpose_471 = transpose_472 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1205: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_9, 0, 0, 9223372036854775807);  masked_fill_9 = None
        slice_1206: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1205, 1, 0, 9223372036854775807);  slice_1205 = None
        slice_1207: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1206, 2, 0, 9223372036854775807);  slice_1206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_328: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_226, slice_1207);  matmul_226 = slice_1207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_113: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_328, -1);  add_328 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_354: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_113, 0.0, False);  softmax_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_227: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_354, slice_1204);  dropout_354 = slice_1204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_473: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_227, 1, 2);  matmul_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_122: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_473, [1, 1, 512]);  transpose_473 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_485: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_122, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_355: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_485, 0.1, False);  linear_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_329: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_171, dropout_355);  layer_norm_171 = dropout_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_172: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_329, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_486: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_172, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_59: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_486);  linear_486 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_356: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_59, 0.0, False);  silu_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_487: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_356, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_356 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_357: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_487, 0.1, False);  linear_487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_330: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_172, dropout_357);  layer_norm_172 = dropout_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_173: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_330, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_330 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_488: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_173, p_model_lm_head_weight);  layer_norm_173 = None
        add_331: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_488, b_model_final_logits_bias);  linear_488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1208: "i64[1]" = torch.ops.aten.slice.Tensor(add_297, 0, -1, 9223372036854775807);  add_297 = None
        add_332: "i64[1]" = torch.ops.aten.add.Tensor(slice_1208, 1);  slice_1208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1209: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_331, 0, 0, 9223372036854775807);  add_331 = None
        select_40: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1209, 1, -1);  slice_1209 = None
        slice_1210: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_40, 1, 0, 9223372036854775807);  select_40 = None
        clone_17: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1210);  slice_1210 = None
        to_175: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_17, torch.float32);  clone_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_176: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_175, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_8: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_176, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__8: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_8, to_32);  zeros_like_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_333: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_176, add__8);  to_176 = add__8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_8: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_333, -1);  add_333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_8: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_8, -1);  log_softmax_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_144: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_8, and_8);  argmax_8 = None
        rsub_18: "i64[1]" = torch.ops.aten.rsub.Scalar(and_8, 1)
        mul_145: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_18);  rsub_18 = None
        add_334: "i64[1]" = torch.ops.aten.add.Tensor(mul_144, mul_145);  mul_144 = mul_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1211: "i64[1]" = torch.ops.aten.slice.Tensor(add_334, 0, 0, 9223372036854775807);  add_334 = None
        unsqueeze_56: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1211, 1);  slice_1211 = None
        cat_8: "i64[1, 10]" = torch.ops.aten.cat.default([cat_7, unsqueeze_56], -1);  cat_7 = unsqueeze_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_25: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_26: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_17: "b8[1]" = torch.ops.aten.__or__.Tensor(full_25, full_26);  full_25 = full_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_177: "i64[1]" = torch.ops.aten.to.dtype_layout(to_159, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1212: "i64[1, 10]" = torch.ops.aten.slice.Tensor(cat_8, 0, 0, 9223372036854775807)
        select_41: "i64[1]" = torch.ops.aten.select.int(slice_1212, 1, -1);  slice_1212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_10: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_41, to_177);  select_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_18: "b8[1]" = torch.ops.aten.__or__.Tensor(or_17, isin_10);  or_17 = isin_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_10: "b8[1]" = torch.ops.aten.bitwise_not.default(or_18);  or_18 = None
        and_9: "i64[1]" = torch.ops.aten.__and__.Tensor(and_8, bitwise_not_10);  and_8 = bitwise_not_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_9: "i64[]" = torch.ops.aten.max.default(and_9)
        eq_8: "b8[]" = torch.ops.aten.eq.Scalar(max_9, 0);  max_9 = eq_8 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1213: "i64[1, 10]" = torch.ops.aten.slice.Tensor(cat_8, 0, 0, 9223372036854775807)
        slice_1214: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1213, 1, -1, 9223372036854775807);  slice_1213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_18: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1214, memory_format = torch.contiguous_format);  slice_1214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_256: "i64[1, 1]" = torch.ops.aten.view.default(clone_18, [-1, 1]);  clone_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_20: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_256, 59513);  view_256 = None
        mul_146: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_20, 22.627416997969522);  embedding_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_57: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_332, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1215: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_58: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1215, 1);  slice_1215 = None
        unsqueeze_59: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_58, 2);  unsqueeze_58 = None
        slice_1216: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_59, 3, 0, 9223372036854775807);  unsqueeze_59 = None
        expand_19: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1216, [1, 1, 1, 23]);  slice_1216 = None
        to_178: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_19, torch.float32);  expand_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_19: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_178, 1.0);  to_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_179: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_19, torch.bool)
        masked_fill_10: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_19, to_179, -3.4028234663852886e+38);  rsub_19 = to_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_21: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_57);  unsqueeze_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_180: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_21, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_21 = None
        add_335: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_146, to_180);  mul_146 = to_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_358: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_335, 0.1, False);  add_335 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_42: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_43: "f32[20, 64]" = torch.ops.aten.select.int(select_42, 0, 0);  select_42 = None
        any_14: "b8[20]" = torch.ops.aten.any.dim(select_43, -1);  select_43 = None
        sum_12: "i64[]" = torch.ops.aten.sum.default(any_14);  any_14 = sum_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_27: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_16: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_123: "i64[1, 1]" = torch.ops.aten.reshape.default(add_332, [-1, 1])
        gt_9: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_16, reshape_123);  arange_16 = reshape_123 = None
        mul__9: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_27, gt_9);  full_27 = gt_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_60: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__9, 0);  mul__9 = None
        unsqueeze_61: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_60, 1);  unsqueeze_60 = None
        slice_1217: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_61, 2, 0, 9223372036854775807);  unsqueeze_61 = None
        slice_1218: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1217, 3, 0, 9223372036854775807);  slice_1217 = None
        expand_20: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1218, [1, 1, -1, -1]);  slice_1218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_489: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_358, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_147: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_489, 0.125);  linear_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_257: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_147, [1, 1, 8, 64]);  mul_147 = None
        transpose_474: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_257, 1, 2);  view_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_490: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_358, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_258: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_490, [1, -1, 8, 64]);  linear_490 = None
        transpose_475: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_258, 1, 2);  view_258 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_491: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_358, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_259: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_491, [1, -1, 8, 64]);  linear_491 = None
        transpose_476: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_259, 1, 2);  view_259 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_181: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_475, torch.float32);  transpose_475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_182: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_476, torch.float32);  transpose_476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1219: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__120: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1219, 2, add_332, to_181);  slice_1219 = to_181 = index_copy__120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1220: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__121: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1220, 2, add_332, to_182);  slice_1220 = to_182 = index_copy__121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1221: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1222: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1221, 2, 0, 9223372036854775807);  slice_1221 = None
        slice_1223: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1222, 3, 0, 9223372036854775807);  slice_1222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1224: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1225: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1224, 2, 0, 9223372036854775807);  slice_1224 = None
        slice_1226: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1225, 3, 0, 9223372036854775807);  slice_1225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_477: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1223, 2, 3);  slice_1223 = None
        matmul_228: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_474, transpose_477);  transpose_474 = transpose_477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1227: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_20, 0, 0, 9223372036854775807)
        slice_1228: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1227, 1, 0, 9223372036854775807);  slice_1227 = None
        slice_1229: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1228, 2, 0, 9223372036854775807);  slice_1228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_336: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_228, slice_1229);  matmul_228 = slice_1229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_114: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_336, -1);  add_336 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_359: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_114, 0.0, False);  softmax_114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_229: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_359, slice_1226);  dropout_359 = slice_1226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_478: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_229, 1, 2);  matmul_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_124: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_478, [1, 1, 512]);  transpose_478 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_492: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_124, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_360: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_492, 0.1, False);  linear_492 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_337: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_358, dropout_360);  dropout_358 = dropout_360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_174: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_337, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_493: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_174, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_148: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_493, 0.125);  linear_493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_260: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_148, [1, 1, 8, 64]);  mul_148 = None
        transpose_479: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_260, 1, 2);  view_260 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1230: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1231: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1230, 2, 0, 23);  slice_1230 = None
        slice_1232: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1231, 3, 0, 9223372036854775807);  slice_1231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1233: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1234: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1233, 2, 0, 23);  slice_1233 = None
        slice_1235: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1234, 3, 0, 9223372036854775807);  slice_1234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_480: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1232, 2, 3);  slice_1232 = None
        matmul_230: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_479, transpose_480);  transpose_479 = transpose_480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1236: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_10, 0, 0, 9223372036854775807)
        slice_1237: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1236, 1, 0, 9223372036854775807);  slice_1236 = None
        slice_1238: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1237, 2, 0, 9223372036854775807);  slice_1237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_338: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_230, slice_1238);  matmul_230 = slice_1238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_115: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_338, -1);  add_338 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_361: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_115, 0.0, False);  softmax_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_231: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_361, slice_1235);  dropout_361 = slice_1235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_481: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_231, 1, 2);  matmul_231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_125: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_481, [1, 1, 512]);  transpose_481 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_494: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_125, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_362: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_494, 0.1, False);  linear_494 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_339: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_174, dropout_362);  layer_norm_174 = dropout_362 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_175: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_339, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_495: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_175, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_60: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_495);  linear_495 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_363: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_60, 0.0, False);  silu_60 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_496: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_363, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_364: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_496, 0.1, False);  linear_496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_340: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_175, dropout_364);  layer_norm_175 = dropout_364 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_176: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_340, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_340 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_497: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_176, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_149: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_497, 0.125);  linear_497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_261: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_149, [1, 1, 8, 64]);  mul_149 = None
        transpose_482: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_261, 1, 2);  view_261 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_498: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_176, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_262: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_498, [1, -1, 8, 64]);  linear_498 = None
        transpose_483: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_262, 1, 2);  view_262 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_499: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_176, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_263: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_499, [1, -1, 8, 64]);  linear_499 = None
        transpose_484: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_263, 1, 2);  view_263 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_183: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_483, torch.float32);  transpose_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_184: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_484, torch.float32);  transpose_484 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1239: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__122: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1239, 2, add_332, to_183);  slice_1239 = to_183 = index_copy__122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1240: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__123: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1240, 2, add_332, to_184);  slice_1240 = to_184 = index_copy__123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1241: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1242: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1241, 2, 0, 9223372036854775807);  slice_1241 = None
        slice_1243: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1242, 3, 0, 9223372036854775807);  slice_1242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1244: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1245: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1244, 2, 0, 9223372036854775807);  slice_1244 = None
        slice_1246: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1245, 3, 0, 9223372036854775807);  slice_1245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_485: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1243, 2, 3);  slice_1243 = None
        matmul_232: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_482, transpose_485);  transpose_482 = transpose_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1247: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_20, 0, 0, 9223372036854775807)
        slice_1248: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1247, 1, 0, 9223372036854775807);  slice_1247 = None
        slice_1249: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1248, 2, 0, 9223372036854775807);  slice_1248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_341: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_232, slice_1249);  matmul_232 = slice_1249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_116: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_341, -1);  add_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_365: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_116, 0.0, False);  softmax_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_233: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_365, slice_1246);  dropout_365 = slice_1246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_486: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_233, 1, 2);  matmul_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_126: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_486, [1, 1, 512]);  transpose_486 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_500: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_126, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_366: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_500, 0.1, False);  linear_500 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_342: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_176, dropout_366);  layer_norm_176 = dropout_366 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_177: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_342, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_342 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_501: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_177, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_150: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_501, 0.125);  linear_501 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_264: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_150, [1, 1, 8, 64]);  mul_150 = None
        transpose_487: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_264, 1, 2);  view_264 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1250: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1251: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1250, 2, 0, 23);  slice_1250 = None
        slice_1252: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1251, 3, 0, 9223372036854775807);  slice_1251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1253: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1254: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1253, 2, 0, 23);  slice_1253 = None
        slice_1255: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1254, 3, 0, 9223372036854775807);  slice_1254 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_488: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1252, 2, 3);  slice_1252 = None
        matmul_234: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_487, transpose_488);  transpose_487 = transpose_488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1256: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_10, 0, 0, 9223372036854775807)
        slice_1257: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1256, 1, 0, 9223372036854775807);  slice_1256 = None
        slice_1258: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1257, 2, 0, 9223372036854775807);  slice_1257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_343: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_234, slice_1258);  matmul_234 = slice_1258 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_117: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_343, -1);  add_343 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_367: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_117, 0.0, False);  softmax_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_235: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_367, slice_1255);  dropout_367 = slice_1255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_489: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_235, 1, 2);  matmul_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_127: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_489, [1, 1, 512]);  transpose_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_502: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_127, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_368: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_502, 0.1, False);  linear_502 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_344: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_177, dropout_368);  layer_norm_177 = dropout_368 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_178: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_344, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_344 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_503: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_178, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_61: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_503);  linear_503 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_369: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_61, 0.0, False);  silu_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_504: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_369, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_370: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_504, 0.1, False);  linear_504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_345: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_178, dropout_370);  layer_norm_178 = dropout_370 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_179: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_345, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_505: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_179, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_151: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_505, 0.125);  linear_505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_265: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_151, [1, 1, 8, 64]);  mul_151 = None
        transpose_490: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_265, 1, 2);  view_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_506: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_179, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_266: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_506, [1, -1, 8, 64]);  linear_506 = None
        transpose_491: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_266, 1, 2);  view_266 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_507: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_179, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_267: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_507, [1, -1, 8, 64]);  linear_507 = None
        transpose_492: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_267, 1, 2);  view_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_185: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_491, torch.float32);  transpose_491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_186: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_492, torch.float32);  transpose_492 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1259: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__124: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1259, 2, add_332, to_185);  slice_1259 = to_185 = index_copy__124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1260: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__125: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1260, 2, add_332, to_186);  slice_1260 = to_186 = index_copy__125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1261: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1262: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1261, 2, 0, 9223372036854775807);  slice_1261 = None
        slice_1263: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1262, 3, 0, 9223372036854775807);  slice_1262 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1264: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1265: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1264, 2, 0, 9223372036854775807);  slice_1264 = None
        slice_1266: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1265, 3, 0, 9223372036854775807);  slice_1265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_493: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1263, 2, 3);  slice_1263 = None
        matmul_236: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_490, transpose_493);  transpose_490 = transpose_493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1267: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_20, 0, 0, 9223372036854775807)
        slice_1268: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1267, 1, 0, 9223372036854775807);  slice_1267 = None
        slice_1269: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1268, 2, 0, 9223372036854775807);  slice_1268 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_346: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_236, slice_1269);  matmul_236 = slice_1269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_118: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_346, -1);  add_346 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_371: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_118, 0.0, False);  softmax_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_237: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_371, slice_1266);  dropout_371 = slice_1266 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_494: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_237, 1, 2);  matmul_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_128: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_494, [1, 1, 512]);  transpose_494 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_508: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_128, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_372: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_508, 0.1, False);  linear_508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_347: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_179, dropout_372);  layer_norm_179 = dropout_372 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_180: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_347, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_347 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_509: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_180, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_152: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_509, 0.125);  linear_509 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_268: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_152, [1, 1, 8, 64]);  mul_152 = None
        transpose_495: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_268, 1, 2);  view_268 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1270: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1271: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1270, 2, 0, 23);  slice_1270 = None
        slice_1272: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1271, 3, 0, 9223372036854775807);  slice_1271 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1273: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1274: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1273, 2, 0, 23);  slice_1273 = None
        slice_1275: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1274, 3, 0, 9223372036854775807);  slice_1274 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_496: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1272, 2, 3);  slice_1272 = None
        matmul_238: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_495, transpose_496);  transpose_495 = transpose_496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1276: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_10, 0, 0, 9223372036854775807)
        slice_1277: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1276, 1, 0, 9223372036854775807);  slice_1276 = None
        slice_1278: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1277, 2, 0, 9223372036854775807);  slice_1277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_348: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_238, slice_1278);  matmul_238 = slice_1278 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_119: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_348, -1);  add_348 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_373: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_119, 0.0, False);  softmax_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_239: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_373, slice_1275);  dropout_373 = slice_1275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_497: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_239, 1, 2);  matmul_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_129: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_497, [1, 1, 512]);  transpose_497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_510: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_129, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_374: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_510, 0.1, False);  linear_510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_349: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_180, dropout_374);  layer_norm_180 = dropout_374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_181: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_349, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_511: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_181, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_62: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_511);  linear_511 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_375: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_62, 0.0, False);  silu_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_512: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_375, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_375 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_376: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_512, 0.1, False);  linear_512 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_350: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_181, dropout_376);  layer_norm_181 = dropout_376 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_182: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_350, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_350 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_513: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_182, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_153: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_513, 0.125);  linear_513 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_269: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_153, [1, 1, 8, 64]);  mul_153 = None
        transpose_498: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_269, 1, 2);  view_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_514: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_182, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_270: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_514, [1, -1, 8, 64]);  linear_514 = None
        transpose_499: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_270, 1, 2);  view_270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_515: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_182, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_271: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_515, [1, -1, 8, 64]);  linear_515 = None
        transpose_500: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_271, 1, 2);  view_271 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_187: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_499, torch.float32);  transpose_499 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_188: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_500, torch.float32);  transpose_500 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1279: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__126: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1279, 2, add_332, to_187);  slice_1279 = to_187 = index_copy__126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1280: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__127: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1280, 2, add_332, to_188);  slice_1280 = to_188 = index_copy__127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1281: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1282: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1281, 2, 0, 9223372036854775807);  slice_1281 = None
        slice_1283: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1282, 3, 0, 9223372036854775807);  slice_1282 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1284: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1285: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1284, 2, 0, 9223372036854775807);  slice_1284 = None
        slice_1286: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1285, 3, 0, 9223372036854775807);  slice_1285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_501: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1283, 2, 3);  slice_1283 = None
        matmul_240: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_498, transpose_501);  transpose_498 = transpose_501 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1287: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_20, 0, 0, 9223372036854775807)
        slice_1288: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1287, 1, 0, 9223372036854775807);  slice_1287 = None
        slice_1289: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1288, 2, 0, 9223372036854775807);  slice_1288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_351: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_240, slice_1289);  matmul_240 = slice_1289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_120: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_351, -1);  add_351 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_377: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_120, 0.0, False);  softmax_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_241: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_377, slice_1286);  dropout_377 = slice_1286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_502: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_241, 1, 2);  matmul_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_130: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_502, [1, 1, 512]);  transpose_502 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_516: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_130, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_378: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_516, 0.1, False);  linear_516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_352: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_182, dropout_378);  layer_norm_182 = dropout_378 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_183: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_352, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_352 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_517: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_183, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_154: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_517, 0.125);  linear_517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_272: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_154, [1, 1, 8, 64]);  mul_154 = None
        transpose_503: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_272, 1, 2);  view_272 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1290: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1291: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1290, 2, 0, 23);  slice_1290 = None
        slice_1292: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1291, 3, 0, 9223372036854775807);  slice_1291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1293: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1294: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1293, 2, 0, 23);  slice_1293 = None
        slice_1295: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1294, 3, 0, 9223372036854775807);  slice_1294 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_504: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1292, 2, 3);  slice_1292 = None
        matmul_242: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_503, transpose_504);  transpose_503 = transpose_504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1296: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_10, 0, 0, 9223372036854775807)
        slice_1297: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1296, 1, 0, 9223372036854775807);  slice_1296 = None
        slice_1298: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1297, 2, 0, 9223372036854775807);  slice_1297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_353: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_242, slice_1298);  matmul_242 = slice_1298 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_121: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_353, -1);  add_353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_379: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_121, 0.0, False);  softmax_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_243: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_379, slice_1295);  dropout_379 = slice_1295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_505: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_243, 1, 2);  matmul_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_131: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_505, [1, 1, 512]);  transpose_505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_518: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_131, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_380: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_518, 0.1, False);  linear_518 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_354: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_183, dropout_380);  layer_norm_183 = dropout_380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_184: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_354, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_354 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_519: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_184, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_63: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_519);  linear_519 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_381: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_63, 0.0, False);  silu_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_520: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_381, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_381 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_382: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_520, 0.1, False);  linear_520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_355: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_184, dropout_382);  layer_norm_184 = dropout_382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_185: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_355, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_521: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_185, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_155: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_521, 0.125);  linear_521 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_273: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_155, [1, 1, 8, 64]);  mul_155 = None
        transpose_506: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_273, 1, 2);  view_273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_522: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_185, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_274: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_522, [1, -1, 8, 64]);  linear_522 = None
        transpose_507: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_274, 1, 2);  view_274 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_523: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_185, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_275: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_523, [1, -1, 8, 64]);  linear_523 = None
        transpose_508: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_275, 1, 2);  view_275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_189: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_507, torch.float32);  transpose_507 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_190: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_508, torch.float32);  transpose_508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1299: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__128: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1299, 2, add_332, to_189);  slice_1299 = to_189 = index_copy__128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1300: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__129: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1300, 2, add_332, to_190);  slice_1300 = to_190 = index_copy__129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1301: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1302: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1301, 2, 0, 9223372036854775807);  slice_1301 = None
        slice_1303: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1302, 3, 0, 9223372036854775807);  slice_1302 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1304: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1305: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1304, 2, 0, 9223372036854775807);  slice_1304 = None
        slice_1306: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1305, 3, 0, 9223372036854775807);  slice_1305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_509: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1303, 2, 3);  slice_1303 = None
        matmul_244: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_506, transpose_509);  transpose_506 = transpose_509 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1307: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_20, 0, 0, 9223372036854775807)
        slice_1308: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1307, 1, 0, 9223372036854775807);  slice_1307 = None
        slice_1309: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1308, 2, 0, 9223372036854775807);  slice_1308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_356: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_244, slice_1309);  matmul_244 = slice_1309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_122: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_356, -1);  add_356 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_383: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_122, 0.0, False);  softmax_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_245: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_383, slice_1306);  dropout_383 = slice_1306 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_510: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_245, 1, 2);  matmul_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_132: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_510, [1, 1, 512]);  transpose_510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_524: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_132, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_384: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_524, 0.1, False);  linear_524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_357: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_185, dropout_384);  layer_norm_185 = dropout_384 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_186: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_357, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_525: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_186, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_156: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_525, 0.125);  linear_525 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_276: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_156, [1, 1, 8, 64]);  mul_156 = None
        transpose_511: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_276, 1, 2);  view_276 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1310: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1311: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1310, 2, 0, 23);  slice_1310 = None
        slice_1312: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1311, 3, 0, 9223372036854775807);  slice_1311 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1313: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1314: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1313, 2, 0, 23);  slice_1313 = None
        slice_1315: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1314, 3, 0, 9223372036854775807);  slice_1314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_512: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1312, 2, 3);  slice_1312 = None
        matmul_246: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_511, transpose_512);  transpose_511 = transpose_512 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1316: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_10, 0, 0, 9223372036854775807)
        slice_1317: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1316, 1, 0, 9223372036854775807);  slice_1316 = None
        slice_1318: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1317, 2, 0, 9223372036854775807);  slice_1317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_358: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_246, slice_1318);  matmul_246 = slice_1318 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_123: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_358, -1);  add_358 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_385: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_123, 0.0, False);  softmax_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_247: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_385, slice_1315);  dropout_385 = slice_1315 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_513: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_247, 1, 2);  matmul_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_133: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_513, [1, 1, 512]);  transpose_513 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_526: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_133, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_386: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_526, 0.1, False);  linear_526 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_359: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_186, dropout_386);  layer_norm_186 = dropout_386 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_187: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_359, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_359 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_527: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_187, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_64: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_527);  linear_527 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_387: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_64, 0.0, False);  silu_64 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_528: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_387, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_388: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_528, 0.1, False);  linear_528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_360: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_187, dropout_388);  layer_norm_187 = dropout_388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_188: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_360, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_529: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_188, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_157: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_529, 0.125);  linear_529 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_277: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_157, [1, 1, 8, 64]);  mul_157 = None
        transpose_514: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_277, 1, 2);  view_277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_530: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_188, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_278: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_530, [1, -1, 8, 64]);  linear_530 = None
        transpose_515: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_278, 1, 2);  view_278 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_531: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_188, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_279: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_531, [1, -1, 8, 64]);  linear_531 = None
        transpose_516: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_279, 1, 2);  view_279 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_191: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_515, torch.float32);  transpose_515 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_192: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_516, torch.float32);  transpose_516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1319: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__130: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1319, 2, add_332, to_191);  slice_1319 = to_191 = index_copy__130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1320: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__131: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1320, 2, add_332, to_192);  slice_1320 = to_192 = index_copy__131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1321: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1322: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1321, 2, 0, 9223372036854775807);  slice_1321 = None
        slice_1323: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1322, 3, 0, 9223372036854775807);  slice_1322 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1324: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1325: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1324, 2, 0, 9223372036854775807);  slice_1324 = None
        slice_1326: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1325, 3, 0, 9223372036854775807);  slice_1325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_517: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1323, 2, 3);  slice_1323 = None
        matmul_248: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_514, transpose_517);  transpose_514 = transpose_517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1327: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_20, 0, 0, 9223372036854775807);  expand_20 = None
        slice_1328: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1327, 1, 0, 9223372036854775807);  slice_1327 = None
        slice_1329: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1328, 2, 0, 9223372036854775807);  slice_1328 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_361: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_248, slice_1329);  matmul_248 = slice_1329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_124: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_361, -1);  add_361 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_389: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_124, 0.0, False);  softmax_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_249: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_389, slice_1326);  dropout_389 = slice_1326 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_518: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_249, 1, 2);  matmul_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_134: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_518, [1, 1, 512]);  transpose_518 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_532: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_134, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_390: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_532, 0.1, False);  linear_532 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_362: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_188, dropout_390);  layer_norm_188 = dropout_390 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_189: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_362, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_362 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_533: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_189, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_158: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_533, 0.125);  linear_533 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_280: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_158, [1, 1, 8, 64]);  mul_158 = None
        transpose_519: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_280, 1, 2);  view_280 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1330: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1331: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1330, 2, 0, 23);  slice_1330 = None
        slice_1332: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1331, 3, 0, 9223372036854775807);  slice_1331 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1333: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1334: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1333, 2, 0, 23);  slice_1333 = None
        slice_1335: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1334, 3, 0, 9223372036854775807);  slice_1334 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_520: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1332, 2, 3);  slice_1332 = None
        matmul_250: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_519, transpose_520);  transpose_519 = transpose_520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1336: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_10, 0, 0, 9223372036854775807);  masked_fill_10 = None
        slice_1337: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1336, 1, 0, 9223372036854775807);  slice_1336 = None
        slice_1338: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1337, 2, 0, 9223372036854775807);  slice_1337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_363: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_250, slice_1338);  matmul_250 = slice_1338 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_125: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_363, -1);  add_363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_391: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_125, 0.0, False);  softmax_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_251: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_391, slice_1335);  dropout_391 = slice_1335 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_521: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_251, 1, 2);  matmul_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_135: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_521, [1, 1, 512]);  transpose_521 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_534: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_135, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_392: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_534, 0.1, False);  linear_534 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_364: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_189, dropout_392);  layer_norm_189 = dropout_392 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_190: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_364, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_364 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_535: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_190, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_65: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_535);  linear_535 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_393: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_65, 0.0, False);  silu_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_536: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_393, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_394: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_536, 0.1, False);  linear_536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_365: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_190, dropout_394);  layer_norm_190 = dropout_394 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_191: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_365, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_537: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_191, p_model_lm_head_weight);  layer_norm_191 = None
        add_366: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_537, b_model_final_logits_bias);  linear_537 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1339: "i64[1]" = torch.ops.aten.slice.Tensor(add_332, 0, -1, 9223372036854775807);  add_332 = None
        add_367: "i64[1]" = torch.ops.aten.add.Tensor(slice_1339, 1);  slice_1339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1340: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_366, 0, 0, 9223372036854775807);  add_366 = None
        select_44: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1340, 1, -1);  slice_1340 = None
        slice_1341: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_44, 1, 0, 9223372036854775807);  select_44 = None
        clone_19: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1341);  slice_1341 = None
        to_193: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_19, torch.float32);  clone_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_194: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_193, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_9: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_194, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__9: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_9, to_32);  zeros_like_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_368: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_194, add__9);  to_194 = add__9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_9: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_368, -1);  add_368 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_9: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_9, -1);  log_softmax_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_159: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_9, and_9);  argmax_9 = None
        rsub_20: "i64[1]" = torch.ops.aten.rsub.Scalar(and_9, 1)
        mul_160: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_20);  rsub_20 = None
        add_369: "i64[1]" = torch.ops.aten.add.Tensor(mul_159, mul_160);  mul_159 = mul_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1342: "i64[1]" = torch.ops.aten.slice.Tensor(add_369, 0, 0, 9223372036854775807);  add_369 = None
        unsqueeze_62: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1342, 1);  slice_1342 = None
        cat_9: "i64[1, 11]" = torch.ops.aten.cat.default([cat_8, unsqueeze_62], -1);  cat_8 = unsqueeze_62 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_28: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_29: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_19: "b8[1]" = torch.ops.aten.__or__.Tensor(full_28, full_29);  full_28 = full_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_195: "i64[1]" = torch.ops.aten.to.dtype_layout(to_177, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1343: "i64[1, 11]" = torch.ops.aten.slice.Tensor(cat_9, 0, 0, 9223372036854775807)
        select_45: "i64[1]" = torch.ops.aten.select.int(slice_1343, 1, -1);  slice_1343 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_11: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_45, to_195);  select_45 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_20: "b8[1]" = torch.ops.aten.__or__.Tensor(or_19, isin_11);  or_19 = isin_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_11: "b8[1]" = torch.ops.aten.bitwise_not.default(or_20);  or_20 = None
        and_10: "i64[1]" = torch.ops.aten.__and__.Tensor(and_9, bitwise_not_11);  and_9 = bitwise_not_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_10: "i64[]" = torch.ops.aten.max.default(and_10)
        eq_9: "b8[]" = torch.ops.aten.eq.Scalar(max_10, 0);  max_10 = eq_9 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1344: "i64[1, 11]" = torch.ops.aten.slice.Tensor(cat_9, 0, 0, 9223372036854775807)
        slice_1345: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1344, 1, -1, 9223372036854775807);  slice_1344 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_20: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1345, memory_format = torch.contiguous_format);  slice_1345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_281: "i64[1, 1]" = torch.ops.aten.view.default(clone_20, [-1, 1]);  clone_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_22: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_281, 59513);  view_281 = None
        mul_161: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_22, 22.627416997969522);  embedding_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_63: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_367, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1346: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_64: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1346, 1);  slice_1346 = None
        unsqueeze_65: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_64, 2);  unsqueeze_64 = None
        slice_1347: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_65, 3, 0, 9223372036854775807);  unsqueeze_65 = None
        expand_21: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1347, [1, 1, 1, 23]);  slice_1347 = None
        to_196: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_21, torch.float32);  expand_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_21: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_196, 1.0);  to_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_197: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_21, torch.bool)
        masked_fill_11: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_21, to_197, -3.4028234663852886e+38);  rsub_21 = to_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_23: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_63);  unsqueeze_63 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_198: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_23, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_23 = None
        add_370: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_161, to_198);  mul_161 = to_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_395: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_370, 0.1, False);  add_370 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_46: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_47: "f32[20, 64]" = torch.ops.aten.select.int(select_46, 0, 0);  select_46 = None
        any_15: "b8[20]" = torch.ops.aten.any.dim(select_47, -1);  select_47 = None
        sum_13: "i64[]" = torch.ops.aten.sum.default(any_15);  any_15 = sum_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_30: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_17: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_136: "i64[1, 1]" = torch.ops.aten.reshape.default(add_367, [-1, 1])
        gt_10: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_17, reshape_136);  arange_17 = reshape_136 = None
        mul__10: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_30, gt_10);  full_30 = gt_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_66: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__10, 0);  mul__10 = None
        unsqueeze_67: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_66, 1);  unsqueeze_66 = None
        slice_1348: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_67, 2, 0, 9223372036854775807);  unsqueeze_67 = None
        slice_1349: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1348, 3, 0, 9223372036854775807);  slice_1348 = None
        expand_22: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1349, [1, 1, -1, -1]);  slice_1349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_538: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_395, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_162: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_538, 0.125);  linear_538 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_282: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_162, [1, 1, 8, 64]);  mul_162 = None
        transpose_522: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_282, 1, 2);  view_282 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_539: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_395, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_283: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_539, [1, -1, 8, 64]);  linear_539 = None
        transpose_523: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_283, 1, 2);  view_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_540: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_395, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_284: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_540, [1, -1, 8, 64]);  linear_540 = None
        transpose_524: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_284, 1, 2);  view_284 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_199: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_523, torch.float32);  transpose_523 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_200: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_524, torch.float32);  transpose_524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1350: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__132: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1350, 2, add_367, to_199);  slice_1350 = to_199 = index_copy__132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1351: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__133: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1351, 2, add_367, to_200);  slice_1351 = to_200 = index_copy__133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1352: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1353: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1352, 2, 0, 9223372036854775807);  slice_1352 = None
        slice_1354: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1353, 3, 0, 9223372036854775807);  slice_1353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1355: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1356: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1355, 2, 0, 9223372036854775807);  slice_1355 = None
        slice_1357: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1356, 3, 0, 9223372036854775807);  slice_1356 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_525: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1354, 2, 3);  slice_1354 = None
        matmul_252: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_522, transpose_525);  transpose_522 = transpose_525 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1358: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_22, 0, 0, 9223372036854775807)
        slice_1359: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1358, 1, 0, 9223372036854775807);  slice_1358 = None
        slice_1360: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1359, 2, 0, 9223372036854775807);  slice_1359 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_371: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_252, slice_1360);  matmul_252 = slice_1360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_126: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_371, -1);  add_371 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_396: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_126, 0.0, False);  softmax_126 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_253: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_396, slice_1357);  dropout_396 = slice_1357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_526: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_253, 1, 2);  matmul_253 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_137: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_526, [1, 1, 512]);  transpose_526 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_541: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_137, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_397: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_541, 0.1, False);  linear_541 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_372: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_395, dropout_397);  dropout_395 = dropout_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_192: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_372, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_372 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_542: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_192, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_163: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_542, 0.125);  linear_542 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_285: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_163, [1, 1, 8, 64]);  mul_163 = None
        transpose_527: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_285, 1, 2);  view_285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1361: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1362: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1361, 2, 0, 23);  slice_1361 = None
        slice_1363: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1362, 3, 0, 9223372036854775807);  slice_1362 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1364: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1365: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1364, 2, 0, 23);  slice_1364 = None
        slice_1366: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1365, 3, 0, 9223372036854775807);  slice_1365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_528: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1363, 2, 3);  slice_1363 = None
        matmul_254: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_527, transpose_528);  transpose_527 = transpose_528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1367: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_11, 0, 0, 9223372036854775807)
        slice_1368: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1367, 1, 0, 9223372036854775807);  slice_1367 = None
        slice_1369: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1368, 2, 0, 9223372036854775807);  slice_1368 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_373: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_254, slice_1369);  matmul_254 = slice_1369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_127: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_373, -1);  add_373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_398: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_127, 0.0, False);  softmax_127 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_255: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_398, slice_1366);  dropout_398 = slice_1366 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_529: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_255, 1, 2);  matmul_255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_138: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_529, [1, 1, 512]);  transpose_529 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_543: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_138, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_399: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_543, 0.1, False);  linear_543 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_374: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_192, dropout_399);  layer_norm_192 = dropout_399 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_193: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_374, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_544: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_193, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_66: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_544);  linear_544 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_400: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_66, 0.0, False);  silu_66 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_545: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_400, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_400 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_401: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_545, 0.1, False);  linear_545 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_375: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_193, dropout_401);  layer_norm_193 = dropout_401 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_194: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_375, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_375 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_546: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_194, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_164: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_546, 0.125);  linear_546 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_286: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_164, [1, 1, 8, 64]);  mul_164 = None
        transpose_530: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_286, 1, 2);  view_286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_547: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_194, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_287: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_547, [1, -1, 8, 64]);  linear_547 = None
        transpose_531: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_287, 1, 2);  view_287 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_548: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_194, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_288: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_548, [1, -1, 8, 64]);  linear_548 = None
        transpose_532: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_288, 1, 2);  view_288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_201: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_531, torch.float32);  transpose_531 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_202: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_532, torch.float32);  transpose_532 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1370: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__134: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1370, 2, add_367, to_201);  slice_1370 = to_201 = index_copy__134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1371: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__135: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1371, 2, add_367, to_202);  slice_1371 = to_202 = index_copy__135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1372: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1373: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1372, 2, 0, 9223372036854775807);  slice_1372 = None
        slice_1374: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1373, 3, 0, 9223372036854775807);  slice_1373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1375: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1376: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1375, 2, 0, 9223372036854775807);  slice_1375 = None
        slice_1377: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1376, 3, 0, 9223372036854775807);  slice_1376 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_533: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1374, 2, 3);  slice_1374 = None
        matmul_256: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_530, transpose_533);  transpose_530 = transpose_533 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1378: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_22, 0, 0, 9223372036854775807)
        slice_1379: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1378, 1, 0, 9223372036854775807);  slice_1378 = None
        slice_1380: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1379, 2, 0, 9223372036854775807);  slice_1379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_376: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_256, slice_1380);  matmul_256 = slice_1380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_128: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_376, -1);  add_376 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_402: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_128, 0.0, False);  softmax_128 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_257: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_402, slice_1377);  dropout_402 = slice_1377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_534: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_257, 1, 2);  matmul_257 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_139: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_534, [1, 1, 512]);  transpose_534 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_549: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_139, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_403: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_549, 0.1, False);  linear_549 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_377: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_194, dropout_403);  layer_norm_194 = dropout_403 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_195: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_377, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_550: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_195, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_165: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_550, 0.125);  linear_550 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_289: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_165, [1, 1, 8, 64]);  mul_165 = None
        transpose_535: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_289, 1, 2);  view_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1381: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1382: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1381, 2, 0, 23);  slice_1381 = None
        slice_1383: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1382, 3, 0, 9223372036854775807);  slice_1382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1384: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1385: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1384, 2, 0, 23);  slice_1384 = None
        slice_1386: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1385, 3, 0, 9223372036854775807);  slice_1385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_536: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1383, 2, 3);  slice_1383 = None
        matmul_258: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_535, transpose_536);  transpose_535 = transpose_536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1387: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_11, 0, 0, 9223372036854775807)
        slice_1388: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1387, 1, 0, 9223372036854775807);  slice_1387 = None
        slice_1389: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1388, 2, 0, 9223372036854775807);  slice_1388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_378: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_258, slice_1389);  matmul_258 = slice_1389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_129: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_378, -1);  add_378 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_404: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_129, 0.0, False);  softmax_129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_259: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_404, slice_1386);  dropout_404 = slice_1386 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_537: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_259, 1, 2);  matmul_259 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_140: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_537, [1, 1, 512]);  transpose_537 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_551: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_140, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_405: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_551, 0.1, False);  linear_551 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_379: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_195, dropout_405);  layer_norm_195 = dropout_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_196: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_379, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_552: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_196, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_67: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_552);  linear_552 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_406: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_67, 0.0, False);  silu_67 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_553: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_406, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_406 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_407: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_553, 0.1, False);  linear_553 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_380: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_196, dropout_407);  layer_norm_196 = dropout_407 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_197: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_380, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_554: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_197, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_166: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_554, 0.125);  linear_554 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_290: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_166, [1, 1, 8, 64]);  mul_166 = None
        transpose_538: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_290, 1, 2);  view_290 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_555: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_197, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_291: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_555, [1, -1, 8, 64]);  linear_555 = None
        transpose_539: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_291, 1, 2);  view_291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_556: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_197, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_292: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_556, [1, -1, 8, 64]);  linear_556 = None
        transpose_540: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_292, 1, 2);  view_292 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_203: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_539, torch.float32);  transpose_539 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_204: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_540, torch.float32);  transpose_540 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1390: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__136: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1390, 2, add_367, to_203);  slice_1390 = to_203 = index_copy__136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1391: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__137: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1391, 2, add_367, to_204);  slice_1391 = to_204 = index_copy__137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1392: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1393: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1392, 2, 0, 9223372036854775807);  slice_1392 = None
        slice_1394: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1393, 3, 0, 9223372036854775807);  slice_1393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1395: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1396: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1395, 2, 0, 9223372036854775807);  slice_1395 = None
        slice_1397: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1396, 3, 0, 9223372036854775807);  slice_1396 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_541: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1394, 2, 3);  slice_1394 = None
        matmul_260: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_538, transpose_541);  transpose_538 = transpose_541 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1398: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_22, 0, 0, 9223372036854775807)
        slice_1399: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1398, 1, 0, 9223372036854775807);  slice_1398 = None
        slice_1400: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1399, 2, 0, 9223372036854775807);  slice_1399 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_381: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_260, slice_1400);  matmul_260 = slice_1400 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_130: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_381, -1);  add_381 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_408: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_130, 0.0, False);  softmax_130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_261: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_408, slice_1397);  dropout_408 = slice_1397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_542: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_261, 1, 2);  matmul_261 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_141: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_542, [1, 1, 512]);  transpose_542 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_557: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_141, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_409: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_557, 0.1, False);  linear_557 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_382: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_197, dropout_409);  layer_norm_197 = dropout_409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_198: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_382, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_558: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_198, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_167: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_558, 0.125);  linear_558 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_293: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_167, [1, 1, 8, 64]);  mul_167 = None
        transpose_543: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_293, 1, 2);  view_293 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1401: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1402: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1401, 2, 0, 23);  slice_1401 = None
        slice_1403: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1402, 3, 0, 9223372036854775807);  slice_1402 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1404: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1405: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1404, 2, 0, 23);  slice_1404 = None
        slice_1406: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1405, 3, 0, 9223372036854775807);  slice_1405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_544: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1403, 2, 3);  slice_1403 = None
        matmul_262: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_543, transpose_544);  transpose_543 = transpose_544 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1407: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_11, 0, 0, 9223372036854775807)
        slice_1408: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1407, 1, 0, 9223372036854775807);  slice_1407 = None
        slice_1409: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1408, 2, 0, 9223372036854775807);  slice_1408 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_383: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_262, slice_1409);  matmul_262 = slice_1409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_131: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_383, -1);  add_383 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_410: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_131, 0.0, False);  softmax_131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_263: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_410, slice_1406);  dropout_410 = slice_1406 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_545: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_263, 1, 2);  matmul_263 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_142: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_545, [1, 1, 512]);  transpose_545 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_559: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_142, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_411: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_559, 0.1, False);  linear_559 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_384: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_198, dropout_411);  layer_norm_198 = dropout_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_199: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_384, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_384 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_560: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_199, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_68: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_560);  linear_560 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_412: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_68, 0.0, False);  silu_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_561: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_412, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_412 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_413: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_561, 0.1, False);  linear_561 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_385: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_199, dropout_413);  layer_norm_199 = dropout_413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_200: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_385, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_562: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_200, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_168: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_562, 0.125);  linear_562 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_294: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_168, [1, 1, 8, 64]);  mul_168 = None
        transpose_546: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_294, 1, 2);  view_294 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_563: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_200, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_295: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_563, [1, -1, 8, 64]);  linear_563 = None
        transpose_547: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_295, 1, 2);  view_295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_564: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_200, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_296: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_564, [1, -1, 8, 64]);  linear_564 = None
        transpose_548: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_296, 1, 2);  view_296 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_205: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_547, torch.float32);  transpose_547 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_206: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_548, torch.float32);  transpose_548 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1410: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__138: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1410, 2, add_367, to_205);  slice_1410 = to_205 = index_copy__138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1411: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__139: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1411, 2, add_367, to_206);  slice_1411 = to_206 = index_copy__139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1412: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1413: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1412, 2, 0, 9223372036854775807);  slice_1412 = None
        slice_1414: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1413, 3, 0, 9223372036854775807);  slice_1413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1415: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1416: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1415, 2, 0, 9223372036854775807);  slice_1415 = None
        slice_1417: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1416, 3, 0, 9223372036854775807);  slice_1416 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_549: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1414, 2, 3);  slice_1414 = None
        matmul_264: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_546, transpose_549);  transpose_546 = transpose_549 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1418: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_22, 0, 0, 9223372036854775807)
        slice_1419: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1418, 1, 0, 9223372036854775807);  slice_1418 = None
        slice_1420: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1419, 2, 0, 9223372036854775807);  slice_1419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_386: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_264, slice_1420);  matmul_264 = slice_1420 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_132: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_386, -1);  add_386 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_414: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_132, 0.0, False);  softmax_132 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_265: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_414, slice_1417);  dropout_414 = slice_1417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_550: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_265, 1, 2);  matmul_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_143: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_550, [1, 1, 512]);  transpose_550 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_565: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_143, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_415: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_565, 0.1, False);  linear_565 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_387: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_200, dropout_415);  layer_norm_200 = dropout_415 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_201: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_387, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_566: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_201, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_169: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_566, 0.125);  linear_566 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_297: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_169, [1, 1, 8, 64]);  mul_169 = None
        transpose_551: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_297, 1, 2);  view_297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1421: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1422: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1421, 2, 0, 23);  slice_1421 = None
        slice_1423: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1422, 3, 0, 9223372036854775807);  slice_1422 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1424: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1425: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1424, 2, 0, 23);  slice_1424 = None
        slice_1426: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1425, 3, 0, 9223372036854775807);  slice_1425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_552: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1423, 2, 3);  slice_1423 = None
        matmul_266: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_551, transpose_552);  transpose_551 = transpose_552 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1427: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_11, 0, 0, 9223372036854775807)
        slice_1428: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1427, 1, 0, 9223372036854775807);  slice_1427 = None
        slice_1429: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1428, 2, 0, 9223372036854775807);  slice_1428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_388: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_266, slice_1429);  matmul_266 = slice_1429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_133: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_388, -1);  add_388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_416: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_133, 0.0, False);  softmax_133 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_267: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_416, slice_1426);  dropout_416 = slice_1426 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_553: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_267, 1, 2);  matmul_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_144: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_553, [1, 1, 512]);  transpose_553 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_567: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_144, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_417: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_567, 0.1, False);  linear_567 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_389: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_201, dropout_417);  layer_norm_201 = dropout_417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_202: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_389, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_568: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_202, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_69: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_568);  linear_568 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_418: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_69, 0.0, False);  silu_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_569: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_418, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_418 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_419: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_569, 0.1, False);  linear_569 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_390: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_202, dropout_419);  layer_norm_202 = dropout_419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_203: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_390, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_390 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_570: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_203, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_170: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_570, 0.125);  linear_570 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_298: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_170, [1, 1, 8, 64]);  mul_170 = None
        transpose_554: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_298, 1, 2);  view_298 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_571: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_203, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_299: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_571, [1, -1, 8, 64]);  linear_571 = None
        transpose_555: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_299, 1, 2);  view_299 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_572: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_203, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_300: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_572, [1, -1, 8, 64]);  linear_572 = None
        transpose_556: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_300, 1, 2);  view_300 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_207: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_555, torch.float32);  transpose_555 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_208: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_556, torch.float32);  transpose_556 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1430: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__140: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1430, 2, add_367, to_207);  slice_1430 = to_207 = index_copy__140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1431: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__141: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1431, 2, add_367, to_208);  slice_1431 = to_208 = index_copy__141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1432: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1433: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1432, 2, 0, 9223372036854775807);  slice_1432 = None
        slice_1434: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1433, 3, 0, 9223372036854775807);  slice_1433 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1435: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1436: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1435, 2, 0, 9223372036854775807);  slice_1435 = None
        slice_1437: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1436, 3, 0, 9223372036854775807);  slice_1436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_557: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1434, 2, 3);  slice_1434 = None
        matmul_268: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_554, transpose_557);  transpose_554 = transpose_557 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1438: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_22, 0, 0, 9223372036854775807)
        slice_1439: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1438, 1, 0, 9223372036854775807);  slice_1438 = None
        slice_1440: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1439, 2, 0, 9223372036854775807);  slice_1439 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_391: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_268, slice_1440);  matmul_268 = slice_1440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_134: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_391, -1);  add_391 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_420: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_134, 0.0, False);  softmax_134 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_269: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_420, slice_1437);  dropout_420 = slice_1437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_558: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_269, 1, 2);  matmul_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_145: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_558, [1, 1, 512]);  transpose_558 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_573: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_145, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_421: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_573, 0.1, False);  linear_573 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_392: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_203, dropout_421);  layer_norm_203 = dropout_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_204: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_392, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_392 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_574: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_204, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_171: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_574, 0.125);  linear_574 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_301: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_171, [1, 1, 8, 64]);  mul_171 = None
        transpose_559: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_301, 1, 2);  view_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1441: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1442: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1441, 2, 0, 23);  slice_1441 = None
        slice_1443: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1442, 3, 0, 9223372036854775807);  slice_1442 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1444: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1445: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1444, 2, 0, 23);  slice_1444 = None
        slice_1446: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1445, 3, 0, 9223372036854775807);  slice_1445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_560: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1443, 2, 3);  slice_1443 = None
        matmul_270: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_559, transpose_560);  transpose_559 = transpose_560 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1447: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_11, 0, 0, 9223372036854775807)
        slice_1448: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1447, 1, 0, 9223372036854775807);  slice_1447 = None
        slice_1449: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1448, 2, 0, 9223372036854775807);  slice_1448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_393: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_270, slice_1449);  matmul_270 = slice_1449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_135: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_393, -1);  add_393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_422: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_135, 0.0, False);  softmax_135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_271: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_422, slice_1446);  dropout_422 = slice_1446 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_561: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_271, 1, 2);  matmul_271 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_146: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_561, [1, 1, 512]);  transpose_561 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_575: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_146, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_423: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_575, 0.1, False);  linear_575 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_394: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_204, dropout_423);  layer_norm_204 = dropout_423 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_205: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_394, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_394 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_576: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_205, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_70: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_576);  linear_576 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_424: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_70, 0.0, False);  silu_70 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_577: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_424, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_424 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_425: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_577, 0.1, False);  linear_577 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_395: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_205, dropout_425);  layer_norm_205 = dropout_425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_206: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_395, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_395 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_578: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_206, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_172: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_578, 0.125);  linear_578 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_302: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_172, [1, 1, 8, 64]);  mul_172 = None
        transpose_562: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_302, 1, 2);  view_302 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_579: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_206, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_303: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_579, [1, -1, 8, 64]);  linear_579 = None
        transpose_563: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_303, 1, 2);  view_303 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_580: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_206, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_304: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_580, [1, -1, 8, 64]);  linear_580 = None
        transpose_564: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_304, 1, 2);  view_304 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_209: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_563, torch.float32);  transpose_563 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_210: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_564, torch.float32);  transpose_564 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1450: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__142: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1450, 2, add_367, to_209);  slice_1450 = to_209 = index_copy__142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1451: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__143: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1451, 2, add_367, to_210);  slice_1451 = to_210 = index_copy__143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1452: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1453: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1452, 2, 0, 9223372036854775807);  slice_1452 = None
        slice_1454: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1453, 3, 0, 9223372036854775807);  slice_1453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1455: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1456: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1455, 2, 0, 9223372036854775807);  slice_1455 = None
        slice_1457: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1456, 3, 0, 9223372036854775807);  slice_1456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_565: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1454, 2, 3);  slice_1454 = None
        matmul_272: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_562, transpose_565);  transpose_562 = transpose_565 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1458: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_22, 0, 0, 9223372036854775807);  expand_22 = None
        slice_1459: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1458, 1, 0, 9223372036854775807);  slice_1458 = None
        slice_1460: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1459, 2, 0, 9223372036854775807);  slice_1459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_396: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_272, slice_1460);  matmul_272 = slice_1460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_136: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_396, -1);  add_396 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_426: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_136, 0.0, False);  softmax_136 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_273: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_426, slice_1457);  dropout_426 = slice_1457 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_566: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_273, 1, 2);  matmul_273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_147: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_566, [1, 1, 512]);  transpose_566 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_581: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_147, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_427: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_581, 0.1, False);  linear_581 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_397: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_206, dropout_427);  layer_norm_206 = dropout_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_207: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_397, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_582: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_207, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_173: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_582, 0.125);  linear_582 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_305: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_173, [1, 1, 8, 64]);  mul_173 = None
        transpose_567: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_305, 1, 2);  view_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1461: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1462: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1461, 2, 0, 23);  slice_1461 = None
        slice_1463: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1462, 3, 0, 9223372036854775807);  slice_1462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1464: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1465: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1464, 2, 0, 23);  slice_1464 = None
        slice_1466: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1465, 3, 0, 9223372036854775807);  slice_1465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_568: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1463, 2, 3);  slice_1463 = None
        matmul_274: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_567, transpose_568);  transpose_567 = transpose_568 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1467: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_11, 0, 0, 9223372036854775807);  masked_fill_11 = None
        slice_1468: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1467, 1, 0, 9223372036854775807);  slice_1467 = None
        slice_1469: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1468, 2, 0, 9223372036854775807);  slice_1468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_398: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_274, slice_1469);  matmul_274 = slice_1469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_137: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_398, -1);  add_398 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_428: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_137, 0.0, False);  softmax_137 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_275: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_428, slice_1466);  dropout_428 = slice_1466 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_569: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_275, 1, 2);  matmul_275 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_148: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_569, [1, 1, 512]);  transpose_569 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_583: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_148, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_429: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_583, 0.1, False);  linear_583 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_399: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_207, dropout_429);  layer_norm_207 = dropout_429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_208: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_399, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_399 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_584: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_208, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_71: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_584);  linear_584 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_430: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_71, 0.0, False);  silu_71 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_585: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_430, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_430 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_431: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_585, 0.1, False);  linear_585 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_400: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_208, dropout_431);  layer_norm_208 = dropout_431 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_209: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_400, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_400 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_586: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_209, p_model_lm_head_weight);  layer_norm_209 = None
        add_401: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_586, b_model_final_logits_bias);  linear_586 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1470: "i64[1]" = torch.ops.aten.slice.Tensor(add_367, 0, -1, 9223372036854775807);  add_367 = None
        add_402: "i64[1]" = torch.ops.aten.add.Tensor(slice_1470, 1);  slice_1470 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1471: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_401, 0, 0, 9223372036854775807);  add_401 = None
        select_48: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1471, 1, -1);  slice_1471 = None
        slice_1472: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_48, 1, 0, 9223372036854775807);  select_48 = None
        clone_21: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1472);  slice_1472 = None
        to_211: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_21, torch.float32);  clone_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_212: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_211, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_10: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_212, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__10: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_10, to_32);  zeros_like_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_403: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_212, add__10);  to_212 = add__10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_10: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_403, -1);  add_403 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_10: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_10, -1);  log_softmax_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_174: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_10, and_10);  argmax_10 = None
        rsub_22: "i64[1]" = torch.ops.aten.rsub.Scalar(and_10, 1)
        mul_175: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_22);  rsub_22 = None
        add_404: "i64[1]" = torch.ops.aten.add.Tensor(mul_174, mul_175);  mul_174 = mul_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1473: "i64[1]" = torch.ops.aten.slice.Tensor(add_404, 0, 0, 9223372036854775807);  add_404 = None
        unsqueeze_68: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1473, 1);  slice_1473 = None
        cat_10: "i64[1, 12]" = torch.ops.aten.cat.default([cat_9, unsqueeze_68], -1);  cat_9 = unsqueeze_68 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_31: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_32: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_21: "b8[1]" = torch.ops.aten.__or__.Tensor(full_31, full_32);  full_31 = full_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_213: "i64[1]" = torch.ops.aten.to.dtype_layout(to_195, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1474: "i64[1, 12]" = torch.ops.aten.slice.Tensor(cat_10, 0, 0, 9223372036854775807)
        select_49: "i64[1]" = torch.ops.aten.select.int(slice_1474, 1, -1);  slice_1474 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_12: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_49, to_213);  select_49 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_22: "b8[1]" = torch.ops.aten.__or__.Tensor(or_21, isin_12);  or_21 = isin_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_12: "b8[1]" = torch.ops.aten.bitwise_not.default(or_22);  or_22 = None
        and_11: "i64[1]" = torch.ops.aten.__and__.Tensor(and_10, bitwise_not_12);  and_10 = bitwise_not_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_11: "i64[]" = torch.ops.aten.max.default(and_11)
        eq_10: "b8[]" = torch.ops.aten.eq.Scalar(max_11, 0);  max_11 = eq_10 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1475: "i64[1, 12]" = torch.ops.aten.slice.Tensor(cat_10, 0, 0, 9223372036854775807)
        slice_1476: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1475, 1, -1, 9223372036854775807);  slice_1475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_22: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1476, memory_format = torch.contiguous_format);  slice_1476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_306: "i64[1, 1]" = torch.ops.aten.view.default(clone_22, [-1, 1]);  clone_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_24: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_306, 59513);  view_306 = None
        mul_176: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_24, 22.627416997969522);  embedding_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_69: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_402, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1477: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_70: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1477, 1);  slice_1477 = None
        unsqueeze_71: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_70, 2);  unsqueeze_70 = None
        slice_1478: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_71, 3, 0, 9223372036854775807);  unsqueeze_71 = None
        expand_23: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1478, [1, 1, 1, 23]);  slice_1478 = None
        to_214: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_23, torch.float32);  expand_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_23: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_214, 1.0);  to_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_215: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_23, torch.bool)
        masked_fill_12: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_23, to_215, -3.4028234663852886e+38);  rsub_23 = to_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_25: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_69);  unsqueeze_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_216: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_25, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_25 = None
        add_405: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_176, to_216);  mul_176 = to_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_432: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_405, 0.1, False);  add_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_50: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_51: "f32[20, 64]" = torch.ops.aten.select.int(select_50, 0, 0);  select_50 = None
        any_16: "b8[20]" = torch.ops.aten.any.dim(select_51, -1);  select_51 = None
        sum_14: "i64[]" = torch.ops.aten.sum.default(any_16);  any_16 = sum_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_33: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_18: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_149: "i64[1, 1]" = torch.ops.aten.reshape.default(add_402, [-1, 1])
        gt_11: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_18, reshape_149);  arange_18 = reshape_149 = None
        mul__11: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_33, gt_11);  full_33 = gt_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_72: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__11, 0);  mul__11 = None
        unsqueeze_73: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_72, 1);  unsqueeze_72 = None
        slice_1479: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_73, 2, 0, 9223372036854775807);  unsqueeze_73 = None
        slice_1480: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1479, 3, 0, 9223372036854775807);  slice_1479 = None
        expand_24: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1480, [1, 1, -1, -1]);  slice_1480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_587: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_432, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_177: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_587, 0.125);  linear_587 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_307: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_177, [1, 1, 8, 64]);  mul_177 = None
        transpose_570: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_307, 1, 2);  view_307 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_588: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_432, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_308: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_588, [1, -1, 8, 64]);  linear_588 = None
        transpose_571: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_308, 1, 2);  view_308 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_589: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_432, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_309: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_589, [1, -1, 8, 64]);  linear_589 = None
        transpose_572: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_309, 1, 2);  view_309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_217: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_571, torch.float32);  transpose_571 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_218: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_572, torch.float32);  transpose_572 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1481: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__144: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1481, 2, add_402, to_217);  slice_1481 = to_217 = index_copy__144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1482: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__145: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1482, 2, add_402, to_218);  slice_1482 = to_218 = index_copy__145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1483: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1484: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1483, 2, 0, 9223372036854775807);  slice_1483 = None
        slice_1485: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1484, 3, 0, 9223372036854775807);  slice_1484 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1486: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1487: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1486, 2, 0, 9223372036854775807);  slice_1486 = None
        slice_1488: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1487, 3, 0, 9223372036854775807);  slice_1487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_573: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1485, 2, 3);  slice_1485 = None
        matmul_276: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_570, transpose_573);  transpose_570 = transpose_573 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1489: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_24, 0, 0, 9223372036854775807)
        slice_1490: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1489, 1, 0, 9223372036854775807);  slice_1489 = None
        slice_1491: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1490, 2, 0, 9223372036854775807);  slice_1490 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_406: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_276, slice_1491);  matmul_276 = slice_1491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_138: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_406, -1);  add_406 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_433: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_138, 0.0, False);  softmax_138 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_277: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_433, slice_1488);  dropout_433 = slice_1488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_574: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_277, 1, 2);  matmul_277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_150: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_574, [1, 1, 512]);  transpose_574 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_590: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_150, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_434: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_590, 0.1, False);  linear_590 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_407: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_432, dropout_434);  dropout_432 = dropout_434 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_210: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_407, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_407 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_591: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_210, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_178: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_591, 0.125);  linear_591 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_310: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_178, [1, 1, 8, 64]);  mul_178 = None
        transpose_575: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_310, 1, 2);  view_310 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1492: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1493: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1492, 2, 0, 23);  slice_1492 = None
        slice_1494: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1493, 3, 0, 9223372036854775807);  slice_1493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1495: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1496: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1495, 2, 0, 23);  slice_1495 = None
        slice_1497: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1496, 3, 0, 9223372036854775807);  slice_1496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_576: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1494, 2, 3);  slice_1494 = None
        matmul_278: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_575, transpose_576);  transpose_575 = transpose_576 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1498: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_12, 0, 0, 9223372036854775807)
        slice_1499: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1498, 1, 0, 9223372036854775807);  slice_1498 = None
        slice_1500: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1499, 2, 0, 9223372036854775807);  slice_1499 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_408: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_278, slice_1500);  matmul_278 = slice_1500 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_139: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_408, -1);  add_408 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_435: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_139, 0.0, False);  softmax_139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_279: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_435, slice_1497);  dropout_435 = slice_1497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_577: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_279, 1, 2);  matmul_279 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_151: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_577, [1, 1, 512]);  transpose_577 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_592: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_151, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_436: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_592, 0.1, False);  linear_592 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_409: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_210, dropout_436);  layer_norm_210 = dropout_436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_211: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_409, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_593: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_211, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_72: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_593);  linear_593 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_437: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_72, 0.0, False);  silu_72 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_594: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_437, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_438: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_594, 0.1, False);  linear_594 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_410: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_211, dropout_438);  layer_norm_211 = dropout_438 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_212: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_410, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_410 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_595: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_212, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_179: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_595, 0.125);  linear_595 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_311: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_179, [1, 1, 8, 64]);  mul_179 = None
        transpose_578: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_311, 1, 2);  view_311 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_596: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_212, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_312: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_596, [1, -1, 8, 64]);  linear_596 = None
        transpose_579: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_312, 1, 2);  view_312 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_597: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_212, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_313: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_597, [1, -1, 8, 64]);  linear_597 = None
        transpose_580: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_313, 1, 2);  view_313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_219: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_579, torch.float32);  transpose_579 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_220: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_580, torch.float32);  transpose_580 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1501: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__146: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1501, 2, add_402, to_219);  slice_1501 = to_219 = index_copy__146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1502: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__147: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1502, 2, add_402, to_220);  slice_1502 = to_220 = index_copy__147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1503: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1504: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1503, 2, 0, 9223372036854775807);  slice_1503 = None
        slice_1505: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1504, 3, 0, 9223372036854775807);  slice_1504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1506: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1507: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1506, 2, 0, 9223372036854775807);  slice_1506 = None
        slice_1508: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1507, 3, 0, 9223372036854775807);  slice_1507 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_581: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1505, 2, 3);  slice_1505 = None
        matmul_280: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_578, transpose_581);  transpose_578 = transpose_581 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1509: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_24, 0, 0, 9223372036854775807)
        slice_1510: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1509, 1, 0, 9223372036854775807);  slice_1509 = None
        slice_1511: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1510, 2, 0, 9223372036854775807);  slice_1510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_411: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_280, slice_1511);  matmul_280 = slice_1511 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_140: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_411, -1);  add_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_439: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_140, 0.0, False);  softmax_140 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_281: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_439, slice_1508);  dropout_439 = slice_1508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_582: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_281, 1, 2);  matmul_281 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_152: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_582, [1, 1, 512]);  transpose_582 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_598: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_152, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_440: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_598, 0.1, False);  linear_598 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_412: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_212, dropout_440);  layer_norm_212 = dropout_440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_213: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_412, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_412 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_599: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_213, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_180: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_599, 0.125);  linear_599 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_314: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_180, [1, 1, 8, 64]);  mul_180 = None
        transpose_583: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_314, 1, 2);  view_314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1512: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1513: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1512, 2, 0, 23);  slice_1512 = None
        slice_1514: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1513, 3, 0, 9223372036854775807);  slice_1513 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1515: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1516: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1515, 2, 0, 23);  slice_1515 = None
        slice_1517: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1516, 3, 0, 9223372036854775807);  slice_1516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_584: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1514, 2, 3);  slice_1514 = None
        matmul_282: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_583, transpose_584);  transpose_583 = transpose_584 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1518: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_12, 0, 0, 9223372036854775807)
        slice_1519: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1518, 1, 0, 9223372036854775807);  slice_1518 = None
        slice_1520: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1519, 2, 0, 9223372036854775807);  slice_1519 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_413: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_282, slice_1520);  matmul_282 = slice_1520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_141: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_413, -1);  add_413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_441: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_141, 0.0, False);  softmax_141 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_283: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_441, slice_1517);  dropout_441 = slice_1517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_585: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_283, 1, 2);  matmul_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_153: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_585, [1, 1, 512]);  transpose_585 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_600: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_153, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_442: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_600, 0.1, False);  linear_600 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_414: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_213, dropout_442);  layer_norm_213 = dropout_442 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_214: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_414, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_414 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_601: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_214, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_73: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_601);  linear_601 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_443: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_73, 0.0, False);  silu_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_602: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_443, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_444: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_602, 0.1, False);  linear_602 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_415: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_214, dropout_444);  layer_norm_214 = dropout_444 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_215: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_415, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_415 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_603: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_215, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_181: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_603, 0.125);  linear_603 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_315: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_181, [1, 1, 8, 64]);  mul_181 = None
        transpose_586: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_315, 1, 2);  view_315 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_604: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_215, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_316: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_604, [1, -1, 8, 64]);  linear_604 = None
        transpose_587: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_316, 1, 2);  view_316 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_605: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_215, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_317: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_605, [1, -1, 8, 64]);  linear_605 = None
        transpose_588: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_317, 1, 2);  view_317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_221: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_587, torch.float32);  transpose_587 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_222: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_588, torch.float32);  transpose_588 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1521: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__148: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1521, 2, add_402, to_221);  slice_1521 = to_221 = index_copy__148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1522: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__149: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1522, 2, add_402, to_222);  slice_1522 = to_222 = index_copy__149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1523: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1524: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1523, 2, 0, 9223372036854775807);  slice_1523 = None
        slice_1525: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1524, 3, 0, 9223372036854775807);  slice_1524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1526: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1527: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1526, 2, 0, 9223372036854775807);  slice_1526 = None
        slice_1528: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1527, 3, 0, 9223372036854775807);  slice_1527 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_589: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1525, 2, 3);  slice_1525 = None
        matmul_284: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_586, transpose_589);  transpose_586 = transpose_589 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1529: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_24, 0, 0, 9223372036854775807)
        slice_1530: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1529, 1, 0, 9223372036854775807);  slice_1529 = None
        slice_1531: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1530, 2, 0, 9223372036854775807);  slice_1530 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_416: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_284, slice_1531);  matmul_284 = slice_1531 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_142: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_416, -1);  add_416 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_445: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_142, 0.0, False);  softmax_142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_285: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_445, slice_1528);  dropout_445 = slice_1528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_590: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_285, 1, 2);  matmul_285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_154: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_590, [1, 1, 512]);  transpose_590 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_606: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_154, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_446: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_606, 0.1, False);  linear_606 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_417: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_215, dropout_446);  layer_norm_215 = dropout_446 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_216: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_417, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_607: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_216, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_182: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_607, 0.125);  linear_607 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_318: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_182, [1, 1, 8, 64]);  mul_182 = None
        transpose_591: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_318, 1, 2);  view_318 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1532: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1533: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1532, 2, 0, 23);  slice_1532 = None
        slice_1534: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1533, 3, 0, 9223372036854775807);  slice_1533 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1535: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1536: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1535, 2, 0, 23);  slice_1535 = None
        slice_1537: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1536, 3, 0, 9223372036854775807);  slice_1536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_592: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1534, 2, 3);  slice_1534 = None
        matmul_286: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_591, transpose_592);  transpose_591 = transpose_592 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1538: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_12, 0, 0, 9223372036854775807)
        slice_1539: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1538, 1, 0, 9223372036854775807);  slice_1538 = None
        slice_1540: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1539, 2, 0, 9223372036854775807);  slice_1539 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_418: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_286, slice_1540);  matmul_286 = slice_1540 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_143: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_418, -1);  add_418 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_447: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_143, 0.0, False);  softmax_143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_287: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_447, slice_1537);  dropout_447 = slice_1537 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_593: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_287, 1, 2);  matmul_287 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_155: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_593, [1, 1, 512]);  transpose_593 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_608: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_155, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_448: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_608, 0.1, False);  linear_608 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_419: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_216, dropout_448);  layer_norm_216 = dropout_448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_217: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_419, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_609: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_217, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_74: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_609);  linear_609 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_449: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_74, 0.0, False);  silu_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_610: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_449, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_450: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_610, 0.1, False);  linear_610 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_420: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_217, dropout_450);  layer_norm_217 = dropout_450 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_218: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_420, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_420 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_611: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_218, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_183: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_611, 0.125);  linear_611 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_319: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_183, [1, 1, 8, 64]);  mul_183 = None
        transpose_594: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_319, 1, 2);  view_319 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_612: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_218, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_320: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_612, [1, -1, 8, 64]);  linear_612 = None
        transpose_595: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_320, 1, 2);  view_320 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_613: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_218, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_321: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_613, [1, -1, 8, 64]);  linear_613 = None
        transpose_596: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_321, 1, 2);  view_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_223: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_595, torch.float32);  transpose_595 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_224: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_596, torch.float32);  transpose_596 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1541: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__150: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1541, 2, add_402, to_223);  slice_1541 = to_223 = index_copy__150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1542: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__151: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1542, 2, add_402, to_224);  slice_1542 = to_224 = index_copy__151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1543: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1544: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1543, 2, 0, 9223372036854775807);  slice_1543 = None
        slice_1545: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1544, 3, 0, 9223372036854775807);  slice_1544 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1546: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1547: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1546, 2, 0, 9223372036854775807);  slice_1546 = None
        slice_1548: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1547, 3, 0, 9223372036854775807);  slice_1547 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_597: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1545, 2, 3);  slice_1545 = None
        matmul_288: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_594, transpose_597);  transpose_594 = transpose_597 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1549: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_24, 0, 0, 9223372036854775807)
        slice_1550: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1549, 1, 0, 9223372036854775807);  slice_1549 = None
        slice_1551: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1550, 2, 0, 9223372036854775807);  slice_1550 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_421: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_288, slice_1551);  matmul_288 = slice_1551 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_144: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_421, -1);  add_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_451: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_144, 0.0, False);  softmax_144 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_289: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_451, slice_1548);  dropout_451 = slice_1548 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_598: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_289, 1, 2);  matmul_289 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_156: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_598, [1, 1, 512]);  transpose_598 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_614: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_156, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_156 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_452: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_614, 0.1, False);  linear_614 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_422: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_218, dropout_452);  layer_norm_218 = dropout_452 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_219: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_422, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_422 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_615: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_219, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_184: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_615, 0.125);  linear_615 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_322: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_184, [1, 1, 8, 64]);  mul_184 = None
        transpose_599: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_322, 1, 2);  view_322 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1552: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1553: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1552, 2, 0, 23);  slice_1552 = None
        slice_1554: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1553, 3, 0, 9223372036854775807);  slice_1553 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1555: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1556: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1555, 2, 0, 23);  slice_1555 = None
        slice_1557: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1556, 3, 0, 9223372036854775807);  slice_1556 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_600: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1554, 2, 3);  slice_1554 = None
        matmul_290: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_599, transpose_600);  transpose_599 = transpose_600 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1558: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_12, 0, 0, 9223372036854775807)
        slice_1559: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1558, 1, 0, 9223372036854775807);  slice_1558 = None
        slice_1560: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1559, 2, 0, 9223372036854775807);  slice_1559 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_423: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_290, slice_1560);  matmul_290 = slice_1560 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_145: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_423, -1);  add_423 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_453: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_145, 0.0, False);  softmax_145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_291: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_453, slice_1557);  dropout_453 = slice_1557 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_601: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_291, 1, 2);  matmul_291 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_157: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_601, [1, 1, 512]);  transpose_601 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_616: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_157, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_454: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_616, 0.1, False);  linear_616 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_424: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_219, dropout_454);  layer_norm_219 = dropout_454 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_220: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_424, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_424 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_617: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_220, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_75: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_617);  linear_617 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_455: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_75, 0.0, False);  silu_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_618: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_455, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_455 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_456: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_618, 0.1, False);  linear_618 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_425: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_220, dropout_456);  layer_norm_220 = dropout_456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_221: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_425, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_619: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_221, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_185: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_619, 0.125);  linear_619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_323: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_185, [1, 1, 8, 64]);  mul_185 = None
        transpose_602: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_323, 1, 2);  view_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_620: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_221, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_324: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_620, [1, -1, 8, 64]);  linear_620 = None
        transpose_603: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_324, 1, 2);  view_324 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_621: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_221, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_325: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_621, [1, -1, 8, 64]);  linear_621 = None
        transpose_604: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_325, 1, 2);  view_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_225: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_603, torch.float32);  transpose_603 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_226: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_604, torch.float32);  transpose_604 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1561: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__152: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1561, 2, add_402, to_225);  slice_1561 = to_225 = index_copy__152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1562: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__153: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1562, 2, add_402, to_226);  slice_1562 = to_226 = index_copy__153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1563: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1564: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1563, 2, 0, 9223372036854775807);  slice_1563 = None
        slice_1565: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1564, 3, 0, 9223372036854775807);  slice_1564 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1566: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1567: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1566, 2, 0, 9223372036854775807);  slice_1566 = None
        slice_1568: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1567, 3, 0, 9223372036854775807);  slice_1567 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_605: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1565, 2, 3);  slice_1565 = None
        matmul_292: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_602, transpose_605);  transpose_602 = transpose_605 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1569: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_24, 0, 0, 9223372036854775807)
        slice_1570: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1569, 1, 0, 9223372036854775807);  slice_1569 = None
        slice_1571: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1570, 2, 0, 9223372036854775807);  slice_1570 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_426: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_292, slice_1571);  matmul_292 = slice_1571 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_146: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_426, -1);  add_426 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_457: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_146, 0.0, False);  softmax_146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_293: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_457, slice_1568);  dropout_457 = slice_1568 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_606: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_293, 1, 2);  matmul_293 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_158: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_606, [1, 1, 512]);  transpose_606 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_622: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_158, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_458: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_622, 0.1, False);  linear_622 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_427: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_221, dropout_458);  layer_norm_221 = dropout_458 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_222: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_427, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_623: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_222, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_186: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_623, 0.125);  linear_623 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_326: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_186, [1, 1, 8, 64]);  mul_186 = None
        transpose_607: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_326, 1, 2);  view_326 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1572: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1573: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1572, 2, 0, 23);  slice_1572 = None
        slice_1574: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1573, 3, 0, 9223372036854775807);  slice_1573 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1575: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1576: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1575, 2, 0, 23);  slice_1575 = None
        slice_1577: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1576, 3, 0, 9223372036854775807);  slice_1576 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_608: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1574, 2, 3);  slice_1574 = None
        matmul_294: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_607, transpose_608);  transpose_607 = transpose_608 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1578: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_12, 0, 0, 9223372036854775807)
        slice_1579: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1578, 1, 0, 9223372036854775807);  slice_1578 = None
        slice_1580: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1579, 2, 0, 9223372036854775807);  slice_1579 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_428: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_294, slice_1580);  matmul_294 = slice_1580 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_147: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_428, -1);  add_428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_459: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_147, 0.0, False);  softmax_147 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_295: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_459, slice_1577);  dropout_459 = slice_1577 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_609: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_295, 1, 2);  matmul_295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_159: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_609, [1, 1, 512]);  transpose_609 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_624: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_159, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_460: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_624, 0.1, False);  linear_624 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_429: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_222, dropout_460);  layer_norm_222 = dropout_460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_223: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_429, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_625: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_223, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_76: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_625);  linear_625 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_461: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_76, 0.0, False);  silu_76 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_626: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_461, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_462: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_626, 0.1, False);  linear_626 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_430: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_223, dropout_462);  layer_norm_223 = dropout_462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_224: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_430, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_430 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_627: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_224, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_187: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_627, 0.125);  linear_627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_327: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_187, [1, 1, 8, 64]);  mul_187 = None
        transpose_610: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_327, 1, 2);  view_327 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_628: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_224, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_328: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_628, [1, -1, 8, 64]);  linear_628 = None
        transpose_611: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_328, 1, 2);  view_328 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_629: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_224, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_329: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_629, [1, -1, 8, 64]);  linear_629 = None
        transpose_612: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_329, 1, 2);  view_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_227: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_611, torch.float32);  transpose_611 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_228: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_612, torch.float32);  transpose_612 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1581: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__154: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1581, 2, add_402, to_227);  slice_1581 = to_227 = index_copy__154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1582: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__155: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1582, 2, add_402, to_228);  slice_1582 = to_228 = index_copy__155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1583: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1584: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1583, 2, 0, 9223372036854775807);  slice_1583 = None
        slice_1585: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1584, 3, 0, 9223372036854775807);  slice_1584 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1586: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1587: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1586, 2, 0, 9223372036854775807);  slice_1586 = None
        slice_1588: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1587, 3, 0, 9223372036854775807);  slice_1587 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_613: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1585, 2, 3);  slice_1585 = None
        matmul_296: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_610, transpose_613);  transpose_610 = transpose_613 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1589: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_24, 0, 0, 9223372036854775807);  expand_24 = None
        slice_1590: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1589, 1, 0, 9223372036854775807);  slice_1589 = None
        slice_1591: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1590, 2, 0, 9223372036854775807);  slice_1590 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_431: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_296, slice_1591);  matmul_296 = slice_1591 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_148: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_431, -1);  add_431 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_463: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_148, 0.0, False);  softmax_148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_297: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_463, slice_1588);  dropout_463 = slice_1588 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_614: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_297, 1, 2);  matmul_297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_160: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_614, [1, 1, 512]);  transpose_614 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_630: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_160, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_464: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_630, 0.1, False);  linear_630 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_432: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_224, dropout_464);  layer_norm_224 = dropout_464 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_225: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_432, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_432 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_631: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_225, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_188: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_631, 0.125);  linear_631 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_330: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_188, [1, 1, 8, 64]);  mul_188 = None
        transpose_615: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_330, 1, 2);  view_330 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1592: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1593: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1592, 2, 0, 23);  slice_1592 = None
        slice_1594: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1593, 3, 0, 9223372036854775807);  slice_1593 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1595: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1596: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1595, 2, 0, 23);  slice_1595 = None
        slice_1597: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1596, 3, 0, 9223372036854775807);  slice_1596 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_616: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1594, 2, 3);  slice_1594 = None
        matmul_298: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_615, transpose_616);  transpose_615 = transpose_616 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1598: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_12, 0, 0, 9223372036854775807);  masked_fill_12 = None
        slice_1599: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1598, 1, 0, 9223372036854775807);  slice_1598 = None
        slice_1600: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1599, 2, 0, 9223372036854775807);  slice_1599 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_433: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_298, slice_1600);  matmul_298 = slice_1600 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_149: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_433, -1);  add_433 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_465: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_149, 0.0, False);  softmax_149 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_299: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_465, slice_1597);  dropout_465 = slice_1597 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_617: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_299, 1, 2);  matmul_299 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_161: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_617, [1, 1, 512]);  transpose_617 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_632: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_161, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_466: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_632, 0.1, False);  linear_632 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_434: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_225, dropout_466);  layer_norm_225 = dropout_466 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_226: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_434, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_434 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_633: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_226, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_77: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_633);  linear_633 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_467: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_77, 0.0, False);  silu_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_634: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_467, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_468: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_634, 0.1, False);  linear_634 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_435: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_226, dropout_468);  layer_norm_226 = dropout_468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_227: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_435, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_435 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_635: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_227, p_model_lm_head_weight);  layer_norm_227 = None
        add_436: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_635, b_model_final_logits_bias);  linear_635 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1601: "i64[1]" = torch.ops.aten.slice.Tensor(add_402, 0, -1, 9223372036854775807);  add_402 = None
        add_437: "i64[1]" = torch.ops.aten.add.Tensor(slice_1601, 1);  slice_1601 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1602: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_436, 0, 0, 9223372036854775807);  add_436 = None
        select_52: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1602, 1, -1);  slice_1602 = None
        slice_1603: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_52, 1, 0, 9223372036854775807);  select_52 = None
        clone_23: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1603);  slice_1603 = None
        to_229: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_23, torch.float32);  clone_23 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_230: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_229, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_11: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_230, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__11: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_11, to_32);  zeros_like_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_438: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_230, add__11);  to_230 = add__11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_11: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_438, -1);  add_438 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_11: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_11, -1);  log_softmax_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_189: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_11, and_11);  argmax_11 = None
        rsub_24: "i64[1]" = torch.ops.aten.rsub.Scalar(and_11, 1)
        mul_190: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_24);  rsub_24 = None
        add_439: "i64[1]" = torch.ops.aten.add.Tensor(mul_189, mul_190);  mul_189 = mul_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1604: "i64[1]" = torch.ops.aten.slice.Tensor(add_439, 0, 0, 9223372036854775807);  add_439 = None
        unsqueeze_74: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1604, 1);  slice_1604 = None
        cat_11: "i64[1, 13]" = torch.ops.aten.cat.default([cat_10, unsqueeze_74], -1);  cat_10 = unsqueeze_74 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_34: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_35: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_23: "b8[1]" = torch.ops.aten.__or__.Tensor(full_34, full_35);  full_34 = full_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_231: "i64[1]" = torch.ops.aten.to.dtype_layout(to_213, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1605: "i64[1, 13]" = torch.ops.aten.slice.Tensor(cat_11, 0, 0, 9223372036854775807)
        select_53: "i64[1]" = torch.ops.aten.select.int(slice_1605, 1, -1);  slice_1605 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_13: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_53, to_231);  select_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_24: "b8[1]" = torch.ops.aten.__or__.Tensor(or_23, isin_13);  or_23 = isin_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_13: "b8[1]" = torch.ops.aten.bitwise_not.default(or_24);  or_24 = None
        and_12: "i64[1]" = torch.ops.aten.__and__.Tensor(and_11, bitwise_not_13);  and_11 = bitwise_not_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_12: "i64[]" = torch.ops.aten.max.default(and_12)
        eq_11: "b8[]" = torch.ops.aten.eq.Scalar(max_12, 0);  max_12 = eq_11 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1606: "i64[1, 13]" = torch.ops.aten.slice.Tensor(cat_11, 0, 0, 9223372036854775807)
        slice_1607: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1606, 1, -1, 9223372036854775807);  slice_1606 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_24: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1607, memory_format = torch.contiguous_format);  slice_1607 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_331: "i64[1, 1]" = torch.ops.aten.view.default(clone_24, [-1, 1]);  clone_24 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_26: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_331, 59513);  view_331 = None
        mul_191: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_26, 22.627416997969522);  embedding_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_75: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_437, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1608: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_76: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1608, 1);  slice_1608 = None
        unsqueeze_77: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_76, 2);  unsqueeze_76 = None
        slice_1609: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_77, 3, 0, 9223372036854775807);  unsqueeze_77 = None
        expand_25: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1609, [1, 1, 1, 23]);  slice_1609 = None
        to_232: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_25, torch.float32);  expand_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_25: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_232, 1.0);  to_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_233: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_25, torch.bool)
        masked_fill_13: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_25, to_233, -3.4028234663852886e+38);  rsub_25 = to_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_27: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_75);  unsqueeze_75 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_234: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_27, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_27 = None
        add_440: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_191, to_234);  mul_191 = to_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_469: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_440, 0.1, False);  add_440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_54: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_55: "f32[20, 64]" = torch.ops.aten.select.int(select_54, 0, 0);  select_54 = None
        any_17: "b8[20]" = torch.ops.aten.any.dim(select_55, -1);  select_55 = None
        sum_15: "i64[]" = torch.ops.aten.sum.default(any_17);  any_17 = sum_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_36: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_19: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_162: "i64[1, 1]" = torch.ops.aten.reshape.default(add_437, [-1, 1])
        gt_12: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_19, reshape_162);  arange_19 = reshape_162 = None
        mul__12: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_36, gt_12);  full_36 = gt_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_78: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__12, 0);  mul__12 = None
        unsqueeze_79: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_78, 1);  unsqueeze_78 = None
        slice_1610: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_79, 2, 0, 9223372036854775807);  unsqueeze_79 = None
        slice_1611: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1610, 3, 0, 9223372036854775807);  slice_1610 = None
        expand_26: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1611, [1, 1, -1, -1]);  slice_1611 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_636: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_469, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_192: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_636, 0.125);  linear_636 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_332: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_192, [1, 1, 8, 64]);  mul_192 = None
        transpose_618: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_332, 1, 2);  view_332 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_637: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_469, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_333: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_637, [1, -1, 8, 64]);  linear_637 = None
        transpose_619: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_333, 1, 2);  view_333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_638: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_469, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_334: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_638, [1, -1, 8, 64]);  linear_638 = None
        transpose_620: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_334, 1, 2);  view_334 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_235: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_619, torch.float32);  transpose_619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_236: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_620, torch.float32);  transpose_620 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1612: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__156: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1612, 2, add_437, to_235);  slice_1612 = to_235 = index_copy__156 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1613: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__157: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1613, 2, add_437, to_236);  slice_1613 = to_236 = index_copy__157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1614: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1615: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1614, 2, 0, 9223372036854775807);  slice_1614 = None
        slice_1616: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1615, 3, 0, 9223372036854775807);  slice_1615 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1617: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1618: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1617, 2, 0, 9223372036854775807);  slice_1617 = None
        slice_1619: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1618, 3, 0, 9223372036854775807);  slice_1618 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_621: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1616, 2, 3);  slice_1616 = None
        matmul_300: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_618, transpose_621);  transpose_618 = transpose_621 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1620: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_26, 0, 0, 9223372036854775807)
        slice_1621: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1620, 1, 0, 9223372036854775807);  slice_1620 = None
        slice_1622: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1621, 2, 0, 9223372036854775807);  slice_1621 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_441: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_300, slice_1622);  matmul_300 = slice_1622 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_150: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_441, -1);  add_441 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_470: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_150, 0.0, False);  softmax_150 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_301: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_470, slice_1619);  dropout_470 = slice_1619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_622: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_301, 1, 2);  matmul_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_163: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_622, [1, 1, 512]);  transpose_622 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_639: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_163, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_471: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_639, 0.1, False);  linear_639 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_442: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_469, dropout_471);  dropout_469 = dropout_471 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_228: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_442, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_442 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_640: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_228, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_193: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_640, 0.125);  linear_640 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_335: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_193, [1, 1, 8, 64]);  mul_193 = None
        transpose_623: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_335, 1, 2);  view_335 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1623: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1624: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1623, 2, 0, 23);  slice_1623 = None
        slice_1625: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1624, 3, 0, 9223372036854775807);  slice_1624 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1626: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1627: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1626, 2, 0, 23);  slice_1626 = None
        slice_1628: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1627, 3, 0, 9223372036854775807);  slice_1627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_624: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1625, 2, 3);  slice_1625 = None
        matmul_302: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_623, transpose_624);  transpose_623 = transpose_624 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1629: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_13, 0, 0, 9223372036854775807)
        slice_1630: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1629, 1, 0, 9223372036854775807);  slice_1629 = None
        slice_1631: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1630, 2, 0, 9223372036854775807);  slice_1630 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_443: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_302, slice_1631);  matmul_302 = slice_1631 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_151: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_443, -1);  add_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_472: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_151, 0.0, False);  softmax_151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_303: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_472, slice_1628);  dropout_472 = slice_1628 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_625: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_303, 1, 2);  matmul_303 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_164: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_625, [1, 1, 512]);  transpose_625 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_641: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_164, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_473: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_641, 0.1, False);  linear_641 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_444: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_228, dropout_473);  layer_norm_228 = dropout_473 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_229: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_444, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_444 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_642: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_229, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_78: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_642);  linear_642 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_474: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_78, 0.0, False);  silu_78 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_643: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_474, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_474 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_475: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_643, 0.1, False);  linear_643 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_445: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_229, dropout_475);  layer_norm_229 = dropout_475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_230: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_445, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_644: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_230, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_194: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_644, 0.125);  linear_644 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_336: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_194, [1, 1, 8, 64]);  mul_194 = None
        transpose_626: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_336, 1, 2);  view_336 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_645: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_230, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_337: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_645, [1, -1, 8, 64]);  linear_645 = None
        transpose_627: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_337, 1, 2);  view_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_646: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_230, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_338: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_646, [1, -1, 8, 64]);  linear_646 = None
        transpose_628: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_338, 1, 2);  view_338 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_237: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_627, torch.float32);  transpose_627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_238: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_628, torch.float32);  transpose_628 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1632: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__158: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1632, 2, add_437, to_237);  slice_1632 = to_237 = index_copy__158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1633: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__159: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1633, 2, add_437, to_238);  slice_1633 = to_238 = index_copy__159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1634: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1635: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1634, 2, 0, 9223372036854775807);  slice_1634 = None
        slice_1636: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1635, 3, 0, 9223372036854775807);  slice_1635 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1637: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1638: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1637, 2, 0, 9223372036854775807);  slice_1637 = None
        slice_1639: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1638, 3, 0, 9223372036854775807);  slice_1638 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_629: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1636, 2, 3);  slice_1636 = None
        matmul_304: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_626, transpose_629);  transpose_626 = transpose_629 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1640: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_26, 0, 0, 9223372036854775807)
        slice_1641: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1640, 1, 0, 9223372036854775807);  slice_1640 = None
        slice_1642: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1641, 2, 0, 9223372036854775807);  slice_1641 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_446: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_304, slice_1642);  matmul_304 = slice_1642 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_152: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_446, -1);  add_446 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_476: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_152, 0.0, False);  softmax_152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_305: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_476, slice_1639);  dropout_476 = slice_1639 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_630: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_305, 1, 2);  matmul_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_165: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_630, [1, 1, 512]);  transpose_630 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_647: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_165, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_477: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_647, 0.1, False);  linear_647 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_447: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_230, dropout_477);  layer_norm_230 = dropout_477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_231: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_447, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_447 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_648: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_231, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_195: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_648, 0.125);  linear_648 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_339: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_195, [1, 1, 8, 64]);  mul_195 = None
        transpose_631: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_339, 1, 2);  view_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1643: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1644: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1643, 2, 0, 23);  slice_1643 = None
        slice_1645: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1644, 3, 0, 9223372036854775807);  slice_1644 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1646: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1647: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1646, 2, 0, 23);  slice_1646 = None
        slice_1648: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1647, 3, 0, 9223372036854775807);  slice_1647 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_632: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1645, 2, 3);  slice_1645 = None
        matmul_306: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_631, transpose_632);  transpose_631 = transpose_632 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1649: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_13, 0, 0, 9223372036854775807)
        slice_1650: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1649, 1, 0, 9223372036854775807);  slice_1649 = None
        slice_1651: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1650, 2, 0, 9223372036854775807);  slice_1650 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_448: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_306, slice_1651);  matmul_306 = slice_1651 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_153: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_448, -1);  add_448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_478: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_153, 0.0, False);  softmax_153 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_307: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_478, slice_1648);  dropout_478 = slice_1648 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_633: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_307, 1, 2);  matmul_307 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_166: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_633, [1, 1, 512]);  transpose_633 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_649: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_166, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_479: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_649, 0.1, False);  linear_649 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_449: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_231, dropout_479);  layer_norm_231 = dropout_479 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_232: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_449, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_650: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_232, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_79: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_650);  linear_650 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_480: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_79, 0.0, False);  silu_79 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_651: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_480, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_481: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_651, 0.1, False);  linear_651 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_450: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_232, dropout_481);  layer_norm_232 = dropout_481 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_233: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_450, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_450 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_652: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_233, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_196: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_652, 0.125);  linear_652 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_340: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_196, [1, 1, 8, 64]);  mul_196 = None
        transpose_634: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_340, 1, 2);  view_340 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_653: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_233, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_341: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_653, [1, -1, 8, 64]);  linear_653 = None
        transpose_635: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_341, 1, 2);  view_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_654: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_233, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_342: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_654, [1, -1, 8, 64]);  linear_654 = None
        transpose_636: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_342, 1, 2);  view_342 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_239: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_635, torch.float32);  transpose_635 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_240: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_636, torch.float32);  transpose_636 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1652: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__160: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1652, 2, add_437, to_239);  slice_1652 = to_239 = index_copy__160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1653: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__161: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1653, 2, add_437, to_240);  slice_1653 = to_240 = index_copy__161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1654: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1655: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1654, 2, 0, 9223372036854775807);  slice_1654 = None
        slice_1656: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1655, 3, 0, 9223372036854775807);  slice_1655 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1657: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1658: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1657, 2, 0, 9223372036854775807);  slice_1657 = None
        slice_1659: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1658, 3, 0, 9223372036854775807);  slice_1658 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_637: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1656, 2, 3);  slice_1656 = None
        matmul_308: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_634, transpose_637);  transpose_634 = transpose_637 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1660: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_26, 0, 0, 9223372036854775807)
        slice_1661: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1660, 1, 0, 9223372036854775807);  slice_1660 = None
        slice_1662: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1661, 2, 0, 9223372036854775807);  slice_1661 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_451: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_308, slice_1662);  matmul_308 = slice_1662 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_154: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_451, -1);  add_451 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_482: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_154, 0.0, False);  softmax_154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_309: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_482, slice_1659);  dropout_482 = slice_1659 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_638: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_309, 1, 2);  matmul_309 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_167: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_638, [1, 1, 512]);  transpose_638 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_655: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_167, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_483: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_655, 0.1, False);  linear_655 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_452: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_233, dropout_483);  layer_norm_233 = dropout_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_234: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_452, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_452 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_656: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_234, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_197: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_656, 0.125);  linear_656 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_343: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_197, [1, 1, 8, 64]);  mul_197 = None
        transpose_639: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_343, 1, 2);  view_343 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1663: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1664: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1663, 2, 0, 23);  slice_1663 = None
        slice_1665: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1664, 3, 0, 9223372036854775807);  slice_1664 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1666: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1667: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1666, 2, 0, 23);  slice_1666 = None
        slice_1668: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1667, 3, 0, 9223372036854775807);  slice_1667 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_640: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1665, 2, 3);  slice_1665 = None
        matmul_310: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_639, transpose_640);  transpose_639 = transpose_640 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1669: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_13, 0, 0, 9223372036854775807)
        slice_1670: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1669, 1, 0, 9223372036854775807);  slice_1669 = None
        slice_1671: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1670, 2, 0, 9223372036854775807);  slice_1670 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_453: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_310, slice_1671);  matmul_310 = slice_1671 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_155: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_453, -1);  add_453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_484: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_155, 0.0, False);  softmax_155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_311: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_484, slice_1668);  dropout_484 = slice_1668 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_641: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_311, 1, 2);  matmul_311 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_168: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_641, [1, 1, 512]);  transpose_641 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_657: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_168, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_485: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_657, 0.1, False);  linear_657 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_454: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_234, dropout_485);  layer_norm_234 = dropout_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_235: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_454, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_454 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_658: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_235, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_80: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_658);  linear_658 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_486: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_80, 0.0, False);  silu_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_659: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_486, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_486 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_487: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_659, 0.1, False);  linear_659 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_455: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_235, dropout_487);  layer_norm_235 = dropout_487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_236: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_455, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_455 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_660: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_236, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_198: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_660, 0.125);  linear_660 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_344: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_198, [1, 1, 8, 64]);  mul_198 = None
        transpose_642: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_344, 1, 2);  view_344 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_661: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_236, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_345: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_661, [1, -1, 8, 64]);  linear_661 = None
        transpose_643: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_345, 1, 2);  view_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_662: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_236, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_346: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_662, [1, -1, 8, 64]);  linear_662 = None
        transpose_644: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_346, 1, 2);  view_346 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_241: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_643, torch.float32);  transpose_643 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_242: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_644, torch.float32);  transpose_644 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1672: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__162: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1672, 2, add_437, to_241);  slice_1672 = to_241 = index_copy__162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1673: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__163: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1673, 2, add_437, to_242);  slice_1673 = to_242 = index_copy__163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1674: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1675: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1674, 2, 0, 9223372036854775807);  slice_1674 = None
        slice_1676: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1675, 3, 0, 9223372036854775807);  slice_1675 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1677: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1678: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1677, 2, 0, 9223372036854775807);  slice_1677 = None
        slice_1679: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1678, 3, 0, 9223372036854775807);  slice_1678 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_645: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1676, 2, 3);  slice_1676 = None
        matmul_312: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_642, transpose_645);  transpose_642 = transpose_645 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1680: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_26, 0, 0, 9223372036854775807)
        slice_1681: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1680, 1, 0, 9223372036854775807);  slice_1680 = None
        slice_1682: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1681, 2, 0, 9223372036854775807);  slice_1681 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_456: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_312, slice_1682);  matmul_312 = slice_1682 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_156: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_456, -1);  add_456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_488: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_156, 0.0, False);  softmax_156 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_313: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_488, slice_1679);  dropout_488 = slice_1679 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_646: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_313, 1, 2);  matmul_313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_169: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_646, [1, 1, 512]);  transpose_646 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_663: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_169, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_489: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_663, 0.1, False);  linear_663 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_457: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_236, dropout_489);  layer_norm_236 = dropout_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_237: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_457, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_457 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_664: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_237, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_199: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_664, 0.125);  linear_664 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_347: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_199, [1, 1, 8, 64]);  mul_199 = None
        transpose_647: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_347, 1, 2);  view_347 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1683: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1684: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1683, 2, 0, 23);  slice_1683 = None
        slice_1685: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1684, 3, 0, 9223372036854775807);  slice_1684 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1686: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1687: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1686, 2, 0, 23);  slice_1686 = None
        slice_1688: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1687, 3, 0, 9223372036854775807);  slice_1687 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_648: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1685, 2, 3);  slice_1685 = None
        matmul_314: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_647, transpose_648);  transpose_647 = transpose_648 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1689: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_13, 0, 0, 9223372036854775807)
        slice_1690: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1689, 1, 0, 9223372036854775807);  slice_1689 = None
        slice_1691: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1690, 2, 0, 9223372036854775807);  slice_1690 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_458: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_314, slice_1691);  matmul_314 = slice_1691 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_157: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_458, -1);  add_458 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_490: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_157, 0.0, False);  softmax_157 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_315: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_490, slice_1688);  dropout_490 = slice_1688 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_649: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_315, 1, 2);  matmul_315 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_170: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_649, [1, 1, 512]);  transpose_649 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_665: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_170, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_491: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_665, 0.1, False);  linear_665 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_459: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_237, dropout_491);  layer_norm_237 = dropout_491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_238: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_459, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_666: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_238, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_81: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_666);  linear_666 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_492: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_81, 0.0, False);  silu_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_667: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_492, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_492 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_493: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_667, 0.1, False);  linear_667 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_460: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_238, dropout_493);  layer_norm_238 = dropout_493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_239: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_460, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_668: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_239, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_200: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_668, 0.125);  linear_668 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_348: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_200, [1, 1, 8, 64]);  mul_200 = None
        transpose_650: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_348, 1, 2);  view_348 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_669: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_239, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_349: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_669, [1, -1, 8, 64]);  linear_669 = None
        transpose_651: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_349, 1, 2);  view_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_670: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_239, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_350: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_670, [1, -1, 8, 64]);  linear_670 = None
        transpose_652: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_350, 1, 2);  view_350 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_243: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_651, torch.float32);  transpose_651 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_244: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_652, torch.float32);  transpose_652 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1692: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__164: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1692, 2, add_437, to_243);  slice_1692 = to_243 = index_copy__164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1693: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__165: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1693, 2, add_437, to_244);  slice_1693 = to_244 = index_copy__165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1694: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1695: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1694, 2, 0, 9223372036854775807);  slice_1694 = None
        slice_1696: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1695, 3, 0, 9223372036854775807);  slice_1695 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1697: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1698: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1697, 2, 0, 9223372036854775807);  slice_1697 = None
        slice_1699: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1698, 3, 0, 9223372036854775807);  slice_1698 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_653: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1696, 2, 3);  slice_1696 = None
        matmul_316: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_650, transpose_653);  transpose_650 = transpose_653 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1700: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_26, 0, 0, 9223372036854775807)
        slice_1701: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1700, 1, 0, 9223372036854775807);  slice_1700 = None
        slice_1702: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1701, 2, 0, 9223372036854775807);  slice_1701 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_461: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_316, slice_1702);  matmul_316 = slice_1702 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_158: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_461, -1);  add_461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_494: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_158, 0.0, False);  softmax_158 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_317: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_494, slice_1699);  dropout_494 = slice_1699 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_654: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_317, 1, 2);  matmul_317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_171: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_654, [1, 1, 512]);  transpose_654 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_671: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_171, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_495: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_671, 0.1, False);  linear_671 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_462: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_239, dropout_495);  layer_norm_239 = dropout_495 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_240: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_462, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_672: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_240, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_201: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_672, 0.125);  linear_672 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_351: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_201, [1, 1, 8, 64]);  mul_201 = None
        transpose_655: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_351, 1, 2);  view_351 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1703: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1704: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1703, 2, 0, 23);  slice_1703 = None
        slice_1705: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1704, 3, 0, 9223372036854775807);  slice_1704 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1706: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1707: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1706, 2, 0, 23);  slice_1706 = None
        slice_1708: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1707, 3, 0, 9223372036854775807);  slice_1707 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_656: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1705, 2, 3);  slice_1705 = None
        matmul_318: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_655, transpose_656);  transpose_655 = transpose_656 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1709: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_13, 0, 0, 9223372036854775807)
        slice_1710: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1709, 1, 0, 9223372036854775807);  slice_1709 = None
        slice_1711: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1710, 2, 0, 9223372036854775807);  slice_1710 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_463: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_318, slice_1711);  matmul_318 = slice_1711 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_159: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_463, -1);  add_463 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_496: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_159, 0.0, False);  softmax_159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_319: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_496, slice_1708);  dropout_496 = slice_1708 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_657: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_319, 1, 2);  matmul_319 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_172: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_657, [1, 1, 512]);  transpose_657 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_673: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_172, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_497: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_673, 0.1, False);  linear_673 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_464: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_240, dropout_497);  layer_norm_240 = dropout_497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_241: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_464, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_464 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_674: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_241, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_82: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_674);  linear_674 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_498: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_82, 0.0, False);  silu_82 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_675: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_498, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_498 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_499: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_675, 0.1, False);  linear_675 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_465: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_241, dropout_499);  layer_norm_241 = dropout_499 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_242: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_465, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_676: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_242, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_202: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_676, 0.125);  linear_676 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_352: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_202, [1, 1, 8, 64]);  mul_202 = None
        transpose_658: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_352, 1, 2);  view_352 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_677: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_242, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_353: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_677, [1, -1, 8, 64]);  linear_677 = None
        transpose_659: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_353, 1, 2);  view_353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_678: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_242, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_354: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_678, [1, -1, 8, 64]);  linear_678 = None
        transpose_660: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_354, 1, 2);  view_354 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_245: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_659, torch.float32);  transpose_659 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_246: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_660, torch.float32);  transpose_660 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1712: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__166: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1712, 2, add_437, to_245);  slice_1712 = to_245 = index_copy__166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1713: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__167: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1713, 2, add_437, to_246);  slice_1713 = to_246 = index_copy__167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1714: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1715: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1714, 2, 0, 9223372036854775807);  slice_1714 = None
        slice_1716: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1715, 3, 0, 9223372036854775807);  slice_1715 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1717: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1718: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1717, 2, 0, 9223372036854775807);  slice_1717 = None
        slice_1719: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1718, 3, 0, 9223372036854775807);  slice_1718 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_661: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1716, 2, 3);  slice_1716 = None
        matmul_320: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_658, transpose_661);  transpose_658 = transpose_661 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1720: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_26, 0, 0, 9223372036854775807);  expand_26 = None
        slice_1721: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1720, 1, 0, 9223372036854775807);  slice_1720 = None
        slice_1722: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1721, 2, 0, 9223372036854775807);  slice_1721 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_466: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_320, slice_1722);  matmul_320 = slice_1722 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_160: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_466, -1);  add_466 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_500: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_160, 0.0, False);  softmax_160 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_321: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_500, slice_1719);  dropout_500 = slice_1719 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_662: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_321, 1, 2);  matmul_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_173: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_662, [1, 1, 512]);  transpose_662 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_679: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_173, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_501: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_679, 0.1, False);  linear_679 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_467: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_242, dropout_501);  layer_norm_242 = dropout_501 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_243: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_467, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_680: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_243, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_203: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_680, 0.125);  linear_680 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_355: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_203, [1, 1, 8, 64]);  mul_203 = None
        transpose_663: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_355, 1, 2);  view_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1723: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1724: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1723, 2, 0, 23);  slice_1723 = None
        slice_1725: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1724, 3, 0, 9223372036854775807);  slice_1724 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1726: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1727: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1726, 2, 0, 23);  slice_1726 = None
        slice_1728: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1727, 3, 0, 9223372036854775807);  slice_1727 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_664: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1725, 2, 3);  slice_1725 = None
        matmul_322: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_663, transpose_664);  transpose_663 = transpose_664 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1729: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_13, 0, 0, 9223372036854775807);  masked_fill_13 = None
        slice_1730: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1729, 1, 0, 9223372036854775807);  slice_1729 = None
        slice_1731: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1730, 2, 0, 9223372036854775807);  slice_1730 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_468: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_322, slice_1731);  matmul_322 = slice_1731 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_161: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_468, -1);  add_468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_502: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_161, 0.0, False);  softmax_161 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_323: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_502, slice_1728);  dropout_502 = slice_1728 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_665: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_323, 1, 2);  matmul_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_174: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_665, [1, 1, 512]);  transpose_665 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_681: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_174, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_503: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_681, 0.1, False);  linear_681 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_469: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_243, dropout_503);  layer_norm_243 = dropout_503 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_244: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_469, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_682: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_244, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_83: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_682);  linear_682 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_504: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_83, 0.0, False);  silu_83 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_683: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_504, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_505: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_683, 0.1, False);  linear_683 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_470: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_244, dropout_505);  layer_norm_244 = dropout_505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_245: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_470, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_470 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_684: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_245, p_model_lm_head_weight);  layer_norm_245 = None
        add_471: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_684, b_model_final_logits_bias);  linear_684 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1732: "i64[1]" = torch.ops.aten.slice.Tensor(add_437, 0, -1, 9223372036854775807);  add_437 = None
        add_472: "i64[1]" = torch.ops.aten.add.Tensor(slice_1732, 1);  slice_1732 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1733: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_471, 0, 0, 9223372036854775807);  add_471 = None
        select_56: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1733, 1, -1);  slice_1733 = None
        slice_1734: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_56, 1, 0, 9223372036854775807);  select_56 = None
        clone_25: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1734);  slice_1734 = None
        to_247: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_25, torch.float32);  clone_25 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_248: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_247, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_12: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_248, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__12: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_12, to_32);  zeros_like_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_473: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_248, add__12);  to_248 = add__12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_12: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_473, -1);  add_473 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_12: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_12, -1);  log_softmax_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_204: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_12, and_12);  argmax_12 = None
        rsub_26: "i64[1]" = torch.ops.aten.rsub.Scalar(and_12, 1)
        mul_205: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_26);  rsub_26 = None
        add_474: "i64[1]" = torch.ops.aten.add.Tensor(mul_204, mul_205);  mul_204 = mul_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1735: "i64[1]" = torch.ops.aten.slice.Tensor(add_474, 0, 0, 9223372036854775807);  add_474 = None
        unsqueeze_80: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1735, 1);  slice_1735 = None
        cat_12: "i64[1, 14]" = torch.ops.aten.cat.default([cat_11, unsqueeze_80], -1);  cat_11 = unsqueeze_80 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_37: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_38: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_25: "b8[1]" = torch.ops.aten.__or__.Tensor(full_37, full_38);  full_37 = full_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_249: "i64[1]" = torch.ops.aten.to.dtype_layout(to_231, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1736: "i64[1, 14]" = torch.ops.aten.slice.Tensor(cat_12, 0, 0, 9223372036854775807)
        select_57: "i64[1]" = torch.ops.aten.select.int(slice_1736, 1, -1);  slice_1736 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_14: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_57, to_249);  select_57 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_26: "b8[1]" = torch.ops.aten.__or__.Tensor(or_25, isin_14);  or_25 = isin_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_14: "b8[1]" = torch.ops.aten.bitwise_not.default(or_26);  or_26 = None
        and_13: "i64[1]" = torch.ops.aten.__and__.Tensor(and_12, bitwise_not_14);  and_12 = bitwise_not_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_13: "i64[]" = torch.ops.aten.max.default(and_13)
        eq_12: "b8[]" = torch.ops.aten.eq.Scalar(max_13, 0);  max_13 = eq_12 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1737: "i64[1, 14]" = torch.ops.aten.slice.Tensor(cat_12, 0, 0, 9223372036854775807)
        slice_1738: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1737, 1, -1, 9223372036854775807);  slice_1737 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_26: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1738, memory_format = torch.contiguous_format);  slice_1738 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_356: "i64[1, 1]" = torch.ops.aten.view.default(clone_26, [-1, 1]);  clone_26 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_28: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_356, 59513);  view_356 = None
        mul_206: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_28, 22.627416997969522);  embedding_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_81: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_472, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1739: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_82: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1739, 1);  slice_1739 = None
        unsqueeze_83: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_82, 2);  unsqueeze_82 = None
        slice_1740: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_83, 3, 0, 9223372036854775807);  unsqueeze_83 = None
        expand_27: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1740, [1, 1, 1, 23]);  slice_1740 = None
        to_250: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_27, torch.float32);  expand_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_27: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_250, 1.0);  to_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_251: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_27, torch.bool)
        masked_fill_14: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_27, to_251, -3.4028234663852886e+38);  rsub_27 = to_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_29: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_81);  unsqueeze_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_252: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_29, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_29 = None
        add_475: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_206, to_252);  mul_206 = to_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_506: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_475, 0.1, False);  add_475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_58: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_59: "f32[20, 64]" = torch.ops.aten.select.int(select_58, 0, 0);  select_58 = None
        any_18: "b8[20]" = torch.ops.aten.any.dim(select_59, -1);  select_59 = None
        sum_16: "i64[]" = torch.ops.aten.sum.default(any_18);  any_18 = sum_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_39: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_20: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_175: "i64[1, 1]" = torch.ops.aten.reshape.default(add_472, [-1, 1])
        gt_13: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_20, reshape_175);  arange_20 = reshape_175 = None
        mul__13: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_39, gt_13);  full_39 = gt_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_84: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__13, 0);  mul__13 = None
        unsqueeze_85: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_84, 1);  unsqueeze_84 = None
        slice_1741: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_85, 2, 0, 9223372036854775807);  unsqueeze_85 = None
        slice_1742: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1741, 3, 0, 9223372036854775807);  slice_1741 = None
        expand_28: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1742, [1, 1, -1, -1]);  slice_1742 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_685: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_506, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_207: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_685, 0.125);  linear_685 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_357: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_207, [1, 1, 8, 64]);  mul_207 = None
        transpose_666: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_357, 1, 2);  view_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_686: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_506, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_358: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_686, [1, -1, 8, 64]);  linear_686 = None
        transpose_667: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_358, 1, 2);  view_358 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_687: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_506, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_359: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_687, [1, -1, 8, 64]);  linear_687 = None
        transpose_668: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_359, 1, 2);  view_359 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_253: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_667, torch.float32);  transpose_667 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_254: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_668, torch.float32);  transpose_668 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1743: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__168: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1743, 2, add_472, to_253);  slice_1743 = to_253 = index_copy__168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1744: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__169: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1744, 2, add_472, to_254);  slice_1744 = to_254 = index_copy__169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1745: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1746: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1745, 2, 0, 9223372036854775807);  slice_1745 = None
        slice_1747: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1746, 3, 0, 9223372036854775807);  slice_1746 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1748: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1749: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1748, 2, 0, 9223372036854775807);  slice_1748 = None
        slice_1750: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1749, 3, 0, 9223372036854775807);  slice_1749 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_669: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1747, 2, 3);  slice_1747 = None
        matmul_324: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_666, transpose_669);  transpose_666 = transpose_669 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1751: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_28, 0, 0, 9223372036854775807)
        slice_1752: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1751, 1, 0, 9223372036854775807);  slice_1751 = None
        slice_1753: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1752, 2, 0, 9223372036854775807);  slice_1752 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_476: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_324, slice_1753);  matmul_324 = slice_1753 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_162: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_476, -1);  add_476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_507: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_162, 0.0, False);  softmax_162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_325: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_507, slice_1750);  dropout_507 = slice_1750 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_670: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_325, 1, 2);  matmul_325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_176: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_670, [1, 1, 512]);  transpose_670 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_688: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_176, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_508: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_688, 0.1, False);  linear_688 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_477: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_506, dropout_508);  dropout_506 = dropout_508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_246: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_477, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_689: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_246, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_208: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_689, 0.125);  linear_689 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_360: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_208, [1, 1, 8, 64]);  mul_208 = None
        transpose_671: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_360, 1, 2);  view_360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1754: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1755: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1754, 2, 0, 23);  slice_1754 = None
        slice_1756: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1755, 3, 0, 9223372036854775807);  slice_1755 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1757: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1758: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1757, 2, 0, 23);  slice_1757 = None
        slice_1759: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1758, 3, 0, 9223372036854775807);  slice_1758 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_672: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1756, 2, 3);  slice_1756 = None
        matmul_326: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_671, transpose_672);  transpose_671 = transpose_672 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1760: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_14, 0, 0, 9223372036854775807)
        slice_1761: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1760, 1, 0, 9223372036854775807);  slice_1760 = None
        slice_1762: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1761, 2, 0, 9223372036854775807);  slice_1761 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_478: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_326, slice_1762);  matmul_326 = slice_1762 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_163: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_478, -1);  add_478 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_509: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_163, 0.0, False);  softmax_163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_327: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_509, slice_1759);  dropout_509 = slice_1759 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_673: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_327, 1, 2);  matmul_327 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_177: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_673, [1, 1, 512]);  transpose_673 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_690: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_177, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_510: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_690, 0.1, False);  linear_690 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_479: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_246, dropout_510);  layer_norm_246 = dropout_510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_247: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_479, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_479 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_691: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_247, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_84: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_691);  linear_691 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_511: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_84, 0.0, False);  silu_84 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_692: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_511, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_511 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_512: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_692, 0.1, False);  linear_692 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_480: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_247, dropout_512);  layer_norm_247 = dropout_512 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_248: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_480, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_693: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_248, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_209: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_693, 0.125);  linear_693 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_361: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_209, [1, 1, 8, 64]);  mul_209 = None
        transpose_674: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_361, 1, 2);  view_361 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_694: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_248, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_362: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_694, [1, -1, 8, 64]);  linear_694 = None
        transpose_675: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_362, 1, 2);  view_362 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_695: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_248, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_363: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_695, [1, -1, 8, 64]);  linear_695 = None
        transpose_676: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_363, 1, 2);  view_363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_255: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_675, torch.float32);  transpose_675 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_256: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_676, torch.float32);  transpose_676 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1763: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__170: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1763, 2, add_472, to_255);  slice_1763 = to_255 = index_copy__170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1764: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__171: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1764, 2, add_472, to_256);  slice_1764 = to_256 = index_copy__171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1765: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1766: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1765, 2, 0, 9223372036854775807);  slice_1765 = None
        slice_1767: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1766, 3, 0, 9223372036854775807);  slice_1766 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1768: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1769: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1768, 2, 0, 9223372036854775807);  slice_1768 = None
        slice_1770: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1769, 3, 0, 9223372036854775807);  slice_1769 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_677: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1767, 2, 3);  slice_1767 = None
        matmul_328: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_674, transpose_677);  transpose_674 = transpose_677 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1771: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_28, 0, 0, 9223372036854775807)
        slice_1772: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1771, 1, 0, 9223372036854775807);  slice_1771 = None
        slice_1773: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1772, 2, 0, 9223372036854775807);  slice_1772 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_481: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_328, slice_1773);  matmul_328 = slice_1773 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_164: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_481, -1);  add_481 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_513: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_164, 0.0, False);  softmax_164 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_329: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_513, slice_1770);  dropout_513 = slice_1770 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_678: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_329, 1, 2);  matmul_329 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_178: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_678, [1, 1, 512]);  transpose_678 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_696: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_178, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_514: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_696, 0.1, False);  linear_696 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_482: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_248, dropout_514);  layer_norm_248 = dropout_514 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_249: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_482, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_482 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_697: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_249, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_210: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_697, 0.125);  linear_697 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_364: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_210, [1, 1, 8, 64]);  mul_210 = None
        transpose_679: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_364, 1, 2);  view_364 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1774: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1775: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1774, 2, 0, 23);  slice_1774 = None
        slice_1776: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1775, 3, 0, 9223372036854775807);  slice_1775 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1777: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1778: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1777, 2, 0, 23);  slice_1777 = None
        slice_1779: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1778, 3, 0, 9223372036854775807);  slice_1778 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_680: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1776, 2, 3);  slice_1776 = None
        matmul_330: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_679, transpose_680);  transpose_679 = transpose_680 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1780: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_14, 0, 0, 9223372036854775807)
        slice_1781: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1780, 1, 0, 9223372036854775807);  slice_1780 = None
        slice_1782: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1781, 2, 0, 9223372036854775807);  slice_1781 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_483: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_330, slice_1782);  matmul_330 = slice_1782 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_165: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_483, -1);  add_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_515: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_165, 0.0, False);  softmax_165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_331: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_515, slice_1779);  dropout_515 = slice_1779 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_681: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_331, 1, 2);  matmul_331 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_179: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_681, [1, 1, 512]);  transpose_681 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_698: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_179, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_516: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_698, 0.1, False);  linear_698 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_484: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_249, dropout_516);  layer_norm_249 = dropout_516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_250: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_484, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_484 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_699: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_250, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_85: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_699);  linear_699 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_517: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_85, 0.0, False);  silu_85 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_700: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_517, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_518: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_700, 0.1, False);  linear_700 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_485: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_250, dropout_518);  layer_norm_250 = dropout_518 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_251: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_485, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_701: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_251, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_211: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_701, 0.125);  linear_701 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_365: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_211, [1, 1, 8, 64]);  mul_211 = None
        transpose_682: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_365, 1, 2);  view_365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_702: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_251, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_366: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_702, [1, -1, 8, 64]);  linear_702 = None
        transpose_683: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_366, 1, 2);  view_366 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_703: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_251, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_367: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_703, [1, -1, 8, 64]);  linear_703 = None
        transpose_684: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_367, 1, 2);  view_367 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_257: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_683, torch.float32);  transpose_683 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_258: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_684, torch.float32);  transpose_684 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1783: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__172: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1783, 2, add_472, to_257);  slice_1783 = to_257 = index_copy__172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1784: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__173: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1784, 2, add_472, to_258);  slice_1784 = to_258 = index_copy__173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1785: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1786: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1785, 2, 0, 9223372036854775807);  slice_1785 = None
        slice_1787: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1786, 3, 0, 9223372036854775807);  slice_1786 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1788: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1789: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1788, 2, 0, 9223372036854775807);  slice_1788 = None
        slice_1790: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1789, 3, 0, 9223372036854775807);  slice_1789 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_685: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1787, 2, 3);  slice_1787 = None
        matmul_332: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_682, transpose_685);  transpose_682 = transpose_685 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1791: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_28, 0, 0, 9223372036854775807)
        slice_1792: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1791, 1, 0, 9223372036854775807);  slice_1791 = None
        slice_1793: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1792, 2, 0, 9223372036854775807);  slice_1792 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_486: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_332, slice_1793);  matmul_332 = slice_1793 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_166: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_486, -1);  add_486 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_519: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_166, 0.0, False);  softmax_166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_333: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_519, slice_1790);  dropout_519 = slice_1790 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_686: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_333, 1, 2);  matmul_333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_180: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_686, [1, 1, 512]);  transpose_686 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_704: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_180, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_520: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_704, 0.1, False);  linear_704 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_487: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_251, dropout_520);  layer_norm_251 = dropout_520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_252: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_487, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_705: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_252, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_212: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_705, 0.125);  linear_705 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_368: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_212, [1, 1, 8, 64]);  mul_212 = None
        transpose_687: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_368, 1, 2);  view_368 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1794: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1795: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1794, 2, 0, 23);  slice_1794 = None
        slice_1796: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1795, 3, 0, 9223372036854775807);  slice_1795 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1797: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1798: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1797, 2, 0, 23);  slice_1797 = None
        slice_1799: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1798, 3, 0, 9223372036854775807);  slice_1798 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_688: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1796, 2, 3);  slice_1796 = None
        matmul_334: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_687, transpose_688);  transpose_687 = transpose_688 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1800: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_14, 0, 0, 9223372036854775807)
        slice_1801: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1800, 1, 0, 9223372036854775807);  slice_1800 = None
        slice_1802: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1801, 2, 0, 9223372036854775807);  slice_1801 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_488: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_334, slice_1802);  matmul_334 = slice_1802 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_167: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_488, -1);  add_488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_521: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_167, 0.0, False);  softmax_167 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_335: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_521, slice_1799);  dropout_521 = slice_1799 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_689: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_335, 1, 2);  matmul_335 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_181: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_689, [1, 1, 512]);  transpose_689 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_706: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_181, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_522: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_706, 0.1, False);  linear_706 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_489: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_252, dropout_522);  layer_norm_252 = dropout_522 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_253: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_489, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_707: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_253, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_86: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_707);  linear_707 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_523: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_86, 0.0, False);  silu_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_708: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_523, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_523 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_524: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_708, 0.1, False);  linear_708 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_490: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_253, dropout_524);  layer_norm_253 = dropout_524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_254: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_490, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_490 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_709: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_254, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_213: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_709, 0.125);  linear_709 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_369: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_213, [1, 1, 8, 64]);  mul_213 = None
        transpose_690: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_369, 1, 2);  view_369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_710: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_254, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_370: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_710, [1, -1, 8, 64]);  linear_710 = None
        transpose_691: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_370, 1, 2);  view_370 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_711: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_254, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_371: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_711, [1, -1, 8, 64]);  linear_711 = None
        transpose_692: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_371, 1, 2);  view_371 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_259: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_691, torch.float32);  transpose_691 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_260: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_692, torch.float32);  transpose_692 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1803: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__174: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1803, 2, add_472, to_259);  slice_1803 = to_259 = index_copy__174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1804: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__175: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1804, 2, add_472, to_260);  slice_1804 = to_260 = index_copy__175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1805: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1806: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1805, 2, 0, 9223372036854775807);  slice_1805 = None
        slice_1807: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1806, 3, 0, 9223372036854775807);  slice_1806 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1808: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1809: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1808, 2, 0, 9223372036854775807);  slice_1808 = None
        slice_1810: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1809, 3, 0, 9223372036854775807);  slice_1809 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_693: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1807, 2, 3);  slice_1807 = None
        matmul_336: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_690, transpose_693);  transpose_690 = transpose_693 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1811: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_28, 0, 0, 9223372036854775807)
        slice_1812: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1811, 1, 0, 9223372036854775807);  slice_1811 = None
        slice_1813: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1812, 2, 0, 9223372036854775807);  slice_1812 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_491: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_336, slice_1813);  matmul_336 = slice_1813 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_168: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_491, -1);  add_491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_525: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_168, 0.0, False);  softmax_168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_337: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_525, slice_1810);  dropout_525 = slice_1810 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_694: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_337, 1, 2);  matmul_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_182: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_694, [1, 1, 512]);  transpose_694 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_712: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_182, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_526: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_712, 0.1, False);  linear_712 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_492: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_254, dropout_526);  layer_norm_254 = dropout_526 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_255: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_492, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_492 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_713: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_255, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_214: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_713, 0.125);  linear_713 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_372: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_214, [1, 1, 8, 64]);  mul_214 = None
        transpose_695: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_372, 1, 2);  view_372 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1814: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1815: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1814, 2, 0, 23);  slice_1814 = None
        slice_1816: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1815, 3, 0, 9223372036854775807);  slice_1815 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1817: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1818: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1817, 2, 0, 23);  slice_1817 = None
        slice_1819: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1818, 3, 0, 9223372036854775807);  slice_1818 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_696: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1816, 2, 3);  slice_1816 = None
        matmul_338: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_695, transpose_696);  transpose_695 = transpose_696 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1820: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_14, 0, 0, 9223372036854775807)
        slice_1821: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1820, 1, 0, 9223372036854775807);  slice_1820 = None
        slice_1822: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1821, 2, 0, 9223372036854775807);  slice_1821 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_493: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_338, slice_1822);  matmul_338 = slice_1822 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_169: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_493, -1);  add_493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_527: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_169, 0.0, False);  softmax_169 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_339: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_527, slice_1819);  dropout_527 = slice_1819 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_697: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_339, 1, 2);  matmul_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_183: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_697, [1, 1, 512]);  transpose_697 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_714: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_183, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_528: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_714, 0.1, False);  linear_714 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_494: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_255, dropout_528);  layer_norm_255 = dropout_528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_256: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_494, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_494 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_715: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_256, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_87: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_715);  linear_715 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_529: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_87, 0.0, False);  silu_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_716: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_529, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_529 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_530: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_716, 0.1, False);  linear_716 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_495: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_256, dropout_530);  layer_norm_256 = dropout_530 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_257: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_495, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_495 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_717: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_257, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_215: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_717, 0.125);  linear_717 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_373: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_215, [1, 1, 8, 64]);  mul_215 = None
        transpose_698: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_373, 1, 2);  view_373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_718: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_257, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_374: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_718, [1, -1, 8, 64]);  linear_718 = None
        transpose_699: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_374, 1, 2);  view_374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_719: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_257, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_375: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_719, [1, -1, 8, 64]);  linear_719 = None
        transpose_700: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_375, 1, 2);  view_375 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_261: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_699, torch.float32);  transpose_699 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_262: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_700, torch.float32);  transpose_700 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1823: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__176: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1823, 2, add_472, to_261);  slice_1823 = to_261 = index_copy__176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1824: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__177: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1824, 2, add_472, to_262);  slice_1824 = to_262 = index_copy__177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1825: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1826: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1825, 2, 0, 9223372036854775807);  slice_1825 = None
        slice_1827: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1826, 3, 0, 9223372036854775807);  slice_1826 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1828: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1829: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1828, 2, 0, 9223372036854775807);  slice_1828 = None
        slice_1830: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1829, 3, 0, 9223372036854775807);  slice_1829 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_701: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1827, 2, 3);  slice_1827 = None
        matmul_340: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_698, transpose_701);  transpose_698 = transpose_701 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1831: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_28, 0, 0, 9223372036854775807)
        slice_1832: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1831, 1, 0, 9223372036854775807);  slice_1831 = None
        slice_1833: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1832, 2, 0, 9223372036854775807);  slice_1832 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_496: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_340, slice_1833);  matmul_340 = slice_1833 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_170: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_496, -1);  add_496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_531: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_170, 0.0, False);  softmax_170 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_341: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_531, slice_1830);  dropout_531 = slice_1830 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_702: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_341, 1, 2);  matmul_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_184: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_702, [1, 1, 512]);  transpose_702 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_720: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_184, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_532: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_720, 0.1, False);  linear_720 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_497: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_257, dropout_532);  layer_norm_257 = dropout_532 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_258: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_497, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_721: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_258, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_216: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_721, 0.125);  linear_721 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_376: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_216, [1, 1, 8, 64]);  mul_216 = None
        transpose_703: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_376, 1, 2);  view_376 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1834: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1835: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1834, 2, 0, 23);  slice_1834 = None
        slice_1836: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1835, 3, 0, 9223372036854775807);  slice_1835 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1837: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1838: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1837, 2, 0, 23);  slice_1837 = None
        slice_1839: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1838, 3, 0, 9223372036854775807);  slice_1838 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_704: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1836, 2, 3);  slice_1836 = None
        matmul_342: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_703, transpose_704);  transpose_703 = transpose_704 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1840: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_14, 0, 0, 9223372036854775807)
        slice_1841: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1840, 1, 0, 9223372036854775807);  slice_1840 = None
        slice_1842: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1841, 2, 0, 9223372036854775807);  slice_1841 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_498: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_342, slice_1842);  matmul_342 = slice_1842 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_171: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_498, -1);  add_498 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_533: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_171, 0.0, False);  softmax_171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_343: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_533, slice_1839);  dropout_533 = slice_1839 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_705: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_343, 1, 2);  matmul_343 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_185: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_705, [1, 1, 512]);  transpose_705 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_722: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_185, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_534: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_722, 0.1, False);  linear_722 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_499: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_258, dropout_534);  layer_norm_258 = dropout_534 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_259: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_499, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_499 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_723: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_259, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_88: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_723);  linear_723 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_535: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_88, 0.0, False);  silu_88 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_724: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_535, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_535 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_536: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_724, 0.1, False);  linear_724 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_500: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_259, dropout_536);  layer_norm_259 = dropout_536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_260: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_500, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_500 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_725: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_260, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_217: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_725, 0.125);  linear_725 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_377: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_217, [1, 1, 8, 64]);  mul_217 = None
        transpose_706: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_377, 1, 2);  view_377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_726: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_260, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_378: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_726, [1, -1, 8, 64]);  linear_726 = None
        transpose_707: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_378, 1, 2);  view_378 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_727: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_260, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_379: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_727, [1, -1, 8, 64]);  linear_727 = None
        transpose_708: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_379, 1, 2);  view_379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_263: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_707, torch.float32);  transpose_707 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_264: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_708, torch.float32);  transpose_708 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1843: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__178: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1843, 2, add_472, to_263);  slice_1843 = to_263 = index_copy__178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1844: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__179: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1844, 2, add_472, to_264);  slice_1844 = to_264 = index_copy__179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1845: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1846: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1845, 2, 0, 9223372036854775807);  slice_1845 = None
        slice_1847: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1846, 3, 0, 9223372036854775807);  slice_1846 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1848: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1849: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1848, 2, 0, 9223372036854775807);  slice_1848 = None
        slice_1850: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1849, 3, 0, 9223372036854775807);  slice_1849 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_709: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1847, 2, 3);  slice_1847 = None
        matmul_344: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_706, transpose_709);  transpose_706 = transpose_709 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1851: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_28, 0, 0, 9223372036854775807);  expand_28 = None
        slice_1852: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1851, 1, 0, 9223372036854775807);  slice_1851 = None
        slice_1853: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1852, 2, 0, 9223372036854775807);  slice_1852 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_501: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_344, slice_1853);  matmul_344 = slice_1853 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_172: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_501, -1);  add_501 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_537: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_172, 0.0, False);  softmax_172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_345: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_537, slice_1850);  dropout_537 = slice_1850 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_710: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_345, 1, 2);  matmul_345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_186: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_710, [1, 1, 512]);  transpose_710 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_728: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_186, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_538: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_728, 0.1, False);  linear_728 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_502: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_260, dropout_538);  layer_norm_260 = dropout_538 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_261: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_502, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_502 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_729: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_261, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_218: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_729, 0.125);  linear_729 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_380: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_218, [1, 1, 8, 64]);  mul_218 = None
        transpose_711: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_380, 1, 2);  view_380 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1854: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1855: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1854, 2, 0, 23);  slice_1854 = None
        slice_1856: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1855, 3, 0, 9223372036854775807);  slice_1855 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1857: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1858: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1857, 2, 0, 23);  slice_1857 = None
        slice_1859: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1858, 3, 0, 9223372036854775807);  slice_1858 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_712: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1856, 2, 3);  slice_1856 = None
        matmul_346: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_711, transpose_712);  transpose_711 = transpose_712 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1860: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_14, 0, 0, 9223372036854775807);  masked_fill_14 = None
        slice_1861: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1860, 1, 0, 9223372036854775807);  slice_1860 = None
        slice_1862: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1861, 2, 0, 9223372036854775807);  slice_1861 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_503: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_346, slice_1862);  matmul_346 = slice_1862 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_173: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_503, -1);  add_503 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_539: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_173, 0.0, False);  softmax_173 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_347: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_539, slice_1859);  dropout_539 = slice_1859 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_713: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_347, 1, 2);  matmul_347 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_187: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_713, [1, 1, 512]);  transpose_713 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_730: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_187, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_540: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_730, 0.1, False);  linear_730 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_504: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_261, dropout_540);  layer_norm_261 = dropout_540 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_262: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_504, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_731: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_262, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_89: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_731);  linear_731 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_541: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_89, 0.0, False);  silu_89 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_732: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_541, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_541 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_542: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_732, 0.1, False);  linear_732 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_505: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_262, dropout_542);  layer_norm_262 = dropout_542 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_263: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_505, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_733: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_263, p_model_lm_head_weight);  layer_norm_263 = None
        add_506: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_733, b_model_final_logits_bias);  linear_733 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1863: "i64[1]" = torch.ops.aten.slice.Tensor(add_472, 0, -1, 9223372036854775807);  add_472 = None
        add_507: "i64[1]" = torch.ops.aten.add.Tensor(slice_1863, 1);  slice_1863 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1864: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_506, 0, 0, 9223372036854775807);  add_506 = None
        select_60: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1864, 1, -1);  slice_1864 = None
        slice_1865: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_60, 1, 0, 9223372036854775807);  select_60 = None
        clone_27: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1865);  slice_1865 = None
        to_265: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_27, torch.float32);  clone_27 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_266: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_265, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_13: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_266, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__13: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_13, to_32);  zeros_like_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_508: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_266, add__13);  to_266 = add__13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_13: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_508, -1);  add_508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_13: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_13, -1);  log_softmax_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_219: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_13, and_13);  argmax_13 = None
        rsub_28: "i64[1]" = torch.ops.aten.rsub.Scalar(and_13, 1)
        mul_220: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_28);  rsub_28 = None
        add_509: "i64[1]" = torch.ops.aten.add.Tensor(mul_219, mul_220);  mul_219 = mul_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1866: "i64[1]" = torch.ops.aten.slice.Tensor(add_509, 0, 0, 9223372036854775807);  add_509 = None
        unsqueeze_86: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1866, 1);  slice_1866 = None
        cat_13: "i64[1, 15]" = torch.ops.aten.cat.default([cat_12, unsqueeze_86], -1);  cat_12 = unsqueeze_86 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_40: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_41: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_27: "b8[1]" = torch.ops.aten.__or__.Tensor(full_40, full_41);  full_40 = full_41 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_267: "i64[1]" = torch.ops.aten.to.dtype_layout(to_249, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1867: "i64[1, 15]" = torch.ops.aten.slice.Tensor(cat_13, 0, 0, 9223372036854775807)
        select_61: "i64[1]" = torch.ops.aten.select.int(slice_1867, 1, -1);  slice_1867 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_15: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_61, to_267);  select_61 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_28: "b8[1]" = torch.ops.aten.__or__.Tensor(or_27, isin_15);  or_27 = isin_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_15: "b8[1]" = torch.ops.aten.bitwise_not.default(or_28);  or_28 = None
        and_14: "i64[1]" = torch.ops.aten.__and__.Tensor(and_13, bitwise_not_15);  and_13 = bitwise_not_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_14: "i64[]" = torch.ops.aten.max.default(and_14)
        eq_13: "b8[]" = torch.ops.aten.eq.Scalar(max_14, 0);  max_14 = eq_13 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1868: "i64[1, 15]" = torch.ops.aten.slice.Tensor(cat_13, 0, 0, 9223372036854775807)
        slice_1869: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1868, 1, -1, 9223372036854775807);  slice_1868 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_28: "i64[1, 1]" = torch.ops.aten.clone.default(slice_1869, memory_format = torch.contiguous_format);  slice_1869 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_381: "i64[1, 1]" = torch.ops.aten.view.default(clone_28, [-1, 1]);  clone_28 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_30: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_381, 59513);  view_381 = None
        mul_221: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_30, 22.627416997969522);  embedding_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_87: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_507, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_1870: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_88: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_1870, 1);  slice_1870 = None
        unsqueeze_89: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_88, 2);  unsqueeze_88 = None
        slice_1871: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_89, 3, 0, 9223372036854775807);  unsqueeze_89 = None
        expand_29: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_1871, [1, 1, 1, 23]);  slice_1871 = None
        to_268: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_29, torch.float32);  expand_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_29: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_268, 1.0);  to_268 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_269: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_29, torch.bool)
        masked_fill_15: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_29, to_269, -3.4028234663852886e+38);  rsub_29 = to_269 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_31: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_87);  unsqueeze_87 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_270: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_31, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_31 = None
        add_510: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_221, to_270);  mul_221 = to_270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_543: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_510, 0.1, False);  add_510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_62: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_63: "f32[20, 64]" = torch.ops.aten.select.int(select_62, 0, 0);  select_62 = None
        any_19: "b8[20]" = torch.ops.aten.any.dim(select_63, -1);  select_63 = None
        sum_17: "i64[]" = torch.ops.aten.sum.default(any_19);  any_19 = sum_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_42: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_21: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_188: "i64[1, 1]" = torch.ops.aten.reshape.default(add_507, [-1, 1])
        gt_14: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_21, reshape_188);  arange_21 = reshape_188 = None
        mul__14: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_42, gt_14);  full_42 = gt_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_90: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__14, 0);  mul__14 = None
        unsqueeze_91: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_90, 1);  unsqueeze_90 = None
        slice_1872: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_91, 2, 0, 9223372036854775807);  unsqueeze_91 = None
        slice_1873: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1872, 3, 0, 9223372036854775807);  slice_1872 = None
        expand_30: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_1873, [1, 1, -1, -1]);  slice_1873 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_734: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_543, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_222: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_734, 0.125);  linear_734 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_382: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_222, [1, 1, 8, 64]);  mul_222 = None
        transpose_714: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_382, 1, 2);  view_382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_735: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_543, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_383: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_735, [1, -1, 8, 64]);  linear_735 = None
        transpose_715: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_383, 1, 2);  view_383 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_736: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_543, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_384: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_736, [1, -1, 8, 64]);  linear_736 = None
        transpose_716: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_384, 1, 2);  view_384 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_271: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_715, torch.float32);  transpose_715 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_272: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_716, torch.float32);  transpose_716 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1874: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__180: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1874, 2, add_507, to_271);  slice_1874 = to_271 = index_copy__180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1875: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__181: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1875, 2, add_507, to_272);  slice_1875 = to_272 = index_copy__181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1876: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1877: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1876, 2, 0, 9223372036854775807);  slice_1876 = None
        slice_1878: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1877, 3, 0, 9223372036854775807);  slice_1877 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1879: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1880: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1879, 2, 0, 9223372036854775807);  slice_1879 = None
        slice_1881: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1880, 3, 0, 9223372036854775807);  slice_1880 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_717: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1878, 2, 3);  slice_1878 = None
        matmul_348: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_714, transpose_717);  transpose_714 = transpose_717 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1882: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_30, 0, 0, 9223372036854775807)
        slice_1883: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1882, 1, 0, 9223372036854775807);  slice_1882 = None
        slice_1884: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1883, 2, 0, 9223372036854775807);  slice_1883 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_511: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_348, slice_1884);  matmul_348 = slice_1884 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_174: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_511, -1);  add_511 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_544: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_174, 0.0, False);  softmax_174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_349: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_544, slice_1881);  dropout_544 = slice_1881 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_718: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_349, 1, 2);  matmul_349 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_189: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_718, [1, 1, 512]);  transpose_718 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_737: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_189, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_545: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_737, 0.1, False);  linear_737 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_512: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_543, dropout_545);  dropout_543 = dropout_545 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_264: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_512, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_512 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_738: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_264, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_223: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_738, 0.125);  linear_738 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_385: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_223, [1, 1, 8, 64]);  mul_223 = None
        transpose_719: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_385, 1, 2);  view_385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1885: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_1886: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1885, 2, 0, 23);  slice_1885 = None
        slice_1887: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1886, 3, 0, 9223372036854775807);  slice_1886 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1888: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_1889: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1888, 2, 0, 23);  slice_1888 = None
        slice_1890: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1889, 3, 0, 9223372036854775807);  slice_1889 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_720: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1887, 2, 3);  slice_1887 = None
        matmul_350: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_719, transpose_720);  transpose_719 = transpose_720 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1891: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_15, 0, 0, 9223372036854775807)
        slice_1892: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1891, 1, 0, 9223372036854775807);  slice_1891 = None
        slice_1893: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1892, 2, 0, 9223372036854775807);  slice_1892 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_513: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_350, slice_1893);  matmul_350 = slice_1893 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_175: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_513, -1);  add_513 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_546: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_175, 0.0, False);  softmax_175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_351: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_546, slice_1890);  dropout_546 = slice_1890 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_721: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_351, 1, 2);  matmul_351 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_190: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_721, [1, 1, 512]);  transpose_721 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_739: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_190, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_547: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_739, 0.1, False);  linear_739 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_514: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_264, dropout_547);  layer_norm_264 = dropout_547 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_265: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_514, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_514 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_740: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_265, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_90: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_740);  linear_740 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_548: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_90, 0.0, False);  silu_90 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_741: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_548, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_548 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_549: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_741, 0.1, False);  linear_741 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_515: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_265, dropout_549);  layer_norm_265 = dropout_549 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_266: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_515, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_515 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_742: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_266, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_224: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_742, 0.125);  linear_742 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_386: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_224, [1, 1, 8, 64]);  mul_224 = None
        transpose_722: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_386, 1, 2);  view_386 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_743: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_266, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_387: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_743, [1, -1, 8, 64]);  linear_743 = None
        transpose_723: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_387, 1, 2);  view_387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_744: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_266, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_388: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_744, [1, -1, 8, 64]);  linear_744 = None
        transpose_724: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_388, 1, 2);  view_388 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_273: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_723, torch.float32);  transpose_723 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_274: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_724, torch.float32);  transpose_724 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1894: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__182: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1894, 2, add_507, to_273);  slice_1894 = to_273 = index_copy__182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1895: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__183: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1895, 2, add_507, to_274);  slice_1895 = to_274 = index_copy__183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1896: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1897: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1896, 2, 0, 9223372036854775807);  slice_1896 = None
        slice_1898: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1897, 3, 0, 9223372036854775807);  slice_1897 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1899: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1900: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1899, 2, 0, 9223372036854775807);  slice_1899 = None
        slice_1901: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1900, 3, 0, 9223372036854775807);  slice_1900 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_725: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1898, 2, 3);  slice_1898 = None
        matmul_352: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_722, transpose_725);  transpose_722 = transpose_725 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1902: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_30, 0, 0, 9223372036854775807)
        slice_1903: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1902, 1, 0, 9223372036854775807);  slice_1902 = None
        slice_1904: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1903, 2, 0, 9223372036854775807);  slice_1903 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_516: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_352, slice_1904);  matmul_352 = slice_1904 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_176: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_516, -1);  add_516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_550: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_176, 0.0, False);  softmax_176 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_353: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_550, slice_1901);  dropout_550 = slice_1901 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_726: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_353, 1, 2);  matmul_353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_191: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_726, [1, 1, 512]);  transpose_726 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_745: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_191, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_551: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_745, 0.1, False);  linear_745 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_517: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_266, dropout_551);  layer_norm_266 = dropout_551 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_267: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_517, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_746: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_267, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_225: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_746, 0.125);  linear_746 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_389: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_225, [1, 1, 8, 64]);  mul_225 = None
        transpose_727: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_389, 1, 2);  view_389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1905: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_1906: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1905, 2, 0, 23);  slice_1905 = None
        slice_1907: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1906, 3, 0, 9223372036854775807);  slice_1906 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1908: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_1909: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1908, 2, 0, 23);  slice_1908 = None
        slice_1910: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1909, 3, 0, 9223372036854775807);  slice_1909 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_728: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1907, 2, 3);  slice_1907 = None
        matmul_354: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_727, transpose_728);  transpose_727 = transpose_728 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1911: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_15, 0, 0, 9223372036854775807)
        slice_1912: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1911, 1, 0, 9223372036854775807);  slice_1911 = None
        slice_1913: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1912, 2, 0, 9223372036854775807);  slice_1912 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_518: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_354, slice_1913);  matmul_354 = slice_1913 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_177: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_518, -1);  add_518 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_552: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_177, 0.0, False);  softmax_177 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_355: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_552, slice_1910);  dropout_552 = slice_1910 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_729: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_355, 1, 2);  matmul_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_192: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_729, [1, 1, 512]);  transpose_729 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_747: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_192, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_553: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_747, 0.1, False);  linear_747 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_519: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_267, dropout_553);  layer_norm_267 = dropout_553 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_268: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_519, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_519 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_748: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_268, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_91: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_748);  linear_748 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_554: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_91, 0.0, False);  silu_91 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_749: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_554, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_554 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_555: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_749, 0.1, False);  linear_749 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_520: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_268, dropout_555);  layer_norm_268 = dropout_555 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_269: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_520, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_750: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_269, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_226: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_750, 0.125);  linear_750 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_390: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_226, [1, 1, 8, 64]);  mul_226 = None
        transpose_730: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_390, 1, 2);  view_390 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_751: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_269, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_391: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_751, [1, -1, 8, 64]);  linear_751 = None
        transpose_731: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_391, 1, 2);  view_391 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_752: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_269, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_392: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_752, [1, -1, 8, 64]);  linear_752 = None
        transpose_732: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_392, 1, 2);  view_392 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_275: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_731, torch.float32);  transpose_731 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_276: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_732, torch.float32);  transpose_732 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1914: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__184: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1914, 2, add_507, to_275);  slice_1914 = to_275 = index_copy__184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1915: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__185: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1915, 2, add_507, to_276);  slice_1915 = to_276 = index_copy__185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1916: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1917: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1916, 2, 0, 9223372036854775807);  slice_1916 = None
        slice_1918: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1917, 3, 0, 9223372036854775807);  slice_1917 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1919: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1920: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1919, 2, 0, 9223372036854775807);  slice_1919 = None
        slice_1921: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1920, 3, 0, 9223372036854775807);  slice_1920 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_733: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1918, 2, 3);  slice_1918 = None
        matmul_356: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_730, transpose_733);  transpose_730 = transpose_733 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1922: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_30, 0, 0, 9223372036854775807)
        slice_1923: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1922, 1, 0, 9223372036854775807);  slice_1922 = None
        slice_1924: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1923, 2, 0, 9223372036854775807);  slice_1923 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_521: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_356, slice_1924);  matmul_356 = slice_1924 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_178: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_521, -1);  add_521 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_556: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_178, 0.0, False);  softmax_178 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_357: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_556, slice_1921);  dropout_556 = slice_1921 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_734: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_357, 1, 2);  matmul_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_193: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_734, [1, 1, 512]);  transpose_734 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_753: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_193, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_557: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_753, 0.1, False);  linear_753 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_522: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_269, dropout_557);  layer_norm_269 = dropout_557 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_270: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_522, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_522 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_754: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_270, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_227: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_754, 0.125);  linear_754 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_393: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_227, [1, 1, 8, 64]);  mul_227 = None
        transpose_735: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_393, 1, 2);  view_393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1925: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_1926: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1925, 2, 0, 23);  slice_1925 = None
        slice_1927: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1926, 3, 0, 9223372036854775807);  slice_1926 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1928: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_1929: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1928, 2, 0, 23);  slice_1928 = None
        slice_1930: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1929, 3, 0, 9223372036854775807);  slice_1929 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_736: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1927, 2, 3);  slice_1927 = None
        matmul_358: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_735, transpose_736);  transpose_735 = transpose_736 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1931: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_15, 0, 0, 9223372036854775807)
        slice_1932: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1931, 1, 0, 9223372036854775807);  slice_1931 = None
        slice_1933: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1932, 2, 0, 9223372036854775807);  slice_1932 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_523: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_358, slice_1933);  matmul_358 = slice_1933 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_179: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_523, -1);  add_523 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_558: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_179, 0.0, False);  softmax_179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_359: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_558, slice_1930);  dropout_558 = slice_1930 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_737: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_359, 1, 2);  matmul_359 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_194: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_737, [1, 1, 512]);  transpose_737 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_755: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_194, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_559: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_755, 0.1, False);  linear_755 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_524: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_270, dropout_559);  layer_norm_270 = dropout_559 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_271: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_524, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_756: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_271, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_92: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_756);  linear_756 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_560: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_92, 0.0, False);  silu_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_757: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_560, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_560 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_561: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_757, 0.1, False);  linear_757 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_525: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_271, dropout_561);  layer_norm_271 = dropout_561 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_272: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_525, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_525 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_758: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_272, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_228: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_758, 0.125);  linear_758 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_394: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_228, [1, 1, 8, 64]);  mul_228 = None
        transpose_738: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_394, 1, 2);  view_394 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_759: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_272, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_395: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_759, [1, -1, 8, 64]);  linear_759 = None
        transpose_739: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_395, 1, 2);  view_395 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_760: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_272, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_396: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_760, [1, -1, 8, 64]);  linear_760 = None
        transpose_740: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_396, 1, 2);  view_396 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_277: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_739, torch.float32);  transpose_739 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_278: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_740, torch.float32);  transpose_740 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1934: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__186: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1934, 2, add_507, to_277);  slice_1934 = to_277 = index_copy__186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1935: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__187: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1935, 2, add_507, to_278);  slice_1935 = to_278 = index_copy__187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1936: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1937: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1936, 2, 0, 9223372036854775807);  slice_1936 = None
        slice_1938: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1937, 3, 0, 9223372036854775807);  slice_1937 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1939: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1940: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1939, 2, 0, 9223372036854775807);  slice_1939 = None
        slice_1941: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1940, 3, 0, 9223372036854775807);  slice_1940 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_741: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1938, 2, 3);  slice_1938 = None
        matmul_360: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_738, transpose_741);  transpose_738 = transpose_741 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1942: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_30, 0, 0, 9223372036854775807)
        slice_1943: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1942, 1, 0, 9223372036854775807);  slice_1942 = None
        slice_1944: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1943, 2, 0, 9223372036854775807);  slice_1943 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_526: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_360, slice_1944);  matmul_360 = slice_1944 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_180: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_526, -1);  add_526 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_562: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_180, 0.0, False);  softmax_180 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_361: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_562, slice_1941);  dropout_562 = slice_1941 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_742: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_361, 1, 2);  matmul_361 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_195: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_742, [1, 1, 512]);  transpose_742 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_761: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_195, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_563: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_761, 0.1, False);  linear_761 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_527: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_272, dropout_563);  layer_norm_272 = dropout_563 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_273: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_527, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_527 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_762: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_273, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_229: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_762, 0.125);  linear_762 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_397: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_229, [1, 1, 8, 64]);  mul_229 = None
        transpose_743: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_397, 1, 2);  view_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1945: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_1946: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1945, 2, 0, 23);  slice_1945 = None
        slice_1947: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1946, 3, 0, 9223372036854775807);  slice_1946 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1948: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_1949: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1948, 2, 0, 23);  slice_1948 = None
        slice_1950: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1949, 3, 0, 9223372036854775807);  slice_1949 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_744: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1947, 2, 3);  slice_1947 = None
        matmul_362: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_743, transpose_744);  transpose_743 = transpose_744 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1951: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_15, 0, 0, 9223372036854775807)
        slice_1952: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1951, 1, 0, 9223372036854775807);  slice_1951 = None
        slice_1953: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1952, 2, 0, 9223372036854775807);  slice_1952 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_528: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_362, slice_1953);  matmul_362 = slice_1953 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_181: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_528, -1);  add_528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_564: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_181, 0.0, False);  softmax_181 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_363: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_564, slice_1950);  dropout_564 = slice_1950 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_745: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_363, 1, 2);  matmul_363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_196: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_745, [1, 1, 512]);  transpose_745 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_763: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_196, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_565: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_763, 0.1, False);  linear_763 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_529: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_273, dropout_565);  layer_norm_273 = dropout_565 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_274: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_529, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_529 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_764: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_274, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_93: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_764);  linear_764 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_566: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_93, 0.0, False);  silu_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_765: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_566, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_566 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_567: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_765, 0.1, False);  linear_765 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_530: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_274, dropout_567);  layer_norm_274 = dropout_567 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_275: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_530, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_530 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_766: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_275, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_230: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_766, 0.125);  linear_766 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_398: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_230, [1, 1, 8, 64]);  mul_230 = None
        transpose_746: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_398, 1, 2);  view_398 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_767: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_275, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_399: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_767, [1, -1, 8, 64]);  linear_767 = None
        transpose_747: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_399, 1, 2);  view_399 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_768: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_275, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_400: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_768, [1, -1, 8, 64]);  linear_768 = None
        transpose_748: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_400, 1, 2);  view_400 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_279: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_747, torch.float32);  transpose_747 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_280: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_748, torch.float32);  transpose_748 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1954: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__188: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1954, 2, add_507, to_279);  slice_1954 = to_279 = index_copy__188 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1955: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__189: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1955, 2, add_507, to_280);  slice_1955 = to_280 = index_copy__189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1956: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1957: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1956, 2, 0, 9223372036854775807);  slice_1956 = None
        slice_1958: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1957, 3, 0, 9223372036854775807);  slice_1957 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1959: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1960: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1959, 2, 0, 9223372036854775807);  slice_1959 = None
        slice_1961: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1960, 3, 0, 9223372036854775807);  slice_1960 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_749: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1958, 2, 3);  slice_1958 = None
        matmul_364: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_746, transpose_749);  transpose_746 = transpose_749 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1962: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_30, 0, 0, 9223372036854775807)
        slice_1963: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1962, 1, 0, 9223372036854775807);  slice_1962 = None
        slice_1964: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1963, 2, 0, 9223372036854775807);  slice_1963 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_531: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_364, slice_1964);  matmul_364 = slice_1964 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_182: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_531, -1);  add_531 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_568: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_182, 0.0, False);  softmax_182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_365: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_568, slice_1961);  dropout_568 = slice_1961 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_750: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_365, 1, 2);  matmul_365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_197: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_750, [1, 1, 512]);  transpose_750 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_769: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_197, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_569: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_769, 0.1, False);  linear_769 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_532: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_275, dropout_569);  layer_norm_275 = dropout_569 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_276: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_532, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_532 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_770: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_276, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_231: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_770, 0.125);  linear_770 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_401: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_231, [1, 1, 8, 64]);  mul_231 = None
        transpose_751: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_401, 1, 2);  view_401 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1965: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_1966: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1965, 2, 0, 23);  slice_1965 = None
        slice_1967: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1966, 3, 0, 9223372036854775807);  slice_1966 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1968: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_1969: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1968, 2, 0, 23);  slice_1968 = None
        slice_1970: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1969, 3, 0, 9223372036854775807);  slice_1969 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_752: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1967, 2, 3);  slice_1967 = None
        matmul_366: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_751, transpose_752);  transpose_751 = transpose_752 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1971: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_15, 0, 0, 9223372036854775807)
        slice_1972: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1971, 1, 0, 9223372036854775807);  slice_1971 = None
        slice_1973: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1972, 2, 0, 9223372036854775807);  slice_1972 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_533: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_366, slice_1973);  matmul_366 = slice_1973 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_183: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_533, -1);  add_533 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_570: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_183, 0.0, False);  softmax_183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_367: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_570, slice_1970);  dropout_570 = slice_1970 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_753: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_367, 1, 2);  matmul_367 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_198: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_753, [1, 1, 512]);  transpose_753 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_771: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_198, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_571: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_771, 0.1, False);  linear_771 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_534: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_276, dropout_571);  layer_norm_276 = dropout_571 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_277: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_534, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_534 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_772: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_277, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_94: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_772);  linear_772 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_572: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_94, 0.0, False);  silu_94 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_773: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_572, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_572 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_573: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_773, 0.1, False);  linear_773 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_535: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_277, dropout_573);  layer_norm_277 = dropout_573 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_278: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_535, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_535 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_774: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_278, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_232: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_774, 0.125);  linear_774 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_402: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_232, [1, 1, 8, 64]);  mul_232 = None
        transpose_754: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_402, 1, 2);  view_402 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_775: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_278, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_403: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_775, [1, -1, 8, 64]);  linear_775 = None
        transpose_755: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_403, 1, 2);  view_403 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_776: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_278, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_404: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_776, [1, -1, 8, 64]);  linear_776 = None
        transpose_756: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_404, 1, 2);  view_404 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_281: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_755, torch.float32);  transpose_755 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_282: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_756, torch.float32);  transpose_756 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_1974: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__190: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1974, 2, add_507, to_281);  slice_1974 = to_281 = index_copy__190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_1975: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__191: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_1975, 2, add_507, to_282);  slice_1975 = to_282 = index_copy__191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_1976: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1977: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1976, 2, 0, 9223372036854775807);  slice_1976 = None
        slice_1978: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1977, 3, 0, 9223372036854775807);  slice_1977 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_1979: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1980: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1979, 2, 0, 9223372036854775807);  slice_1979 = None
        slice_1981: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_1980, 3, 0, 9223372036854775807);  slice_1980 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_757: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_1978, 2, 3);  slice_1978 = None
        matmul_368: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_754, transpose_757);  transpose_754 = transpose_757 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1982: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_30, 0, 0, 9223372036854775807);  expand_30 = None
        slice_1983: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1982, 1, 0, 9223372036854775807);  slice_1982 = None
        slice_1984: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_1983, 2, 0, 9223372036854775807);  slice_1983 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_536: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_368, slice_1984);  matmul_368 = slice_1984 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_184: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_536, -1);  add_536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_574: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_184, 0.0, False);  softmax_184 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_369: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_574, slice_1981);  dropout_574 = slice_1981 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_758: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_369, 1, 2);  matmul_369 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_199: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_758, [1, 1, 512]);  transpose_758 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_777: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_199, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_575: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_777, 0.1, False);  linear_777 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_537: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_278, dropout_575);  layer_norm_278 = dropout_575 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_279: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_537, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_537 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_778: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_279, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_233: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_778, 0.125);  linear_778 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_405: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_233, [1, 1, 8, 64]);  mul_233 = None
        transpose_759: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_405, 1, 2);  view_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1985: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_1986: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1985, 2, 0, 23);  slice_1985 = None
        slice_1987: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1986, 3, 0, 9223372036854775807);  slice_1986 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_1988: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_1989: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1988, 2, 0, 23);  slice_1988 = None
        slice_1990: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_1989, 3, 0, 9223372036854775807);  slice_1989 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_760: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_1987, 2, 3);  slice_1987 = None
        matmul_370: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_759, transpose_760);  transpose_759 = transpose_760 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_1991: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_15, 0, 0, 9223372036854775807);  masked_fill_15 = None
        slice_1992: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1991, 1, 0, 9223372036854775807);  slice_1991 = None
        slice_1993: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_1992, 2, 0, 9223372036854775807);  slice_1992 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_538: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_370, slice_1993);  matmul_370 = slice_1993 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_185: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_538, -1);  add_538 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_576: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_185, 0.0, False);  softmax_185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_371: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_576, slice_1990);  dropout_576 = slice_1990 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_761: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_371, 1, 2);  matmul_371 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_200: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_761, [1, 1, 512]);  transpose_761 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_779: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_200, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_577: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_779, 0.1, False);  linear_779 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_539: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_279, dropout_577);  layer_norm_279 = dropout_577 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_280: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_539, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_539 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_780: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_280, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_95: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_780);  linear_780 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_578: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_95, 0.0, False);  silu_95 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_781: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_578, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_578 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_579: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_781, 0.1, False);  linear_781 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_540: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_280, dropout_579);  layer_norm_280 = dropout_579 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_281: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_540, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_540 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_782: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_281, p_model_lm_head_weight);  layer_norm_281 = None
        add_541: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_782, b_model_final_logits_bias);  linear_782 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_1994: "i64[1]" = torch.ops.aten.slice.Tensor(add_507, 0, -1, 9223372036854775807);  add_507 = None
        add_542: "i64[1]" = torch.ops.aten.add.Tensor(slice_1994, 1);  slice_1994 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_1995: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_541, 0, 0, 9223372036854775807);  add_541 = None
        select_64: "f32[1, 59514]" = torch.ops.aten.select.int(slice_1995, 1, -1);  slice_1995 = None
        slice_1996: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_64, 1, 0, 9223372036854775807);  select_64 = None
        clone_29: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_1996);  slice_1996 = None
        to_283: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_29, torch.float32);  clone_29 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_284: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_283, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_14: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_284, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__14: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_14, to_32);  zeros_like_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_543: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_284, add__14);  to_284 = add__14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_14: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_543, -1);  add_543 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_14: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_14, -1);  log_softmax_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_234: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_14, and_14);  argmax_14 = None
        rsub_30: "i64[1]" = torch.ops.aten.rsub.Scalar(and_14, 1)
        mul_235: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_30);  rsub_30 = None
        add_544: "i64[1]" = torch.ops.aten.add.Tensor(mul_234, mul_235);  mul_234 = mul_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_1997: "i64[1]" = torch.ops.aten.slice.Tensor(add_544, 0, 0, 9223372036854775807);  add_544 = None
        unsqueeze_92: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_1997, 1);  slice_1997 = None
        cat_14: "i64[1, 16]" = torch.ops.aten.cat.default([cat_13, unsqueeze_92], -1);  cat_13 = unsqueeze_92 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_43: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_44: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_29: "b8[1]" = torch.ops.aten.__or__.Tensor(full_43, full_44);  full_43 = full_44 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_285: "i64[1]" = torch.ops.aten.to.dtype_layout(to_267, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_267 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_1998: "i64[1, 16]" = torch.ops.aten.slice.Tensor(cat_14, 0, 0, 9223372036854775807)
        select_65: "i64[1]" = torch.ops.aten.select.int(slice_1998, 1, -1);  slice_1998 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_16: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_65, to_285);  select_65 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_30: "b8[1]" = torch.ops.aten.__or__.Tensor(or_29, isin_16);  or_29 = isin_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_16: "b8[1]" = torch.ops.aten.bitwise_not.default(or_30);  or_30 = None
        and_15: "i64[1]" = torch.ops.aten.__and__.Tensor(and_14, bitwise_not_16);  and_14 = bitwise_not_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_15: "i64[]" = torch.ops.aten.max.default(and_15)
        eq_14: "b8[]" = torch.ops.aten.eq.Scalar(max_15, 0);  max_15 = eq_14 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_1999: "i64[1, 16]" = torch.ops.aten.slice.Tensor(cat_14, 0, 0, 9223372036854775807)
        slice_2000: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_1999, 1, -1, 9223372036854775807);  slice_1999 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_30: "i64[1, 1]" = torch.ops.aten.clone.default(slice_2000, memory_format = torch.contiguous_format);  slice_2000 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_406: "i64[1, 1]" = torch.ops.aten.view.default(clone_30, [-1, 1]);  clone_30 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_32: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_406, 59513);  view_406 = None
        mul_236: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_32, 22.627416997969522);  embedding_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_93: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_542, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_2001: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_94: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_2001, 1);  slice_2001 = None
        unsqueeze_95: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_94, 2);  unsqueeze_94 = None
        slice_2002: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_95, 3, 0, 9223372036854775807);  unsqueeze_95 = None
        expand_31: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_2002, [1, 1, 1, 23]);  slice_2002 = None
        to_286: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_31, torch.float32);  expand_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_31: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_286, 1.0);  to_286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_287: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_31, torch.bool)
        masked_fill_16: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_31, to_287, -3.4028234663852886e+38);  rsub_31 = to_287 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_33: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_93);  unsqueeze_93 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_288: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_33, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_33 = None
        add_545: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_236, to_288);  mul_236 = to_288 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_580: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_545, 0.1, False);  add_545 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_66: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_67: "f32[20, 64]" = torch.ops.aten.select.int(select_66, 0, 0);  select_66 = None
        any_20: "b8[20]" = torch.ops.aten.any.dim(select_67, -1);  select_67 = None
        sum_18: "i64[]" = torch.ops.aten.sum.default(any_20);  any_20 = sum_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_45: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_22: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_201: "i64[1, 1]" = torch.ops.aten.reshape.default(add_542, [-1, 1])
        gt_15: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_22, reshape_201);  arange_22 = reshape_201 = None
        mul__15: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_45, gt_15);  full_45 = gt_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_96: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__15, 0);  mul__15 = None
        unsqueeze_97: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_96, 1);  unsqueeze_96 = None
        slice_2003: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_97, 2, 0, 9223372036854775807);  unsqueeze_97 = None
        slice_2004: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2003, 3, 0, 9223372036854775807);  slice_2003 = None
        expand_32: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_2004, [1, 1, -1, -1]);  slice_2004 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_783: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_580, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_237: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_783, 0.125);  linear_783 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_407: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_237, [1, 1, 8, 64]);  mul_237 = None
        transpose_762: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_407, 1, 2);  view_407 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_784: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_580, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_408: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_784, [1, -1, 8, 64]);  linear_784 = None
        transpose_763: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_408, 1, 2);  view_408 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_785: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_580, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_409: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_785, [1, -1, 8, 64]);  linear_785 = None
        transpose_764: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_409, 1, 2);  view_409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_289: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_763, torch.float32);  transpose_763 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_290: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_764, torch.float32);  transpose_764 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2005: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__192: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2005, 2, add_542, to_289);  slice_2005 = to_289 = index_copy__192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2006: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__193: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2006, 2, add_542, to_290);  slice_2006 = to_290 = index_copy__193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2007: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2008: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2007, 2, 0, 9223372036854775807);  slice_2007 = None
        slice_2009: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2008, 3, 0, 9223372036854775807);  slice_2008 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2010: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2011: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2010, 2, 0, 9223372036854775807);  slice_2010 = None
        slice_2012: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2011, 3, 0, 9223372036854775807);  slice_2011 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_765: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2009, 2, 3);  slice_2009 = None
        matmul_372: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_762, transpose_765);  transpose_762 = transpose_765 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2013: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_32, 0, 0, 9223372036854775807)
        slice_2014: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2013, 1, 0, 9223372036854775807);  slice_2013 = None
        slice_2015: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2014, 2, 0, 9223372036854775807);  slice_2014 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_546: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_372, slice_2015);  matmul_372 = slice_2015 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_186: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_546, -1);  add_546 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_581: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_186, 0.0, False);  softmax_186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_373: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_581, slice_2012);  dropout_581 = slice_2012 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_766: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_373, 1, 2);  matmul_373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_202: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_766, [1, 1, 512]);  transpose_766 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_786: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_202, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_582: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_786, 0.1, False);  linear_786 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_547: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_580, dropout_582);  dropout_580 = dropout_582 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_282: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_547, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_547 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_787: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_282, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_238: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_787, 0.125);  linear_787 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_410: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_238, [1, 1, 8, 64]);  mul_238 = None
        transpose_767: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_410, 1, 2);  view_410 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2016: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2017: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2016, 2, 0, 23);  slice_2016 = None
        slice_2018: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2017, 3, 0, 9223372036854775807);  slice_2017 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2019: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2020: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2019, 2, 0, 23);  slice_2019 = None
        slice_2021: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2020, 3, 0, 9223372036854775807);  slice_2020 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_768: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2018, 2, 3);  slice_2018 = None
        matmul_374: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_767, transpose_768);  transpose_767 = transpose_768 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2022: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_16, 0, 0, 9223372036854775807)
        slice_2023: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2022, 1, 0, 9223372036854775807);  slice_2022 = None
        slice_2024: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2023, 2, 0, 9223372036854775807);  slice_2023 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_548: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_374, slice_2024);  matmul_374 = slice_2024 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_187: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_548, -1);  add_548 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_583: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_187, 0.0, False);  softmax_187 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_375: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_583, slice_2021);  dropout_583 = slice_2021 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_769: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_375, 1, 2);  matmul_375 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_203: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_769, [1, 1, 512]);  transpose_769 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_788: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_203, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_584: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_788, 0.1, False);  linear_788 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_549: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_282, dropout_584);  layer_norm_282 = dropout_584 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_283: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_549, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_549 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_789: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_283, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_96: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_789);  linear_789 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_585: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_96, 0.0, False);  silu_96 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_790: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_585, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_585 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_586: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_790, 0.1, False);  linear_790 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_550: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_283, dropout_586);  layer_norm_283 = dropout_586 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_284: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_550, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_550 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_791: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_284, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_239: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_791, 0.125);  linear_791 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_411: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_239, [1, 1, 8, 64]);  mul_239 = None
        transpose_770: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_411, 1, 2);  view_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_792: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_284, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_412: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_792, [1, -1, 8, 64]);  linear_792 = None
        transpose_771: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_412, 1, 2);  view_412 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_793: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_284, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_413: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_793, [1, -1, 8, 64]);  linear_793 = None
        transpose_772: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_413, 1, 2);  view_413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_291: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_771, torch.float32);  transpose_771 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_292: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_772, torch.float32);  transpose_772 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2025: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__194: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2025, 2, add_542, to_291);  slice_2025 = to_291 = index_copy__194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2026: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__195: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2026, 2, add_542, to_292);  slice_2026 = to_292 = index_copy__195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2027: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2028: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2027, 2, 0, 9223372036854775807);  slice_2027 = None
        slice_2029: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2028, 3, 0, 9223372036854775807);  slice_2028 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2030: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2031: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2030, 2, 0, 9223372036854775807);  slice_2030 = None
        slice_2032: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2031, 3, 0, 9223372036854775807);  slice_2031 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_773: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2029, 2, 3);  slice_2029 = None
        matmul_376: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_770, transpose_773);  transpose_770 = transpose_773 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2033: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_32, 0, 0, 9223372036854775807)
        slice_2034: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2033, 1, 0, 9223372036854775807);  slice_2033 = None
        slice_2035: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2034, 2, 0, 9223372036854775807);  slice_2034 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_551: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_376, slice_2035);  matmul_376 = slice_2035 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_188: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_551, -1);  add_551 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_587: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_188, 0.0, False);  softmax_188 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_377: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_587, slice_2032);  dropout_587 = slice_2032 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_774: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_377, 1, 2);  matmul_377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_204: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_774, [1, 1, 512]);  transpose_774 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_794: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_204, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_588: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_794, 0.1, False);  linear_794 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_552: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_284, dropout_588);  layer_norm_284 = dropout_588 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_285: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_552, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_552 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_795: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_285, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_240: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_795, 0.125);  linear_795 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_414: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_240, [1, 1, 8, 64]);  mul_240 = None
        transpose_775: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_414, 1, 2);  view_414 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2036: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2037: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2036, 2, 0, 23);  slice_2036 = None
        slice_2038: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2037, 3, 0, 9223372036854775807);  slice_2037 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2039: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2040: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2039, 2, 0, 23);  slice_2039 = None
        slice_2041: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2040, 3, 0, 9223372036854775807);  slice_2040 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_776: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2038, 2, 3);  slice_2038 = None
        matmul_378: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_775, transpose_776);  transpose_775 = transpose_776 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2042: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_16, 0, 0, 9223372036854775807)
        slice_2043: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2042, 1, 0, 9223372036854775807);  slice_2042 = None
        slice_2044: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2043, 2, 0, 9223372036854775807);  slice_2043 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_553: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_378, slice_2044);  matmul_378 = slice_2044 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_189: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_553, -1);  add_553 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_589: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_189, 0.0, False);  softmax_189 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_379: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_589, slice_2041);  dropout_589 = slice_2041 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_777: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_379, 1, 2);  matmul_379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_205: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_777, [1, 1, 512]);  transpose_777 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_796: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_205, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_590: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_796, 0.1, False);  linear_796 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_554: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_285, dropout_590);  layer_norm_285 = dropout_590 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_286: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_554, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_554 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_797: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_286, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_97: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_797);  linear_797 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_591: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_97, 0.0, False);  silu_97 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_798: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_591, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_591 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_592: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_798, 0.1, False);  linear_798 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_555: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_286, dropout_592);  layer_norm_286 = dropout_592 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_287: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_555, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_555 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_799: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_287, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_241: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_799, 0.125);  linear_799 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_415: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_241, [1, 1, 8, 64]);  mul_241 = None
        transpose_778: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_415, 1, 2);  view_415 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_800: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_287, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_416: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_800, [1, -1, 8, 64]);  linear_800 = None
        transpose_779: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_416, 1, 2);  view_416 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_801: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_287, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_417: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_801, [1, -1, 8, 64]);  linear_801 = None
        transpose_780: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_417, 1, 2);  view_417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_293: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_779, torch.float32);  transpose_779 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_294: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_780, torch.float32);  transpose_780 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2045: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__196: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2045, 2, add_542, to_293);  slice_2045 = to_293 = index_copy__196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2046: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__197: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2046, 2, add_542, to_294);  slice_2046 = to_294 = index_copy__197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2047: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2048: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2047, 2, 0, 9223372036854775807);  slice_2047 = None
        slice_2049: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2048, 3, 0, 9223372036854775807);  slice_2048 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2050: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2051: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2050, 2, 0, 9223372036854775807);  slice_2050 = None
        slice_2052: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2051, 3, 0, 9223372036854775807);  slice_2051 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_781: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2049, 2, 3);  slice_2049 = None
        matmul_380: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_778, transpose_781);  transpose_778 = transpose_781 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2053: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_32, 0, 0, 9223372036854775807)
        slice_2054: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2053, 1, 0, 9223372036854775807);  slice_2053 = None
        slice_2055: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2054, 2, 0, 9223372036854775807);  slice_2054 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_556: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_380, slice_2055);  matmul_380 = slice_2055 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_190: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_556, -1);  add_556 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_593: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_190, 0.0, False);  softmax_190 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_381: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_593, slice_2052);  dropout_593 = slice_2052 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_782: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_381, 1, 2);  matmul_381 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_206: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_782, [1, 1, 512]);  transpose_782 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_802: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_206, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_594: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_802, 0.1, False);  linear_802 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_557: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_287, dropout_594);  layer_norm_287 = dropout_594 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_288: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_557, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_557 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_803: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_288, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_242: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_803, 0.125);  linear_803 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_418: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_242, [1, 1, 8, 64]);  mul_242 = None
        transpose_783: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_418, 1, 2);  view_418 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2056: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2057: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2056, 2, 0, 23);  slice_2056 = None
        slice_2058: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2057, 3, 0, 9223372036854775807);  slice_2057 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2059: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2060: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2059, 2, 0, 23);  slice_2059 = None
        slice_2061: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2060, 3, 0, 9223372036854775807);  slice_2060 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_784: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2058, 2, 3);  slice_2058 = None
        matmul_382: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_783, transpose_784);  transpose_783 = transpose_784 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2062: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_16, 0, 0, 9223372036854775807)
        slice_2063: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2062, 1, 0, 9223372036854775807);  slice_2062 = None
        slice_2064: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2063, 2, 0, 9223372036854775807);  slice_2063 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_558: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_382, slice_2064);  matmul_382 = slice_2064 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_191: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_558, -1);  add_558 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_595: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_191, 0.0, False);  softmax_191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_383: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_595, slice_2061);  dropout_595 = slice_2061 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_785: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_383, 1, 2);  matmul_383 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_207: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_785, [1, 1, 512]);  transpose_785 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_804: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_207, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_596: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_804, 0.1, False);  linear_804 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_559: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_288, dropout_596);  layer_norm_288 = dropout_596 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_289: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_559, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_559 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_805: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_289, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_98: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_805);  linear_805 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_597: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_98, 0.0, False);  silu_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_806: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_597, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_597 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_598: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_806, 0.1, False);  linear_806 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_560: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_289, dropout_598);  layer_norm_289 = dropout_598 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_290: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_560, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_560 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_807: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_290, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_243: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_807, 0.125);  linear_807 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_419: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_243, [1, 1, 8, 64]);  mul_243 = None
        transpose_786: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_419, 1, 2);  view_419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_808: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_290, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_420: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_808, [1, -1, 8, 64]);  linear_808 = None
        transpose_787: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_420, 1, 2);  view_420 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_809: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_290, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_421: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_809, [1, -1, 8, 64]);  linear_809 = None
        transpose_788: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_421, 1, 2);  view_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_295: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_787, torch.float32);  transpose_787 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_296: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_788, torch.float32);  transpose_788 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2065: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__198: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2065, 2, add_542, to_295);  slice_2065 = to_295 = index_copy__198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2066: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__199: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2066, 2, add_542, to_296);  slice_2066 = to_296 = index_copy__199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2067: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2068: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2067, 2, 0, 9223372036854775807);  slice_2067 = None
        slice_2069: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2068, 3, 0, 9223372036854775807);  slice_2068 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2070: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2071: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2070, 2, 0, 9223372036854775807);  slice_2070 = None
        slice_2072: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2071, 3, 0, 9223372036854775807);  slice_2071 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_789: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2069, 2, 3);  slice_2069 = None
        matmul_384: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_786, transpose_789);  transpose_786 = transpose_789 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2073: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_32, 0, 0, 9223372036854775807)
        slice_2074: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2073, 1, 0, 9223372036854775807);  slice_2073 = None
        slice_2075: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2074, 2, 0, 9223372036854775807);  slice_2074 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_561: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_384, slice_2075);  matmul_384 = slice_2075 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_192: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_561, -1);  add_561 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_599: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_192, 0.0, False);  softmax_192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_385: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_599, slice_2072);  dropout_599 = slice_2072 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_790: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_385, 1, 2);  matmul_385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_208: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_790, [1, 1, 512]);  transpose_790 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_810: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_208, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_600: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_810, 0.1, False);  linear_810 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_562: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_290, dropout_600);  layer_norm_290 = dropout_600 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_291: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_562, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_562 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_811: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_291, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_244: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_811, 0.125);  linear_811 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_422: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_244, [1, 1, 8, 64]);  mul_244 = None
        transpose_791: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_422, 1, 2);  view_422 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2076: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2077: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2076, 2, 0, 23);  slice_2076 = None
        slice_2078: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2077, 3, 0, 9223372036854775807);  slice_2077 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2079: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2080: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2079, 2, 0, 23);  slice_2079 = None
        slice_2081: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2080, 3, 0, 9223372036854775807);  slice_2080 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_792: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2078, 2, 3);  slice_2078 = None
        matmul_386: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_791, transpose_792);  transpose_791 = transpose_792 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2082: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_16, 0, 0, 9223372036854775807)
        slice_2083: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2082, 1, 0, 9223372036854775807);  slice_2082 = None
        slice_2084: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2083, 2, 0, 9223372036854775807);  slice_2083 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_563: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_386, slice_2084);  matmul_386 = slice_2084 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_193: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_563, -1);  add_563 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_601: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_193, 0.0, False);  softmax_193 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_387: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_601, slice_2081);  dropout_601 = slice_2081 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_793: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_387, 1, 2);  matmul_387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_209: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_793, [1, 1, 512]);  transpose_793 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_812: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_209, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_602: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_812, 0.1, False);  linear_812 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_564: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_291, dropout_602);  layer_norm_291 = dropout_602 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_292: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_564, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_564 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_813: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_292, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_99: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_813);  linear_813 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_603: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_99, 0.0, False);  silu_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_814: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_603, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_603 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_604: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_814, 0.1, False);  linear_814 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_565: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_292, dropout_604);  layer_norm_292 = dropout_604 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_293: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_565, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_565 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_815: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_293, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_245: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_815, 0.125);  linear_815 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_423: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_245, [1, 1, 8, 64]);  mul_245 = None
        transpose_794: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_423, 1, 2);  view_423 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_816: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_293, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_424: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_816, [1, -1, 8, 64]);  linear_816 = None
        transpose_795: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_424, 1, 2);  view_424 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_817: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_293, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_425: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_817, [1, -1, 8, 64]);  linear_817 = None
        transpose_796: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_425, 1, 2);  view_425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_297: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_795, torch.float32);  transpose_795 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_298: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_796, torch.float32);  transpose_796 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2085: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__200: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2085, 2, add_542, to_297);  slice_2085 = to_297 = index_copy__200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2086: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__201: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2086, 2, add_542, to_298);  slice_2086 = to_298 = index_copy__201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2087: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2088: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2087, 2, 0, 9223372036854775807);  slice_2087 = None
        slice_2089: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2088, 3, 0, 9223372036854775807);  slice_2088 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2090: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2091: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2090, 2, 0, 9223372036854775807);  slice_2090 = None
        slice_2092: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2091, 3, 0, 9223372036854775807);  slice_2091 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_797: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2089, 2, 3);  slice_2089 = None
        matmul_388: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_794, transpose_797);  transpose_794 = transpose_797 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2093: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_32, 0, 0, 9223372036854775807)
        slice_2094: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2093, 1, 0, 9223372036854775807);  slice_2093 = None
        slice_2095: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2094, 2, 0, 9223372036854775807);  slice_2094 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_566: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_388, slice_2095);  matmul_388 = slice_2095 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_194: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_566, -1);  add_566 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_605: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_194, 0.0, False);  softmax_194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_389: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_605, slice_2092);  dropout_605 = slice_2092 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_798: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_389, 1, 2);  matmul_389 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_210: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_798, [1, 1, 512]);  transpose_798 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_818: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_210, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_606: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_818, 0.1, False);  linear_818 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_567: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_293, dropout_606);  layer_norm_293 = dropout_606 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_294: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_567, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_567 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_819: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_294, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_246: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_819, 0.125);  linear_819 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_426: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_246, [1, 1, 8, 64]);  mul_246 = None
        transpose_799: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_426, 1, 2);  view_426 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2096: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2097: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2096, 2, 0, 23);  slice_2096 = None
        slice_2098: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2097, 3, 0, 9223372036854775807);  slice_2097 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2099: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2100: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2099, 2, 0, 23);  slice_2099 = None
        slice_2101: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2100, 3, 0, 9223372036854775807);  slice_2100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_800: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2098, 2, 3);  slice_2098 = None
        matmul_390: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_799, transpose_800);  transpose_799 = transpose_800 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2102: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_16, 0, 0, 9223372036854775807)
        slice_2103: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2102, 1, 0, 9223372036854775807);  slice_2102 = None
        slice_2104: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2103, 2, 0, 9223372036854775807);  slice_2103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_568: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_390, slice_2104);  matmul_390 = slice_2104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_195: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_568, -1);  add_568 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_607: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_195, 0.0, False);  softmax_195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_391: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_607, slice_2101);  dropout_607 = slice_2101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_801: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_391, 1, 2);  matmul_391 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_211: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_801, [1, 1, 512]);  transpose_801 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_820: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_211, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_608: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_820, 0.1, False);  linear_820 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_569: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_294, dropout_608);  layer_norm_294 = dropout_608 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_295: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_569, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_569 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_821: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_295, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_100: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_821);  linear_821 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_609: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_100, 0.0, False);  silu_100 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_822: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_609, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_609 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_610: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_822, 0.1, False);  linear_822 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_570: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_295, dropout_610);  layer_norm_295 = dropout_610 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_296: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_570, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_570 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_823: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_296, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_247: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_823, 0.125);  linear_823 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_427: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_247, [1, 1, 8, 64]);  mul_247 = None
        transpose_802: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_427, 1, 2);  view_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_824: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_296, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_428: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_824, [1, -1, 8, 64]);  linear_824 = None
        transpose_803: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_428, 1, 2);  view_428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_825: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_296, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_429: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_825, [1, -1, 8, 64]);  linear_825 = None
        transpose_804: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_429, 1, 2);  view_429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_299: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_803, torch.float32);  transpose_803 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_300: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_804, torch.float32);  transpose_804 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2105: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__202: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2105, 2, add_542, to_299);  slice_2105 = to_299 = index_copy__202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2106: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__203: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2106, 2, add_542, to_300);  slice_2106 = to_300 = index_copy__203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2107: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2108: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2107, 2, 0, 9223372036854775807);  slice_2107 = None
        slice_2109: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2108, 3, 0, 9223372036854775807);  slice_2108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2110: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2111: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2110, 2, 0, 9223372036854775807);  slice_2110 = None
        slice_2112: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2111, 3, 0, 9223372036854775807);  slice_2111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_805: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2109, 2, 3);  slice_2109 = None
        matmul_392: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_802, transpose_805);  transpose_802 = transpose_805 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2113: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_32, 0, 0, 9223372036854775807);  expand_32 = None
        slice_2114: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2113, 1, 0, 9223372036854775807);  slice_2113 = None
        slice_2115: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2114, 2, 0, 9223372036854775807);  slice_2114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_571: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_392, slice_2115);  matmul_392 = slice_2115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_196: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_571, -1);  add_571 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_611: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_196, 0.0, False);  softmax_196 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_393: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_611, slice_2112);  dropout_611 = slice_2112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_806: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_393, 1, 2);  matmul_393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_212: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_806, [1, 1, 512]);  transpose_806 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_826: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_212, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_612: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_826, 0.1, False);  linear_826 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_572: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_296, dropout_612);  layer_norm_296 = dropout_612 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_297: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_572, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_572 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_827: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_297, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_248: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_827, 0.125);  linear_827 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_430: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_248, [1, 1, 8, 64]);  mul_248 = None
        transpose_807: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_430, 1, 2);  view_430 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2116: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2117: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2116, 2, 0, 23);  slice_2116 = None
        slice_2118: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2117, 3, 0, 9223372036854775807);  slice_2117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2119: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2120: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2119, 2, 0, 23);  slice_2119 = None
        slice_2121: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2120, 3, 0, 9223372036854775807);  slice_2120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_808: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2118, 2, 3);  slice_2118 = None
        matmul_394: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_807, transpose_808);  transpose_807 = transpose_808 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2122: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_16, 0, 0, 9223372036854775807);  masked_fill_16 = None
        slice_2123: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2122, 1, 0, 9223372036854775807);  slice_2122 = None
        slice_2124: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2123, 2, 0, 9223372036854775807);  slice_2123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_573: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_394, slice_2124);  matmul_394 = slice_2124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_197: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_573, -1);  add_573 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_613: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_197, 0.0, False);  softmax_197 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_395: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_613, slice_2121);  dropout_613 = slice_2121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_809: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_395, 1, 2);  matmul_395 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_213: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_809, [1, 1, 512]);  transpose_809 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_828: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_213, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_614: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_828, 0.1, False);  linear_828 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_574: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_297, dropout_614);  layer_norm_297 = dropout_614 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_298: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_574, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_574 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_829: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_298, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_101: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_829);  linear_829 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_615: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_101, 0.0, False);  silu_101 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_830: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_615, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_615 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_616: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_830, 0.1, False);  linear_830 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_575: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_298, dropout_616);  layer_norm_298 = dropout_616 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_299: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_575, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_575 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_831: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_299, p_model_lm_head_weight);  layer_norm_299 = None
        add_576: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_831, b_model_final_logits_bias);  linear_831 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_2125: "i64[1]" = torch.ops.aten.slice.Tensor(add_542, 0, -1, 9223372036854775807);  add_542 = None
        add_577: "i64[1]" = torch.ops.aten.add.Tensor(slice_2125, 1);  slice_2125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_2126: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_576, 0, 0, 9223372036854775807);  add_576 = None
        select_68: "f32[1, 59514]" = torch.ops.aten.select.int(slice_2126, 1, -1);  slice_2126 = None
        slice_2127: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_68, 1, 0, 9223372036854775807);  select_68 = None
        clone_31: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_2127);  slice_2127 = None
        to_301: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_31, torch.float32);  clone_31 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_302: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_301, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_301 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_15: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_302, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__15: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_15, to_32);  zeros_like_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_578: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_302, add__15);  to_302 = add__15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_15: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_578, -1);  add_578 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_15: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_15, -1);  log_softmax_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_249: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_15, and_15);  argmax_15 = None
        rsub_32: "i64[1]" = torch.ops.aten.rsub.Scalar(and_15, 1)
        mul_250: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_32);  rsub_32 = None
        add_579: "i64[1]" = torch.ops.aten.add.Tensor(mul_249, mul_250);  mul_249 = mul_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_2128: "i64[1]" = torch.ops.aten.slice.Tensor(add_579, 0, 0, 9223372036854775807);  add_579 = None
        unsqueeze_98: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_2128, 1);  slice_2128 = None
        cat_15: "i64[1, 17]" = torch.ops.aten.cat.default([cat_14, unsqueeze_98], -1);  cat_14 = unsqueeze_98 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_46: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_47: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_31: "b8[1]" = torch.ops.aten.__or__.Tensor(full_46, full_47);  full_46 = full_47 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_303: "i64[1]" = torch.ops.aten.to.dtype_layout(to_285, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_2129: "i64[1, 17]" = torch.ops.aten.slice.Tensor(cat_15, 0, 0, 9223372036854775807)
        select_69: "i64[1]" = torch.ops.aten.select.int(slice_2129, 1, -1);  slice_2129 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_17: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_69, to_303);  select_69 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_32: "b8[1]" = torch.ops.aten.__or__.Tensor(or_31, isin_17);  or_31 = isin_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_17: "b8[1]" = torch.ops.aten.bitwise_not.default(or_32);  or_32 = None
        and_16: "i64[1]" = torch.ops.aten.__and__.Tensor(and_15, bitwise_not_17);  and_15 = bitwise_not_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_16: "i64[]" = torch.ops.aten.max.default(and_16)
        eq_15: "b8[]" = torch.ops.aten.eq.Scalar(max_16, 0);  max_16 = eq_15 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_2130: "i64[1, 17]" = torch.ops.aten.slice.Tensor(cat_15, 0, 0, 9223372036854775807)
        slice_2131: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_2130, 1, -1, 9223372036854775807);  slice_2130 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_32: "i64[1, 1]" = torch.ops.aten.clone.default(slice_2131, memory_format = torch.contiguous_format);  slice_2131 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_431: "i64[1, 1]" = torch.ops.aten.view.default(clone_32, [-1, 1]);  clone_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_34: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_431, 59513);  view_431 = None
        mul_251: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_34, 22.627416997969522);  embedding_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_99: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_577, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_2132: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_100: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_2132, 1);  slice_2132 = None
        unsqueeze_101: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_100, 2);  unsqueeze_100 = None
        slice_2133: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_101, 3, 0, 9223372036854775807);  unsqueeze_101 = None
        expand_33: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_2133, [1, 1, 1, 23]);  slice_2133 = None
        to_304: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_33, torch.float32);  expand_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_33: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_304, 1.0);  to_304 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_305: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_33, torch.bool)
        masked_fill_17: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_33, to_305, -3.4028234663852886e+38);  rsub_33 = to_305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_35: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_99);  unsqueeze_99 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_306: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_35, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_35 = None
        add_580: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_251, to_306);  mul_251 = to_306 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_617: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_580, 0.1, False);  add_580 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_70: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_71: "f32[20, 64]" = torch.ops.aten.select.int(select_70, 0, 0);  select_70 = None
        any_21: "b8[20]" = torch.ops.aten.any.dim(select_71, -1);  select_71 = None
        sum_19: "i64[]" = torch.ops.aten.sum.default(any_21);  any_21 = sum_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_48: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_23: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_214: "i64[1, 1]" = torch.ops.aten.reshape.default(add_577, [-1, 1])
        gt_16: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_23, reshape_214);  arange_23 = reshape_214 = None
        mul__16: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_48, gt_16);  full_48 = gt_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_102: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__16, 0);  mul__16 = None
        unsqueeze_103: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_102, 1);  unsqueeze_102 = None
        slice_2134: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_103, 2, 0, 9223372036854775807);  unsqueeze_103 = None
        slice_2135: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2134, 3, 0, 9223372036854775807);  slice_2134 = None
        expand_34: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_2135, [1, 1, -1, -1]);  slice_2135 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_832: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_617, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_252: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_832, 0.125);  linear_832 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_432: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_252, [1, 1, 8, 64]);  mul_252 = None
        transpose_810: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_432, 1, 2);  view_432 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_833: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_617, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_433: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_833, [1, -1, 8, 64]);  linear_833 = None
        transpose_811: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_433, 1, 2);  view_433 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_834: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_617, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_434: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_834, [1, -1, 8, 64]);  linear_834 = None
        transpose_812: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_434, 1, 2);  view_434 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_307: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_811, torch.float32);  transpose_811 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_308: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_812, torch.float32);  transpose_812 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2136: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__204: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2136, 2, add_577, to_307);  slice_2136 = to_307 = index_copy__204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2137: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__205: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2137, 2, add_577, to_308);  slice_2137 = to_308 = index_copy__205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2138: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2139: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2138, 2, 0, 9223372036854775807);  slice_2138 = None
        slice_2140: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2139, 3, 0, 9223372036854775807);  slice_2139 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2141: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2142: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2141, 2, 0, 9223372036854775807);  slice_2141 = None
        slice_2143: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2142, 3, 0, 9223372036854775807);  slice_2142 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_813: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2140, 2, 3);  slice_2140 = None
        matmul_396: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_810, transpose_813);  transpose_810 = transpose_813 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2144: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_34, 0, 0, 9223372036854775807)
        slice_2145: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2144, 1, 0, 9223372036854775807);  slice_2144 = None
        slice_2146: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2145, 2, 0, 9223372036854775807);  slice_2145 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_581: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_396, slice_2146);  matmul_396 = slice_2146 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_198: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_581, -1);  add_581 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_618: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_198, 0.0, False);  softmax_198 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_397: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_618, slice_2143);  dropout_618 = slice_2143 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_814: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_397, 1, 2);  matmul_397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_215: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_814, [1, 1, 512]);  transpose_814 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_835: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_215, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_619: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_835, 0.1, False);  linear_835 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_582: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_617, dropout_619);  dropout_617 = dropout_619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_300: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_582, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_582 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_836: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_300, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_253: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_836, 0.125);  linear_836 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_435: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_253, [1, 1, 8, 64]);  mul_253 = None
        transpose_815: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_435, 1, 2);  view_435 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2147: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2148: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2147, 2, 0, 23);  slice_2147 = None
        slice_2149: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2148, 3, 0, 9223372036854775807);  slice_2148 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2150: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2151: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2150, 2, 0, 23);  slice_2150 = None
        slice_2152: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2151, 3, 0, 9223372036854775807);  slice_2151 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_816: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2149, 2, 3);  slice_2149 = None
        matmul_398: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_815, transpose_816);  transpose_815 = transpose_816 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2153: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_17, 0, 0, 9223372036854775807)
        slice_2154: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2153, 1, 0, 9223372036854775807);  slice_2153 = None
        slice_2155: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2154, 2, 0, 9223372036854775807);  slice_2154 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_583: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_398, slice_2155);  matmul_398 = slice_2155 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_199: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_583, -1);  add_583 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_620: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_199, 0.0, False);  softmax_199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_399: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_620, slice_2152);  dropout_620 = slice_2152 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_817: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_399, 1, 2);  matmul_399 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_216: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_817, [1, 1, 512]);  transpose_817 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_837: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_216, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_621: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_837, 0.1, False);  linear_837 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_584: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_300, dropout_621);  layer_norm_300 = dropout_621 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_301: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_584, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_584 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_838: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_301, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_102: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_838);  linear_838 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_622: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_102, 0.0, False);  silu_102 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_839: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_622, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_622 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_623: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_839, 0.1, False);  linear_839 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_585: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_301, dropout_623);  layer_norm_301 = dropout_623 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_302: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_585, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_585 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_840: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_302, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_254: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_840, 0.125);  linear_840 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_436: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_254, [1, 1, 8, 64]);  mul_254 = None
        transpose_818: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_436, 1, 2);  view_436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_841: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_302, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_437: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_841, [1, -1, 8, 64]);  linear_841 = None
        transpose_819: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_437, 1, 2);  view_437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_842: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_302, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_438: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_842, [1, -1, 8, 64]);  linear_842 = None
        transpose_820: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_438, 1, 2);  view_438 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_309: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_819, torch.float32);  transpose_819 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_310: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_820, torch.float32);  transpose_820 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2156: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__206: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2156, 2, add_577, to_309);  slice_2156 = to_309 = index_copy__206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2157: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__207: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2157, 2, add_577, to_310);  slice_2157 = to_310 = index_copy__207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2158: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2159: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2158, 2, 0, 9223372036854775807);  slice_2158 = None
        slice_2160: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2159, 3, 0, 9223372036854775807);  slice_2159 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2161: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2162: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2161, 2, 0, 9223372036854775807);  slice_2161 = None
        slice_2163: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2162, 3, 0, 9223372036854775807);  slice_2162 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_821: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2160, 2, 3);  slice_2160 = None
        matmul_400: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_818, transpose_821);  transpose_818 = transpose_821 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2164: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_34, 0, 0, 9223372036854775807)
        slice_2165: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2164, 1, 0, 9223372036854775807);  slice_2164 = None
        slice_2166: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2165, 2, 0, 9223372036854775807);  slice_2165 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_586: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_400, slice_2166);  matmul_400 = slice_2166 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_200: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_586, -1);  add_586 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_624: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_200, 0.0, False);  softmax_200 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_401: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_624, slice_2163);  dropout_624 = slice_2163 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_822: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_401, 1, 2);  matmul_401 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_217: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_822, [1, 1, 512]);  transpose_822 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_843: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_217, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_625: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_843, 0.1, False);  linear_843 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_587: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_302, dropout_625);  layer_norm_302 = dropout_625 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_303: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_587, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_587 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_844: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_303, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_255: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_844, 0.125);  linear_844 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_439: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_255, [1, 1, 8, 64]);  mul_255 = None
        transpose_823: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_439, 1, 2);  view_439 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2167: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2168: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2167, 2, 0, 23);  slice_2167 = None
        slice_2169: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2168, 3, 0, 9223372036854775807);  slice_2168 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2170: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2171: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2170, 2, 0, 23);  slice_2170 = None
        slice_2172: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2171, 3, 0, 9223372036854775807);  slice_2171 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_824: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2169, 2, 3);  slice_2169 = None
        matmul_402: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_823, transpose_824);  transpose_823 = transpose_824 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2173: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_17, 0, 0, 9223372036854775807)
        slice_2174: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2173, 1, 0, 9223372036854775807);  slice_2173 = None
        slice_2175: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2174, 2, 0, 9223372036854775807);  slice_2174 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_588: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_402, slice_2175);  matmul_402 = slice_2175 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_201: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_588, -1);  add_588 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_626: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_201, 0.0, False);  softmax_201 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_403: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_626, slice_2172);  dropout_626 = slice_2172 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_825: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_403, 1, 2);  matmul_403 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_218: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_825, [1, 1, 512]);  transpose_825 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_845: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_218, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_627: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_845, 0.1, False);  linear_845 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_589: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_303, dropout_627);  layer_norm_303 = dropout_627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_304: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_589, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_589 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_846: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_304, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_103: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_846);  linear_846 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_628: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_103, 0.0, False);  silu_103 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_847: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_628, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_628 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_629: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_847, 0.1, False);  linear_847 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_590: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_304, dropout_629);  layer_norm_304 = dropout_629 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_305: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_590, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_590 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_848: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_305, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_256: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_848, 0.125);  linear_848 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_440: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_256, [1, 1, 8, 64]);  mul_256 = None
        transpose_826: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_440, 1, 2);  view_440 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_849: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_305, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_441: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_849, [1, -1, 8, 64]);  linear_849 = None
        transpose_827: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_441, 1, 2);  view_441 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_850: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_305, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_442: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_850, [1, -1, 8, 64]);  linear_850 = None
        transpose_828: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_442, 1, 2);  view_442 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_311: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_827, torch.float32);  transpose_827 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_312: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_828, torch.float32);  transpose_828 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2176: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__208: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2176, 2, add_577, to_311);  slice_2176 = to_311 = index_copy__208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2177: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__209: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2177, 2, add_577, to_312);  slice_2177 = to_312 = index_copy__209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2178: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2179: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2178, 2, 0, 9223372036854775807);  slice_2178 = None
        slice_2180: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2179, 3, 0, 9223372036854775807);  slice_2179 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2181: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2182: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2181, 2, 0, 9223372036854775807);  slice_2181 = None
        slice_2183: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2182, 3, 0, 9223372036854775807);  slice_2182 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_829: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2180, 2, 3);  slice_2180 = None
        matmul_404: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_826, transpose_829);  transpose_826 = transpose_829 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2184: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_34, 0, 0, 9223372036854775807)
        slice_2185: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2184, 1, 0, 9223372036854775807);  slice_2184 = None
        slice_2186: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2185, 2, 0, 9223372036854775807);  slice_2185 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_591: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_404, slice_2186);  matmul_404 = slice_2186 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_202: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_591, -1);  add_591 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_630: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_202, 0.0, False);  softmax_202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_405: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_630, slice_2183);  dropout_630 = slice_2183 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_830: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_405, 1, 2);  matmul_405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_219: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_830, [1, 1, 512]);  transpose_830 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_851: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_219, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_631: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_851, 0.1, False);  linear_851 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_592: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_305, dropout_631);  layer_norm_305 = dropout_631 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_306: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_592, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_592 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_852: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_306, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_257: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_852, 0.125);  linear_852 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_443: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_257, [1, 1, 8, 64]);  mul_257 = None
        transpose_831: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_443, 1, 2);  view_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2187: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2188: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2187, 2, 0, 23);  slice_2187 = None
        slice_2189: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2188, 3, 0, 9223372036854775807);  slice_2188 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2190: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2191: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2190, 2, 0, 23);  slice_2190 = None
        slice_2192: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2191, 3, 0, 9223372036854775807);  slice_2191 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_832: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2189, 2, 3);  slice_2189 = None
        matmul_406: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_831, transpose_832);  transpose_831 = transpose_832 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2193: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_17, 0, 0, 9223372036854775807)
        slice_2194: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2193, 1, 0, 9223372036854775807);  slice_2193 = None
        slice_2195: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2194, 2, 0, 9223372036854775807);  slice_2194 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_593: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_406, slice_2195);  matmul_406 = slice_2195 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_203: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_593, -1);  add_593 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_632: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_203, 0.0, False);  softmax_203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_407: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_632, slice_2192);  dropout_632 = slice_2192 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_833: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_407, 1, 2);  matmul_407 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_220: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_833, [1, 1, 512]);  transpose_833 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_853: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_220, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_633: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_853, 0.1, False);  linear_853 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_594: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_306, dropout_633);  layer_norm_306 = dropout_633 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_307: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_594, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_594 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_854: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_307, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_104: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_854);  linear_854 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_634: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_104, 0.0, False);  silu_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_855: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_634, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_634 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_635: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_855, 0.1, False);  linear_855 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_595: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_307, dropout_635);  layer_norm_307 = dropout_635 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_308: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_595, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_595 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_856: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_308, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_258: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_856, 0.125);  linear_856 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_444: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_258, [1, 1, 8, 64]);  mul_258 = None
        transpose_834: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_444, 1, 2);  view_444 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_857: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_308, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_445: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_857, [1, -1, 8, 64]);  linear_857 = None
        transpose_835: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_445, 1, 2);  view_445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_858: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_308, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_446: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_858, [1, -1, 8, 64]);  linear_858 = None
        transpose_836: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_446, 1, 2);  view_446 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_313: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_835, torch.float32);  transpose_835 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_314: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_836, torch.float32);  transpose_836 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2196: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__210: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2196, 2, add_577, to_313);  slice_2196 = to_313 = index_copy__210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2197: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__211: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2197, 2, add_577, to_314);  slice_2197 = to_314 = index_copy__211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2198: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2199: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2198, 2, 0, 9223372036854775807);  slice_2198 = None
        slice_2200: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2199, 3, 0, 9223372036854775807);  slice_2199 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2201: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2202: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2201, 2, 0, 9223372036854775807);  slice_2201 = None
        slice_2203: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2202, 3, 0, 9223372036854775807);  slice_2202 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_837: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2200, 2, 3);  slice_2200 = None
        matmul_408: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_834, transpose_837);  transpose_834 = transpose_837 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2204: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_34, 0, 0, 9223372036854775807)
        slice_2205: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2204, 1, 0, 9223372036854775807);  slice_2204 = None
        slice_2206: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2205, 2, 0, 9223372036854775807);  slice_2205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_596: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_408, slice_2206);  matmul_408 = slice_2206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_204: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_596, -1);  add_596 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_636: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_204, 0.0, False);  softmax_204 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_409: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_636, slice_2203);  dropout_636 = slice_2203 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_838: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_409, 1, 2);  matmul_409 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_221: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_838, [1, 1, 512]);  transpose_838 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_859: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_221, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_637: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_859, 0.1, False);  linear_859 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_597: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_308, dropout_637);  layer_norm_308 = dropout_637 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_309: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_597, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_597 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_860: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_309, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_259: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_860, 0.125);  linear_860 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_447: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_259, [1, 1, 8, 64]);  mul_259 = None
        transpose_839: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_447, 1, 2);  view_447 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2207: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2208: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2207, 2, 0, 23);  slice_2207 = None
        slice_2209: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2208, 3, 0, 9223372036854775807);  slice_2208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2210: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2211: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2210, 2, 0, 23);  slice_2210 = None
        slice_2212: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2211, 3, 0, 9223372036854775807);  slice_2211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_840: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2209, 2, 3);  slice_2209 = None
        matmul_410: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_839, transpose_840);  transpose_839 = transpose_840 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2213: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_17, 0, 0, 9223372036854775807)
        slice_2214: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2213, 1, 0, 9223372036854775807);  slice_2213 = None
        slice_2215: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2214, 2, 0, 9223372036854775807);  slice_2214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_598: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_410, slice_2215);  matmul_410 = slice_2215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_205: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_598, -1);  add_598 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_638: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_205, 0.0, False);  softmax_205 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_411: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_638, slice_2212);  dropout_638 = slice_2212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_841: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_411, 1, 2);  matmul_411 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_222: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_841, [1, 1, 512]);  transpose_841 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_861: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_222, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_639: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_861, 0.1, False);  linear_861 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_599: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_309, dropout_639);  layer_norm_309 = dropout_639 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_310: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_599, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_599 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_862: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_310, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_105: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_862);  linear_862 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_640: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_105, 0.0, False);  silu_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_863: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_640, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_640 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_641: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_863, 0.1, False);  linear_863 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_600: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_310, dropout_641);  layer_norm_310 = dropout_641 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_311: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_600, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_600 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_864: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_311, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_260: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_864, 0.125);  linear_864 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_448: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_260, [1, 1, 8, 64]);  mul_260 = None
        transpose_842: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_448, 1, 2);  view_448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_865: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_311, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_449: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_865, [1, -1, 8, 64]);  linear_865 = None
        transpose_843: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_449, 1, 2);  view_449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_866: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_311, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_450: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_866, [1, -1, 8, 64]);  linear_866 = None
        transpose_844: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_450, 1, 2);  view_450 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_315: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_843, torch.float32);  transpose_843 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_316: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_844, torch.float32);  transpose_844 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2216: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__212: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2216, 2, add_577, to_315);  slice_2216 = to_315 = index_copy__212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2217: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__213: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2217, 2, add_577, to_316);  slice_2217 = to_316 = index_copy__213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2218: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2219: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2218, 2, 0, 9223372036854775807);  slice_2218 = None
        slice_2220: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2219, 3, 0, 9223372036854775807);  slice_2219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2221: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2222: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2221, 2, 0, 9223372036854775807);  slice_2221 = None
        slice_2223: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2222, 3, 0, 9223372036854775807);  slice_2222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_845: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2220, 2, 3);  slice_2220 = None
        matmul_412: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_842, transpose_845);  transpose_842 = transpose_845 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2224: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_34, 0, 0, 9223372036854775807)
        slice_2225: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2224, 1, 0, 9223372036854775807);  slice_2224 = None
        slice_2226: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2225, 2, 0, 9223372036854775807);  slice_2225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_601: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_412, slice_2226);  matmul_412 = slice_2226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_206: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_601, -1);  add_601 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_642: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_206, 0.0, False);  softmax_206 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_413: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_642, slice_2223);  dropout_642 = slice_2223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_846: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_413, 1, 2);  matmul_413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_223: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_846, [1, 1, 512]);  transpose_846 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_867: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_223, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_643: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_867, 0.1, False);  linear_867 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_602: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_311, dropout_643);  layer_norm_311 = dropout_643 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_312: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_602, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_602 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_868: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_312, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_261: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_868, 0.125);  linear_868 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_451: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_261, [1, 1, 8, 64]);  mul_261 = None
        transpose_847: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_451, 1, 2);  view_451 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2227: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2228: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2227, 2, 0, 23);  slice_2227 = None
        slice_2229: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2228, 3, 0, 9223372036854775807);  slice_2228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2230: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2231: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2230, 2, 0, 23);  slice_2230 = None
        slice_2232: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2231, 3, 0, 9223372036854775807);  slice_2231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_848: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2229, 2, 3);  slice_2229 = None
        matmul_414: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_847, transpose_848);  transpose_847 = transpose_848 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2233: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_17, 0, 0, 9223372036854775807)
        slice_2234: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2233, 1, 0, 9223372036854775807);  slice_2233 = None
        slice_2235: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2234, 2, 0, 9223372036854775807);  slice_2234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_603: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_414, slice_2235);  matmul_414 = slice_2235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_207: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_603, -1);  add_603 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_644: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_207, 0.0, False);  softmax_207 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_415: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_644, slice_2232);  dropout_644 = slice_2232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_849: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_415, 1, 2);  matmul_415 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_224: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_849, [1, 1, 512]);  transpose_849 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_869: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_224, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_645: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_869, 0.1, False);  linear_869 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_604: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_312, dropout_645);  layer_norm_312 = dropout_645 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_313: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_604, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_604 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_870: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_313, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_106: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_870);  linear_870 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_646: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_106, 0.0, False);  silu_106 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_871: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_646, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_646 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_647: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_871, 0.1, False);  linear_871 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_605: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_313, dropout_647);  layer_norm_313 = dropout_647 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_314: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_605, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_605 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_872: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_314, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_262: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_872, 0.125);  linear_872 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_452: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_262, [1, 1, 8, 64]);  mul_262 = None
        transpose_850: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_452, 1, 2);  view_452 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_873: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_314, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_453: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_873, [1, -1, 8, 64]);  linear_873 = None
        transpose_851: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_453, 1, 2);  view_453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_874: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_314, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_454: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_874, [1, -1, 8, 64]);  linear_874 = None
        transpose_852: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_454, 1, 2);  view_454 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_317: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_851, torch.float32);  transpose_851 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_318: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_852, torch.float32);  transpose_852 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2236: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__214: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2236, 2, add_577, to_317);  slice_2236 = to_317 = index_copy__214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2237: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__215: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2237, 2, add_577, to_318);  slice_2237 = to_318 = index_copy__215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2238: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2239: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2238, 2, 0, 9223372036854775807);  slice_2238 = None
        slice_2240: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2239, 3, 0, 9223372036854775807);  slice_2239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2241: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2242: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2241, 2, 0, 9223372036854775807);  slice_2241 = None
        slice_2243: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2242, 3, 0, 9223372036854775807);  slice_2242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_853: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2240, 2, 3);  slice_2240 = None
        matmul_416: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_850, transpose_853);  transpose_850 = transpose_853 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2244: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_34, 0, 0, 9223372036854775807);  expand_34 = None
        slice_2245: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2244, 1, 0, 9223372036854775807);  slice_2244 = None
        slice_2246: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2245, 2, 0, 9223372036854775807);  slice_2245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_606: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_416, slice_2246);  matmul_416 = slice_2246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_208: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_606, -1);  add_606 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_648: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_208, 0.0, False);  softmax_208 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_417: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_648, slice_2243);  dropout_648 = slice_2243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_854: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_417, 1, 2);  matmul_417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_225: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_854, [1, 1, 512]);  transpose_854 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_875: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_225, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_649: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_875, 0.1, False);  linear_875 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_607: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_314, dropout_649);  layer_norm_314 = dropout_649 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_315: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_607, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_607 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_876: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_315, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_263: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_876, 0.125);  linear_876 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_455: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_263, [1, 1, 8, 64]);  mul_263 = None
        transpose_855: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_455, 1, 2);  view_455 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2247: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2248: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2247, 2, 0, 23);  slice_2247 = None
        slice_2249: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2248, 3, 0, 9223372036854775807);  slice_2248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2250: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2251: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2250, 2, 0, 23);  slice_2250 = None
        slice_2252: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2251, 3, 0, 9223372036854775807);  slice_2251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_856: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2249, 2, 3);  slice_2249 = None
        matmul_418: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_855, transpose_856);  transpose_855 = transpose_856 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2253: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_17, 0, 0, 9223372036854775807);  masked_fill_17 = None
        slice_2254: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2253, 1, 0, 9223372036854775807);  slice_2253 = None
        slice_2255: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2254, 2, 0, 9223372036854775807);  slice_2254 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_608: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_418, slice_2255);  matmul_418 = slice_2255 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_209: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_608, -1);  add_608 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_650: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_209, 0.0, False);  softmax_209 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_419: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_650, slice_2252);  dropout_650 = slice_2252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_857: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_419, 1, 2);  matmul_419 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_226: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_857, [1, 1, 512]);  transpose_857 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_877: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_226, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_651: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_877, 0.1, False);  linear_877 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_609: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_315, dropout_651);  layer_norm_315 = dropout_651 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_316: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_609, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_609 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_878: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_316, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_107: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_878);  linear_878 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_652: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_107, 0.0, False);  silu_107 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_879: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_652, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_652 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_653: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_879, 0.1, False);  linear_879 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_610: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_316, dropout_653);  layer_norm_316 = dropout_653 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_317: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_610, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_610 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_880: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_317, p_model_lm_head_weight);  layer_norm_317 = None
        add_611: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_880, b_model_final_logits_bias);  linear_880 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_2256: "i64[1]" = torch.ops.aten.slice.Tensor(add_577, 0, -1, 9223372036854775807);  add_577 = None
        add_612: "i64[1]" = torch.ops.aten.add.Tensor(slice_2256, 1);  slice_2256 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_2257: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_611, 0, 0, 9223372036854775807);  add_611 = None
        select_72: "f32[1, 59514]" = torch.ops.aten.select.int(slice_2257, 1, -1);  slice_2257 = None
        slice_2258: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_72, 1, 0, 9223372036854775807);  select_72 = None
        clone_33: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_2258);  slice_2258 = None
        to_319: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_33, torch.float32);  clone_33 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_320: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_319, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_319 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_16: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_320, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__16: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_16, to_32);  zeros_like_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_613: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_320, add__16);  to_320 = add__16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_16: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_613, -1);  add_613 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_16: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_16, -1);  log_softmax_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_264: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_16, and_16);  argmax_16 = None
        rsub_34: "i64[1]" = torch.ops.aten.rsub.Scalar(and_16, 1)
        mul_265: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_34);  rsub_34 = None
        add_614: "i64[1]" = torch.ops.aten.add.Tensor(mul_264, mul_265);  mul_264 = mul_265 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_2259: "i64[1]" = torch.ops.aten.slice.Tensor(add_614, 0, 0, 9223372036854775807);  add_614 = None
        unsqueeze_104: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_2259, 1);  slice_2259 = None
        cat_16: "i64[1, 18]" = torch.ops.aten.cat.default([cat_15, unsqueeze_104], -1);  cat_15 = unsqueeze_104 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_49: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_50: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_33: "b8[1]" = torch.ops.aten.__or__.Tensor(full_49, full_50);  full_49 = full_50 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_321: "i64[1]" = torch.ops.aten.to.dtype_layout(to_303, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_303 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_2260: "i64[1, 18]" = torch.ops.aten.slice.Tensor(cat_16, 0, 0, 9223372036854775807)
        select_73: "i64[1]" = torch.ops.aten.select.int(slice_2260, 1, -1);  slice_2260 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_18: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_73, to_321);  select_73 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_34: "b8[1]" = torch.ops.aten.__or__.Tensor(or_33, isin_18);  or_33 = isin_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_18: "b8[1]" = torch.ops.aten.bitwise_not.default(or_34);  or_34 = None
        and_17: "i64[1]" = torch.ops.aten.__and__.Tensor(and_16, bitwise_not_18);  and_16 = bitwise_not_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_17: "i64[]" = torch.ops.aten.max.default(and_17)
        eq_16: "b8[]" = torch.ops.aten.eq.Scalar(max_17, 0);  max_17 = eq_16 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_2261: "i64[1, 18]" = torch.ops.aten.slice.Tensor(cat_16, 0, 0, 9223372036854775807)
        slice_2262: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_2261, 1, -1, 9223372036854775807);  slice_2261 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_34: "i64[1, 1]" = torch.ops.aten.clone.default(slice_2262, memory_format = torch.contiguous_format);  slice_2262 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_456: "i64[1, 1]" = torch.ops.aten.view.default(clone_34, [-1, 1]);  clone_34 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_36: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_456, 59513);  view_456 = None
        mul_266: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_36, 22.627416997969522);  embedding_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_105: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_612, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_2263: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_106: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_2263, 1);  slice_2263 = None
        unsqueeze_107: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_106, 2);  unsqueeze_106 = None
        slice_2264: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_107, 3, 0, 9223372036854775807);  unsqueeze_107 = None
        expand_35: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_2264, [1, 1, 1, 23]);  slice_2264 = None
        to_322: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_35, torch.float32);  expand_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_35: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_322, 1.0);  to_322 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_323: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_35, torch.bool)
        masked_fill_18: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_35, to_323, -3.4028234663852886e+38);  rsub_35 = to_323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_37: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_105);  unsqueeze_105 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_324: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_37, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_37 = None
        add_615: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_266, to_324);  mul_266 = to_324 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_654: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_615, 0.1, False);  add_615 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_74: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_75: "f32[20, 64]" = torch.ops.aten.select.int(select_74, 0, 0);  select_74 = None
        any_22: "b8[20]" = torch.ops.aten.any.dim(select_75, -1);  select_75 = None
        sum_20: "i64[]" = torch.ops.aten.sum.default(any_22);  any_22 = sum_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_51: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_24: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_227: "i64[1, 1]" = torch.ops.aten.reshape.default(add_612, [-1, 1])
        gt_17: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_24, reshape_227);  arange_24 = reshape_227 = None
        mul__17: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_51, gt_17);  full_51 = gt_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_108: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__17, 0);  mul__17 = None
        unsqueeze_109: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_108, 1);  unsqueeze_108 = None
        slice_2265: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_109, 2, 0, 9223372036854775807);  unsqueeze_109 = None
        slice_2266: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2265, 3, 0, 9223372036854775807);  slice_2265 = None
        expand_36: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_2266, [1, 1, -1, -1]);  slice_2266 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_881: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_654, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_267: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_881, 0.125);  linear_881 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_457: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_267, [1, 1, 8, 64]);  mul_267 = None
        transpose_858: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_457, 1, 2);  view_457 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_882: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_654, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_458: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_882, [1, -1, 8, 64]);  linear_882 = None
        transpose_859: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_458, 1, 2);  view_458 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_883: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_654, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_459: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_883, [1, -1, 8, 64]);  linear_883 = None
        transpose_860: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_459, 1, 2);  view_459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_325: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_859, torch.float32);  transpose_859 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_326: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_860, torch.float32);  transpose_860 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2267: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__216: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2267, 2, add_612, to_325);  slice_2267 = to_325 = index_copy__216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2268: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__217: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2268, 2, add_612, to_326);  slice_2268 = to_326 = index_copy__217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2269: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2270: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2269, 2, 0, 9223372036854775807);  slice_2269 = None
        slice_2271: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2270, 3, 0, 9223372036854775807);  slice_2270 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2272: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2273: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2272, 2, 0, 9223372036854775807);  slice_2272 = None
        slice_2274: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2273, 3, 0, 9223372036854775807);  slice_2273 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_861: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2271, 2, 3);  slice_2271 = None
        matmul_420: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_858, transpose_861);  transpose_858 = transpose_861 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2275: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_36, 0, 0, 9223372036854775807)
        slice_2276: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2275, 1, 0, 9223372036854775807);  slice_2275 = None
        slice_2277: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2276, 2, 0, 9223372036854775807);  slice_2276 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_616: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_420, slice_2277);  matmul_420 = slice_2277 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_210: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_616, -1);  add_616 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_655: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_210, 0.0, False);  softmax_210 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_421: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_655, slice_2274);  dropout_655 = slice_2274 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_862: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_421, 1, 2);  matmul_421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_228: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_862, [1, 1, 512]);  transpose_862 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_884: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_228, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_656: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_884, 0.1, False);  linear_884 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_617: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_654, dropout_656);  dropout_654 = dropout_656 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_318: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_617, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_617 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_885: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_318, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_268: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_885, 0.125);  linear_885 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_460: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_268, [1, 1, 8, 64]);  mul_268 = None
        transpose_863: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_460, 1, 2);  view_460 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2278: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2279: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2278, 2, 0, 23);  slice_2278 = None
        slice_2280: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2279, 3, 0, 9223372036854775807);  slice_2279 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2281: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2282: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2281, 2, 0, 23);  slice_2281 = None
        slice_2283: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2282, 3, 0, 9223372036854775807);  slice_2282 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_864: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2280, 2, 3);  slice_2280 = None
        matmul_422: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_863, transpose_864);  transpose_863 = transpose_864 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2284: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_18, 0, 0, 9223372036854775807)
        slice_2285: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2284, 1, 0, 9223372036854775807);  slice_2284 = None
        slice_2286: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2285, 2, 0, 9223372036854775807);  slice_2285 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_618: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_422, slice_2286);  matmul_422 = slice_2286 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_211: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_618, -1);  add_618 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_657: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_211, 0.0, False);  softmax_211 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_423: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_657, slice_2283);  dropout_657 = slice_2283 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_865: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_423, 1, 2);  matmul_423 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_229: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_865, [1, 1, 512]);  transpose_865 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_886: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_229, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_658: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_886, 0.1, False);  linear_886 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_619: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_318, dropout_658);  layer_norm_318 = dropout_658 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_319: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_619, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_887: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_319, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_108: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_887);  linear_887 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_659: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_108, 0.0, False);  silu_108 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_888: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_659, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_659 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_660: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_888, 0.1, False);  linear_888 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_620: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_319, dropout_660);  layer_norm_319 = dropout_660 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_320: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_620, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_620 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_889: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_320, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_269: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_889, 0.125);  linear_889 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_461: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_269, [1, 1, 8, 64]);  mul_269 = None
        transpose_866: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_461, 1, 2);  view_461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_890: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_320, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_462: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_890, [1, -1, 8, 64]);  linear_890 = None
        transpose_867: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_462, 1, 2);  view_462 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_891: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_320, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_463: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_891, [1, -1, 8, 64]);  linear_891 = None
        transpose_868: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_463, 1, 2);  view_463 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_327: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_867, torch.float32);  transpose_867 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_328: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_868, torch.float32);  transpose_868 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2287: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__218: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2287, 2, add_612, to_327);  slice_2287 = to_327 = index_copy__218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2288: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__219: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2288, 2, add_612, to_328);  slice_2288 = to_328 = index_copy__219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2289: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2290: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2289, 2, 0, 9223372036854775807);  slice_2289 = None
        slice_2291: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2290, 3, 0, 9223372036854775807);  slice_2290 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2292: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2293: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2292, 2, 0, 9223372036854775807);  slice_2292 = None
        slice_2294: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2293, 3, 0, 9223372036854775807);  slice_2293 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_869: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2291, 2, 3);  slice_2291 = None
        matmul_424: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_866, transpose_869);  transpose_866 = transpose_869 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2295: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_36, 0, 0, 9223372036854775807)
        slice_2296: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2295, 1, 0, 9223372036854775807);  slice_2295 = None
        slice_2297: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2296, 2, 0, 9223372036854775807);  slice_2296 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_621: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_424, slice_2297);  matmul_424 = slice_2297 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_212: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_621, -1);  add_621 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_661: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_212, 0.0, False);  softmax_212 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_425: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_661, slice_2294);  dropout_661 = slice_2294 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_870: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_425, 1, 2);  matmul_425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_230: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_870, [1, 1, 512]);  transpose_870 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_892: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_230, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_662: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_892, 0.1, False);  linear_892 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_622: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_320, dropout_662);  layer_norm_320 = dropout_662 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_321: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_622, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_622 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_893: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_321, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_270: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_893, 0.125);  linear_893 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_464: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_270, [1, 1, 8, 64]);  mul_270 = None
        transpose_871: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_464, 1, 2);  view_464 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2298: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2299: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2298, 2, 0, 23);  slice_2298 = None
        slice_2300: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2299, 3, 0, 9223372036854775807);  slice_2299 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2301: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2302: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2301, 2, 0, 23);  slice_2301 = None
        slice_2303: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2302, 3, 0, 9223372036854775807);  slice_2302 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_872: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2300, 2, 3);  slice_2300 = None
        matmul_426: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_871, transpose_872);  transpose_871 = transpose_872 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2304: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_18, 0, 0, 9223372036854775807)
        slice_2305: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2304, 1, 0, 9223372036854775807);  slice_2304 = None
        slice_2306: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2305, 2, 0, 9223372036854775807);  slice_2305 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_623: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_426, slice_2306);  matmul_426 = slice_2306 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_213: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_623, -1);  add_623 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_663: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_213, 0.0, False);  softmax_213 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_427: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_663, slice_2303);  dropout_663 = slice_2303 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_873: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_427, 1, 2);  matmul_427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_231: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_873, [1, 1, 512]);  transpose_873 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_894: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_231, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_664: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_894, 0.1, False);  linear_894 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_624: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_321, dropout_664);  layer_norm_321 = dropout_664 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_322: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_624, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_624 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_895: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_322, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_109: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_895);  linear_895 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_665: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_109, 0.0, False);  silu_109 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_896: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_665, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_665 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_666: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_896, 0.1, False);  linear_896 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_625: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_322, dropout_666);  layer_norm_322 = dropout_666 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_323: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_625, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_625 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_897: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_323, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_271: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_897, 0.125);  linear_897 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_465: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_271, [1, 1, 8, 64]);  mul_271 = None
        transpose_874: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_465, 1, 2);  view_465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_898: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_323, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_466: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_898, [1, -1, 8, 64]);  linear_898 = None
        transpose_875: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_466, 1, 2);  view_466 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_899: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_323, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_467: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_899, [1, -1, 8, 64]);  linear_899 = None
        transpose_876: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_467, 1, 2);  view_467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_329: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_875, torch.float32);  transpose_875 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_330: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_876, torch.float32);  transpose_876 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2307: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__220: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2307, 2, add_612, to_329);  slice_2307 = to_329 = index_copy__220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2308: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__221: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2308, 2, add_612, to_330);  slice_2308 = to_330 = index_copy__221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2309: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2310: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2309, 2, 0, 9223372036854775807);  slice_2309 = None
        slice_2311: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2310, 3, 0, 9223372036854775807);  slice_2310 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2312: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2313: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2312, 2, 0, 9223372036854775807);  slice_2312 = None
        slice_2314: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2313, 3, 0, 9223372036854775807);  slice_2313 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_877: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2311, 2, 3);  slice_2311 = None
        matmul_428: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_874, transpose_877);  transpose_874 = transpose_877 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2315: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_36, 0, 0, 9223372036854775807)
        slice_2316: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2315, 1, 0, 9223372036854775807);  slice_2315 = None
        slice_2317: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2316, 2, 0, 9223372036854775807);  slice_2316 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_626: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_428, slice_2317);  matmul_428 = slice_2317 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_214: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_626, -1);  add_626 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_667: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_214, 0.0, False);  softmax_214 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_429: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_667, slice_2314);  dropout_667 = slice_2314 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_878: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_429, 1, 2);  matmul_429 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_232: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_878, [1, 1, 512]);  transpose_878 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_900: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_232, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_668: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_900, 0.1, False);  linear_900 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_627: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_323, dropout_668);  layer_norm_323 = dropout_668 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_324: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_627, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_901: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_324, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_272: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_901, 0.125);  linear_901 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_468: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_272, [1, 1, 8, 64]);  mul_272 = None
        transpose_879: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_468, 1, 2);  view_468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2318: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2319: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2318, 2, 0, 23);  slice_2318 = None
        slice_2320: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2319, 3, 0, 9223372036854775807);  slice_2319 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2321: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2322: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2321, 2, 0, 23);  slice_2321 = None
        slice_2323: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2322, 3, 0, 9223372036854775807);  slice_2322 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_880: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2320, 2, 3);  slice_2320 = None
        matmul_430: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_879, transpose_880);  transpose_879 = transpose_880 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2324: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_18, 0, 0, 9223372036854775807)
        slice_2325: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2324, 1, 0, 9223372036854775807);  slice_2324 = None
        slice_2326: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2325, 2, 0, 9223372036854775807);  slice_2325 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_628: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_430, slice_2326);  matmul_430 = slice_2326 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_215: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_628, -1);  add_628 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_669: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_215, 0.0, False);  softmax_215 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_431: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_669, slice_2323);  dropout_669 = slice_2323 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_881: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_431, 1, 2);  matmul_431 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_233: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_881, [1, 1, 512]);  transpose_881 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_902: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_233, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_670: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_902, 0.1, False);  linear_902 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_629: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_324, dropout_670);  layer_norm_324 = dropout_670 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_325: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_629, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_629 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_903: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_325, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_110: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_903);  linear_903 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_671: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_110, 0.0, False);  silu_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_904: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_671, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_671 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_672: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_904, 0.1, False);  linear_904 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_630: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_325, dropout_672);  layer_norm_325 = dropout_672 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_326: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_630, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_630 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_905: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_326, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_273: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_905, 0.125);  linear_905 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_469: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_273, [1, 1, 8, 64]);  mul_273 = None
        transpose_882: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_469, 1, 2);  view_469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_906: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_326, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_470: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_906, [1, -1, 8, 64]);  linear_906 = None
        transpose_883: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_470, 1, 2);  view_470 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_907: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_326, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_471: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_907, [1, -1, 8, 64]);  linear_907 = None
        transpose_884: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_471, 1, 2);  view_471 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_331: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_883, torch.float32);  transpose_883 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_332: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_884, torch.float32);  transpose_884 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2327: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__222: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2327, 2, add_612, to_331);  slice_2327 = to_331 = index_copy__222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2328: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__223: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2328, 2, add_612, to_332);  slice_2328 = to_332 = index_copy__223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2329: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2330: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2329, 2, 0, 9223372036854775807);  slice_2329 = None
        slice_2331: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2330, 3, 0, 9223372036854775807);  slice_2330 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2332: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2333: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2332, 2, 0, 9223372036854775807);  slice_2332 = None
        slice_2334: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2333, 3, 0, 9223372036854775807);  slice_2333 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_885: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2331, 2, 3);  slice_2331 = None
        matmul_432: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_882, transpose_885);  transpose_882 = transpose_885 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2335: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_36, 0, 0, 9223372036854775807)
        slice_2336: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2335, 1, 0, 9223372036854775807);  slice_2335 = None
        slice_2337: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2336, 2, 0, 9223372036854775807);  slice_2336 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_631: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_432, slice_2337);  matmul_432 = slice_2337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_216: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_631, -1);  add_631 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_673: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_216, 0.0, False);  softmax_216 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_433: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_673, slice_2334);  dropout_673 = slice_2334 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_886: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_433, 1, 2);  matmul_433 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_234: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_886, [1, 1, 512]);  transpose_886 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_908: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_234, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_674: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_908, 0.1, False);  linear_908 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_632: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_326, dropout_674);  layer_norm_326 = dropout_674 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_327: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_632, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_632 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_909: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_327, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_274: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_909, 0.125);  linear_909 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_472: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_274, [1, 1, 8, 64]);  mul_274 = None
        transpose_887: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_472, 1, 2);  view_472 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2338: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2339: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2338, 2, 0, 23);  slice_2338 = None
        slice_2340: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2339, 3, 0, 9223372036854775807);  slice_2339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2341: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2342: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2341, 2, 0, 23);  slice_2341 = None
        slice_2343: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2342, 3, 0, 9223372036854775807);  slice_2342 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_888: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2340, 2, 3);  slice_2340 = None
        matmul_434: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_887, transpose_888);  transpose_887 = transpose_888 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2344: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_18, 0, 0, 9223372036854775807)
        slice_2345: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2344, 1, 0, 9223372036854775807);  slice_2344 = None
        slice_2346: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2345, 2, 0, 9223372036854775807);  slice_2345 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_633: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_434, slice_2346);  matmul_434 = slice_2346 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_217: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_633, -1);  add_633 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_675: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_217, 0.0, False);  softmax_217 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_435: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_675, slice_2343);  dropout_675 = slice_2343 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_889: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_435, 1, 2);  matmul_435 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_235: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_889, [1, 1, 512]);  transpose_889 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_910: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_235, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_676: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_910, 0.1, False);  linear_910 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_634: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_327, dropout_676);  layer_norm_327 = dropout_676 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_328: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_634, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_634 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_911: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_328, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_111: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_911);  linear_911 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_677: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_111, 0.0, False);  silu_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_912: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_677, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_677 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_678: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_912, 0.1, False);  linear_912 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_635: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_328, dropout_678);  layer_norm_328 = dropout_678 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_329: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_635, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_635 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_913: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_329, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_275: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_913, 0.125);  linear_913 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_473: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_275, [1, 1, 8, 64]);  mul_275 = None
        transpose_890: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_473, 1, 2);  view_473 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_914: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_329, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_474: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_914, [1, -1, 8, 64]);  linear_914 = None
        transpose_891: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_474, 1, 2);  view_474 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_915: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_329, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_475: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_915, [1, -1, 8, 64]);  linear_915 = None
        transpose_892: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_475, 1, 2);  view_475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_333: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_891, torch.float32);  transpose_891 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_334: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_892, torch.float32);  transpose_892 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2347: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__224: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2347, 2, add_612, to_333);  slice_2347 = to_333 = index_copy__224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2348: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__225: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2348, 2, add_612, to_334);  slice_2348 = to_334 = index_copy__225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2349: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2350: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2349, 2, 0, 9223372036854775807);  slice_2349 = None
        slice_2351: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2350, 3, 0, 9223372036854775807);  slice_2350 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2352: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2353: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2352, 2, 0, 9223372036854775807);  slice_2352 = None
        slice_2354: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2353, 3, 0, 9223372036854775807);  slice_2353 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_893: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2351, 2, 3);  slice_2351 = None
        matmul_436: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_890, transpose_893);  transpose_890 = transpose_893 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2355: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_36, 0, 0, 9223372036854775807)
        slice_2356: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2355, 1, 0, 9223372036854775807);  slice_2355 = None
        slice_2357: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2356, 2, 0, 9223372036854775807);  slice_2356 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_636: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_436, slice_2357);  matmul_436 = slice_2357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_218: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_636, -1);  add_636 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_679: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_218, 0.0, False);  softmax_218 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_437: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_679, slice_2354);  dropout_679 = slice_2354 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_894: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_437, 1, 2);  matmul_437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_236: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_894, [1, 1, 512]);  transpose_894 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_916: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_236, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_680: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_916, 0.1, False);  linear_916 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_637: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_329, dropout_680);  layer_norm_329 = dropout_680 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_330: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_637, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_637 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_917: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_330, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_276: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_917, 0.125);  linear_917 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_476: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_276, [1, 1, 8, 64]);  mul_276 = None
        transpose_895: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_476, 1, 2);  view_476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2358: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2359: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2358, 2, 0, 23);  slice_2358 = None
        slice_2360: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2359, 3, 0, 9223372036854775807);  slice_2359 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2361: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2362: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2361, 2, 0, 23);  slice_2361 = None
        slice_2363: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2362, 3, 0, 9223372036854775807);  slice_2362 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_896: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2360, 2, 3);  slice_2360 = None
        matmul_438: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_895, transpose_896);  transpose_895 = transpose_896 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2364: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_18, 0, 0, 9223372036854775807)
        slice_2365: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2364, 1, 0, 9223372036854775807);  slice_2364 = None
        slice_2366: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2365, 2, 0, 9223372036854775807);  slice_2365 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_638: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_438, slice_2366);  matmul_438 = slice_2366 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_219: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_638, -1);  add_638 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_681: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_219, 0.0, False);  softmax_219 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_439: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_681, slice_2363);  dropout_681 = slice_2363 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_897: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_439, 1, 2);  matmul_439 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_237: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_897, [1, 1, 512]);  transpose_897 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_918: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_237, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_682: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_918, 0.1, False);  linear_918 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_639: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_330, dropout_682);  layer_norm_330 = dropout_682 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_331: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_639, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_639 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_919: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_331, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_112: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_919);  linear_919 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_683: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_112, 0.0, False);  silu_112 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_920: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_683, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_683 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_684: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_920, 0.1, False);  linear_920 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_640: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_331, dropout_684);  layer_norm_331 = dropout_684 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_332: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_640, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_640 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_921: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_332, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_277: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_921, 0.125);  linear_921 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_477: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_277, [1, 1, 8, 64]);  mul_277 = None
        transpose_898: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_477, 1, 2);  view_477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_922: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_332, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_478: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_922, [1, -1, 8, 64]);  linear_922 = None
        transpose_899: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_478, 1, 2);  view_478 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_923: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_332, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_479: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_923, [1, -1, 8, 64]);  linear_923 = None
        transpose_900: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_479, 1, 2);  view_479 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_335: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_899, torch.float32);  transpose_899 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_336: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_900, torch.float32);  transpose_900 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2367: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__226: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2367, 2, add_612, to_335);  slice_2367 = to_335 = index_copy__226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2368: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__227: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2368, 2, add_612, to_336);  slice_2368 = to_336 = index_copy__227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2369: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2370: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2369, 2, 0, 9223372036854775807);  slice_2369 = None
        slice_2371: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2370, 3, 0, 9223372036854775807);  slice_2370 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2372: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2373: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2372, 2, 0, 9223372036854775807);  slice_2372 = None
        slice_2374: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2373, 3, 0, 9223372036854775807);  slice_2373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_901: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2371, 2, 3);  slice_2371 = None
        matmul_440: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_898, transpose_901);  transpose_898 = transpose_901 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2375: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_36, 0, 0, 9223372036854775807);  expand_36 = None
        slice_2376: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2375, 1, 0, 9223372036854775807);  slice_2375 = None
        slice_2377: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2376, 2, 0, 9223372036854775807);  slice_2376 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_641: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_440, slice_2377);  matmul_440 = slice_2377 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_220: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_641, -1);  add_641 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_685: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_220, 0.0, False);  softmax_220 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_441: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_685, slice_2374);  dropout_685 = slice_2374 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_902: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_441, 1, 2);  matmul_441 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_238: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_902, [1, 1, 512]);  transpose_902 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_924: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_238, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_686: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_924, 0.1, False);  linear_924 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_642: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_332, dropout_686);  layer_norm_332 = dropout_686 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_333: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_642, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_642 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_925: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_333, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_278: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_925, 0.125);  linear_925 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_480: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_278, [1, 1, 8, 64]);  mul_278 = None
        transpose_903: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_480, 1, 2);  view_480 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2378: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2379: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2378, 2, 0, 23);  slice_2378 = None
        slice_2380: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2379, 3, 0, 9223372036854775807);  slice_2379 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2381: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2382: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2381, 2, 0, 23);  slice_2381 = None
        slice_2383: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2382, 3, 0, 9223372036854775807);  slice_2382 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_904: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2380, 2, 3);  slice_2380 = None
        matmul_442: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_903, transpose_904);  transpose_903 = transpose_904 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2384: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_18, 0, 0, 9223372036854775807);  masked_fill_18 = None
        slice_2385: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2384, 1, 0, 9223372036854775807);  slice_2384 = None
        slice_2386: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2385, 2, 0, 9223372036854775807);  slice_2385 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_643: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_442, slice_2386);  matmul_442 = slice_2386 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_221: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_643, -1);  add_643 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_687: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_221, 0.0, False);  softmax_221 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_443: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_687, slice_2383);  dropout_687 = slice_2383 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_905: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_443, 1, 2);  matmul_443 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_239: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_905, [1, 1, 512]);  transpose_905 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_926: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_239, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_688: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_926, 0.1, False);  linear_926 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_644: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_333, dropout_688);  layer_norm_333 = dropout_688 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_334: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_644, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_644 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_927: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_334, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_113: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_927);  linear_927 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_689: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_113, 0.0, False);  silu_113 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_928: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_689, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_689 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_690: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_928, 0.1, False);  linear_928 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_645: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_334, dropout_690);  layer_norm_334 = dropout_690 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_335: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_645, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_645 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_929: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_335, p_model_lm_head_weight);  layer_norm_335 = None
        add_646: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_929, b_model_final_logits_bias);  linear_929 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_2387: "i64[1]" = torch.ops.aten.slice.Tensor(add_612, 0, -1, 9223372036854775807);  add_612 = None
        add_647: "i64[1]" = torch.ops.aten.add.Tensor(slice_2387, 1);  slice_2387 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_2388: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_646, 0, 0, 9223372036854775807);  add_646 = None
        select_76: "f32[1, 59514]" = torch.ops.aten.select.int(slice_2388, 1, -1);  slice_2388 = None
        slice_2389: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_76, 1, 0, 9223372036854775807);  select_76 = None
        clone_35: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_2389);  slice_2389 = None
        to_337: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_35, torch.float32);  clone_35 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_338: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_337, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_337 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_17: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_338, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__17: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_17, to_32);  zeros_like_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_648: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_338, add__17);  to_338 = add__17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_17: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_648, -1);  add_648 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_17: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_17, -1);  log_softmax_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_279: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_17, and_17);  argmax_17 = None
        rsub_36: "i64[1]" = torch.ops.aten.rsub.Scalar(and_17, 1)
        mul_280: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_36);  rsub_36 = None
        add_649: "i64[1]" = torch.ops.aten.add.Tensor(mul_279, mul_280);  mul_279 = mul_280 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_2390: "i64[1]" = torch.ops.aten.slice.Tensor(add_649, 0, 0, 9223372036854775807);  add_649 = None
        unsqueeze_110: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_2390, 1);  slice_2390 = None
        cat_17: "i64[1, 19]" = torch.ops.aten.cat.default([cat_16, unsqueeze_110], -1);  cat_16 = unsqueeze_110 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_52: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_53: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_35: "b8[1]" = torch.ops.aten.__or__.Tensor(full_52, full_53);  full_52 = full_53 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_339: "i64[1]" = torch.ops.aten.to.dtype_layout(to_321, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_321 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_2391: "i64[1, 19]" = torch.ops.aten.slice.Tensor(cat_17, 0, 0, 9223372036854775807)
        select_77: "i64[1]" = torch.ops.aten.select.int(slice_2391, 1, -1);  slice_2391 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_19: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_77, to_339);  select_77 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_36: "b8[1]" = torch.ops.aten.__or__.Tensor(or_35, isin_19);  or_35 = isin_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_19: "b8[1]" = torch.ops.aten.bitwise_not.default(or_36);  or_36 = None
        and_18: "i64[1]" = torch.ops.aten.__and__.Tensor(and_17, bitwise_not_19);  and_17 = bitwise_not_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_18: "i64[]" = torch.ops.aten.max.default(and_18)
        eq_17: "b8[]" = torch.ops.aten.eq.Scalar(max_18, 0);  max_18 = eq_17 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_2392: "i64[1, 19]" = torch.ops.aten.slice.Tensor(cat_17, 0, 0, 9223372036854775807)
        slice_2393: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_2392, 1, -1, 9223372036854775807);  slice_2392 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_36: "i64[1, 1]" = torch.ops.aten.clone.default(slice_2393, memory_format = torch.contiguous_format);  slice_2393 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_481: "i64[1, 1]" = torch.ops.aten.view.default(clone_36, [-1, 1]);  clone_36 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_38: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_481, 59513);  view_481 = None
        mul_281: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_38, 22.627416997969522);  embedding_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_111: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_647, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_2394: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807)
        unsqueeze_112: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_2394, 1);  slice_2394 = None
        unsqueeze_113: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_112, 2);  unsqueeze_112 = None
        slice_2395: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_113, 3, 0, 9223372036854775807);  unsqueeze_113 = None
        expand_37: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_2395, [1, 1, 1, 23]);  slice_2395 = None
        to_340: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_37, torch.float32);  expand_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_37: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_340, 1.0);  to_340 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_341: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_37, torch.bool)
        masked_fill_19: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_37, to_341, -3.4028234663852886e+38);  rsub_37 = to_341 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_39: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_111);  unsqueeze_111 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_342: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_39, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_39 = None
        add_650: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_281, to_342);  mul_281 = to_342 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_691: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_650, 0.1, False);  add_650 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_78: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_79: "f32[20, 64]" = torch.ops.aten.select.int(select_78, 0, 0);  select_78 = None
        any_23: "b8[20]" = torch.ops.aten.any.dim(select_79, -1);  select_79 = None
        sum_21: "i64[]" = torch.ops.aten.sum.default(any_23);  any_23 = sum_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_54: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_25: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_240: "i64[1, 1]" = torch.ops.aten.reshape.default(add_647, [-1, 1])
        gt_18: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_25, reshape_240);  arange_25 = reshape_240 = None
        mul__18: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_54, gt_18);  full_54 = gt_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_114: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__18, 0);  mul__18 = None
        unsqueeze_115: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_114, 1);  unsqueeze_114 = None
        slice_2396: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_115, 2, 0, 9223372036854775807);  unsqueeze_115 = None
        slice_2397: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2396, 3, 0, 9223372036854775807);  slice_2396 = None
        expand_38: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_2397, [1, 1, -1, -1]);  slice_2397 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_930: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_691, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias)
        mul_282: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_930, 0.125);  linear_930 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_482: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_282, [1, 1, 8, 64]);  mul_282 = None
        transpose_906: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_482, 1, 2);  view_482 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_931: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_691, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_483: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_931, [1, -1, 8, 64]);  linear_931 = None
        transpose_907: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_483, 1, 2);  view_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_932: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_691, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_484: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_932, [1, -1, 8, 64]);  linear_932 = None
        transpose_908: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_484, 1, 2);  view_484 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_343: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_907, torch.float32);  transpose_907 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_344: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_908, torch.float32);  transpose_908 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2398: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__228: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2398, 2, add_647, to_343);  slice_2398 = to_343 = index_copy__228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2399: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__229: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2399, 2, add_647, to_344);  slice_2399 = to_344 = index_copy__229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2400: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2401: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2400, 2, 0, 9223372036854775807);  slice_2400 = None
        slice_2402: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2401, 3, 0, 9223372036854775807);  slice_2401 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2403: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2404: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2403, 2, 0, 9223372036854775807);  slice_2403 = None
        slice_2405: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2404, 3, 0, 9223372036854775807);  slice_2404 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_909: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2402, 2, 3);  slice_2402 = None
        matmul_444: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_906, transpose_909);  transpose_906 = transpose_909 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2406: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_38, 0, 0, 9223372036854775807)
        slice_2407: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2406, 1, 0, 9223372036854775807);  slice_2406 = None
        slice_2408: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2407, 2, 0, 9223372036854775807);  slice_2407 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_651: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_444, slice_2408);  matmul_444 = slice_2408 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_222: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_651, -1);  add_651 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_692: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_222, 0.0, False);  softmax_222 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_445: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_692, slice_2405);  dropout_692 = slice_2405 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_910: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_445, 1, 2);  matmul_445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_241: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_910, [1, 1, 512]);  transpose_910 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_933: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_241, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_693: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_933, 0.1, False);  linear_933 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_652: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_691, dropout_693);  dropout_691 = dropout_693 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_336: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_652, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_652 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_934: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_336, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias)
        mul_283: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_934, 0.125);  linear_934 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_485: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_283, [1, 1, 8, 64]);  mul_283 = None
        transpose_911: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_485, 1, 2);  view_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2409: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807)
        slice_2410: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2409, 2, 0, 23);  slice_2409 = None
        slice_2411: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2410, 3, 0, 9223372036854775807);  slice_2410 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2412: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807)
        slice_2413: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2412, 2, 0, 23);  slice_2412 = None
        slice_2414: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2413, 3, 0, 9223372036854775807);  slice_2413 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_912: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2411, 2, 3);  slice_2411 = None
        matmul_446: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_911, transpose_912);  transpose_911 = transpose_912 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2415: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_19, 0, 0, 9223372036854775807)
        slice_2416: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2415, 1, 0, 9223372036854775807);  slice_2415 = None
        slice_2417: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2416, 2, 0, 9223372036854775807);  slice_2416 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_653: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_446, slice_2417);  matmul_446 = slice_2417 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_223: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_653, -1);  add_653 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_694: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_223, 0.0, False);  softmax_223 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_447: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_694, slice_2414);  dropout_694 = slice_2414 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_913: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_447, 1, 2);  matmul_447 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_242: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_913, [1, 1, 512]);  transpose_913 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_935: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_242, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_695: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_935, 0.1, False);  linear_935 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_654: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_336, dropout_695);  layer_norm_336 = dropout_695 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_337: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_654, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_654 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_936: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_337, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias)
        silu_114: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_936);  linear_936 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_696: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_114, 0.0, False);  silu_114 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_937: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_696, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_696 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_697: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_937, 0.1, False);  linear_937 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_655: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_337, dropout_697);  layer_norm_337 = dropout_697 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_338: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_655, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_655 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_938: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_338, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias)
        mul_284: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_938, 0.125);  linear_938 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_486: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_284, [1, 1, 8, 64]);  mul_284 = None
        transpose_914: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_486, 1, 2);  view_486 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_939: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_338, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_487: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_939, [1, -1, 8, 64]);  linear_939 = None
        transpose_915: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_487, 1, 2);  view_487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_940: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_338, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_488: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_940, [1, -1, 8, 64]);  linear_940 = None
        transpose_916: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_488, 1, 2);  view_488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_345: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_915, torch.float32);  transpose_915 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_346: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_916, torch.float32);  transpose_916 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2418: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__230: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2418, 2, add_647, to_345);  slice_2418 = to_345 = index_copy__230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2419: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__231: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2419, 2, add_647, to_346);  slice_2419 = to_346 = index_copy__231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2420: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2421: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2420, 2, 0, 9223372036854775807);  slice_2420 = None
        slice_2422: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2421, 3, 0, 9223372036854775807);  slice_2421 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2423: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2424: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2423, 2, 0, 9223372036854775807);  slice_2423 = None
        slice_2425: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2424, 3, 0, 9223372036854775807);  slice_2424 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_917: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2422, 2, 3);  slice_2422 = None
        matmul_448: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_914, transpose_917);  transpose_914 = transpose_917 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2426: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_38, 0, 0, 9223372036854775807)
        slice_2427: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2426, 1, 0, 9223372036854775807);  slice_2426 = None
        slice_2428: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2427, 2, 0, 9223372036854775807);  slice_2427 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_656: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_448, slice_2428);  matmul_448 = slice_2428 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_224: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_656, -1);  add_656 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_698: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_224, 0.0, False);  softmax_224 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_449: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_698, slice_2425);  dropout_698 = slice_2425 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_918: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_449, 1, 2);  matmul_449 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_243: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_918, [1, 1, 512]);  transpose_918 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_941: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_243, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_699: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_941, 0.1, False);  linear_941 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_657: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_338, dropout_699);  layer_norm_338 = dropout_699 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_339: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_657, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_657 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_942: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_339, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias)
        mul_285: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_942, 0.125);  linear_942 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_489: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_285, [1, 1, 8, 64]);  mul_285 = None
        transpose_919: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_489, 1, 2);  view_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2429: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807)
        slice_2430: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2429, 2, 0, 23);  slice_2429 = None
        slice_2431: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2430, 3, 0, 9223372036854775807);  slice_2430 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2432: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807)
        slice_2433: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2432, 2, 0, 23);  slice_2432 = None
        slice_2434: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2433, 3, 0, 9223372036854775807);  slice_2433 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_920: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2431, 2, 3);  slice_2431 = None
        matmul_450: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_919, transpose_920);  transpose_919 = transpose_920 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2435: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_19, 0, 0, 9223372036854775807)
        slice_2436: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2435, 1, 0, 9223372036854775807);  slice_2435 = None
        slice_2437: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2436, 2, 0, 9223372036854775807);  slice_2436 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_658: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_450, slice_2437);  matmul_450 = slice_2437 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_225: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_658, -1);  add_658 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_700: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_225, 0.0, False);  softmax_225 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_451: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_700, slice_2434);  dropout_700 = slice_2434 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_921: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_451, 1, 2);  matmul_451 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_244: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_921, [1, 1, 512]);  transpose_921 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_943: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_244, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_701: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_943, 0.1, False);  linear_943 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_659: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_339, dropout_701);  layer_norm_339 = dropout_701 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_340: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_659, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_659 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_944: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_340, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias)
        silu_115: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_944);  linear_944 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_702: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_115, 0.0, False);  silu_115 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_945: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_702, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_702 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_703: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_945, 0.1, False);  linear_945 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_660: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_340, dropout_703);  layer_norm_340 = dropout_703 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_341: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_660, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_660 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_946: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_341, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias)
        mul_286: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_946, 0.125);  linear_946 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_490: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_286, [1, 1, 8, 64]);  mul_286 = None
        transpose_922: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_490, 1, 2);  view_490 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_947: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_341, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_491: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_947, [1, -1, 8, 64]);  linear_947 = None
        transpose_923: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_491, 1, 2);  view_491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_948: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_341, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_492: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_948, [1, -1, 8, 64]);  linear_948 = None
        transpose_924: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_492, 1, 2);  view_492 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_347: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_923, torch.float32);  transpose_923 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_348: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_924, torch.float32);  transpose_924 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2438: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__232: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2438, 2, add_647, to_347);  slice_2438 = to_347 = index_copy__232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2439: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__233: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2439, 2, add_647, to_348);  slice_2439 = to_348 = index_copy__233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2440: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2441: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2440, 2, 0, 9223372036854775807);  slice_2440 = None
        slice_2442: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2441, 3, 0, 9223372036854775807);  slice_2441 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2443: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2444: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2443, 2, 0, 9223372036854775807);  slice_2443 = None
        slice_2445: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2444, 3, 0, 9223372036854775807);  slice_2444 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_925: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2442, 2, 3);  slice_2442 = None
        matmul_452: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_922, transpose_925);  transpose_922 = transpose_925 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2446: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_38, 0, 0, 9223372036854775807)
        slice_2447: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2446, 1, 0, 9223372036854775807);  slice_2446 = None
        slice_2448: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2447, 2, 0, 9223372036854775807);  slice_2447 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_661: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_452, slice_2448);  matmul_452 = slice_2448 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_226: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_661, -1);  add_661 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_704: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_226, 0.0, False);  softmax_226 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_453: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_704, slice_2445);  dropout_704 = slice_2445 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_926: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_453, 1, 2);  matmul_453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_245: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_926, [1, 1, 512]);  transpose_926 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_949: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_245, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_705: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_949, 0.1, False);  linear_949 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_662: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_341, dropout_705);  layer_norm_341 = dropout_705 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_342: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_662, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_662 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_950: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_342, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias)
        mul_287: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_950, 0.125);  linear_950 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_493: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_287, [1, 1, 8, 64]);  mul_287 = None
        transpose_927: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_493, 1, 2);  view_493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2449: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807)
        slice_2450: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2449, 2, 0, 23);  slice_2449 = None
        slice_2451: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2450, 3, 0, 9223372036854775807);  slice_2450 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2452: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807)
        slice_2453: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2452, 2, 0, 23);  slice_2452 = None
        slice_2454: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2453, 3, 0, 9223372036854775807);  slice_2453 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_928: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2451, 2, 3);  slice_2451 = None
        matmul_454: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_927, transpose_928);  transpose_927 = transpose_928 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2455: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_19, 0, 0, 9223372036854775807)
        slice_2456: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2455, 1, 0, 9223372036854775807);  slice_2455 = None
        slice_2457: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2456, 2, 0, 9223372036854775807);  slice_2456 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_663: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_454, slice_2457);  matmul_454 = slice_2457 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_227: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_663, -1);  add_663 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_706: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_227, 0.0, False);  softmax_227 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_455: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_706, slice_2454);  dropout_706 = slice_2454 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_929: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_455, 1, 2);  matmul_455 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_246: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_929, [1, 1, 512]);  transpose_929 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_951: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_246, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_707: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_951, 0.1, False);  linear_951 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_664: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_342, dropout_707);  layer_norm_342 = dropout_707 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_343: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_664, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_664 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_952: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_343, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias)
        silu_116: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_952);  linear_952 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_708: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_116, 0.0, False);  silu_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_953: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_708, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_708 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_709: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_953, 0.1, False);  linear_953 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_665: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_343, dropout_709);  layer_norm_343 = dropout_709 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_344: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_665, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_665 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_954: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_344, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias)
        mul_288: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_954, 0.125);  linear_954 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_494: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_288, [1, 1, 8, 64]);  mul_288 = None
        transpose_930: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_494, 1, 2);  view_494 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_955: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_344, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_495: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_955, [1, -1, 8, 64]);  linear_955 = None
        transpose_931: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_495, 1, 2);  view_495 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_956: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_344, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_496: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_956, [1, -1, 8, 64]);  linear_956 = None
        transpose_932: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_496, 1, 2);  view_496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_349: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_931, torch.float32);  transpose_931 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_350: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_932, torch.float32);  transpose_932 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2458: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__234: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2458, 2, add_647, to_349);  slice_2458 = to_349 = index_copy__234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2459: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__235: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2459, 2, add_647, to_350);  slice_2459 = to_350 = index_copy__235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2460: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2461: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2460, 2, 0, 9223372036854775807);  slice_2460 = None
        slice_2462: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2461, 3, 0, 9223372036854775807);  slice_2461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2463: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2464: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2463, 2, 0, 9223372036854775807);  slice_2463 = None
        slice_2465: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2464, 3, 0, 9223372036854775807);  slice_2464 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_933: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2462, 2, 3);  slice_2462 = None
        matmul_456: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_930, transpose_933);  transpose_930 = transpose_933 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2466: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_38, 0, 0, 9223372036854775807)
        slice_2467: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2466, 1, 0, 9223372036854775807);  slice_2466 = None
        slice_2468: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2467, 2, 0, 9223372036854775807);  slice_2467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_666: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_456, slice_2468);  matmul_456 = slice_2468 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_228: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_666, -1);  add_666 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_710: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_228, 0.0, False);  softmax_228 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_457: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_710, slice_2465);  dropout_710 = slice_2465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_934: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_457, 1, 2);  matmul_457 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_247: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_934, [1, 1, 512]);  transpose_934 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_957: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_247, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_711: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_957, 0.1, False);  linear_957 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_667: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_344, dropout_711);  layer_norm_344 = dropout_711 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_345: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_667, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_667 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_958: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_345, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias)
        mul_289: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_958, 0.125);  linear_958 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_497: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_289, [1, 1, 8, 64]);  mul_289 = None
        transpose_935: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_497, 1, 2);  view_497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2469: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807)
        slice_2470: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2469, 2, 0, 23);  slice_2469 = None
        slice_2471: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2470, 3, 0, 9223372036854775807);  slice_2470 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2472: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807)
        slice_2473: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2472, 2, 0, 23);  slice_2472 = None
        slice_2474: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2473, 3, 0, 9223372036854775807);  slice_2473 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_936: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2471, 2, 3);  slice_2471 = None
        matmul_458: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_935, transpose_936);  transpose_935 = transpose_936 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2475: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_19, 0, 0, 9223372036854775807)
        slice_2476: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2475, 1, 0, 9223372036854775807);  slice_2475 = None
        slice_2477: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2476, 2, 0, 9223372036854775807);  slice_2476 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_668: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_458, slice_2477);  matmul_458 = slice_2477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_229: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_668, -1);  add_668 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_712: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_229, 0.0, False);  softmax_229 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_459: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_712, slice_2474);  dropout_712 = slice_2474 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_937: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_459, 1, 2);  matmul_459 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_248: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_937, [1, 1, 512]);  transpose_937 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_959: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_248, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_713: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_959, 0.1, False);  linear_959 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_669: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_345, dropout_713);  layer_norm_345 = dropout_713 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_346: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_669, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_669 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_960: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_346, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias)
        silu_117: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_960);  linear_960 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_714: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_117, 0.0, False);  silu_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_961: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_714, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_714 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_715: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_961, 0.1, False);  linear_961 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_670: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_346, dropout_715);  layer_norm_346 = dropout_715 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_347: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_670, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_670 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_962: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_347, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias)
        mul_290: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_962, 0.125);  linear_962 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_498: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_290, [1, 1, 8, 64]);  mul_290 = None
        transpose_938: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_498, 1, 2);  view_498 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_963: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_347, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_499: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_963, [1, -1, 8, 64]);  linear_963 = None
        transpose_939: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_499, 1, 2);  view_499 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_964: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_347, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_500: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_964, [1, -1, 8, 64]);  linear_964 = None
        transpose_940: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_500, 1, 2);  view_500 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_351: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_939, torch.float32);  transpose_939 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_352: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_940, torch.float32);  transpose_940 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2478: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__236: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2478, 2, add_647, to_351);  slice_2478 = to_351 = index_copy__236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2479: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__237: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2479, 2, add_647, to_352);  slice_2479 = to_352 = index_copy__237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2480: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2481: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2480, 2, 0, 9223372036854775807);  slice_2480 = None
        slice_2482: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2481, 3, 0, 9223372036854775807);  slice_2481 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2483: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2484: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2483, 2, 0, 9223372036854775807);  slice_2483 = None
        slice_2485: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2484, 3, 0, 9223372036854775807);  slice_2484 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_941: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2482, 2, 3);  slice_2482 = None
        matmul_460: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_938, transpose_941);  transpose_938 = transpose_941 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2486: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_38, 0, 0, 9223372036854775807)
        slice_2487: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2486, 1, 0, 9223372036854775807);  slice_2486 = None
        slice_2488: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2487, 2, 0, 9223372036854775807);  slice_2487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_671: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_460, slice_2488);  matmul_460 = slice_2488 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_230: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_671, -1);  add_671 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_716: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_230, 0.0, False);  softmax_230 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_461: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_716, slice_2485);  dropout_716 = slice_2485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_942: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_461, 1, 2);  matmul_461 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_249: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_942, [1, 1, 512]);  transpose_942 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_965: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_249, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_717: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_965, 0.1, False);  linear_965 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_672: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_347, dropout_717);  layer_norm_347 = dropout_717 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_348: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_672, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_672 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_966: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_348, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias)
        mul_291: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_966, 0.125);  linear_966 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_501: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_291, [1, 1, 8, 64]);  mul_291 = None
        transpose_943: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_501, 1, 2);  view_501 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2489: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807)
        slice_2490: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2489, 2, 0, 23);  slice_2489 = None
        slice_2491: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2490, 3, 0, 9223372036854775807);  slice_2490 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2492: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807)
        slice_2493: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2492, 2, 0, 23);  slice_2492 = None
        slice_2494: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2493, 3, 0, 9223372036854775807);  slice_2493 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_944: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2491, 2, 3);  slice_2491 = None
        matmul_462: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_943, transpose_944);  transpose_943 = transpose_944 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2495: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_19, 0, 0, 9223372036854775807)
        slice_2496: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2495, 1, 0, 9223372036854775807);  slice_2495 = None
        slice_2497: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2496, 2, 0, 9223372036854775807);  slice_2496 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_673: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_462, slice_2497);  matmul_462 = slice_2497 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_231: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_673, -1);  add_673 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_718: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_231, 0.0, False);  softmax_231 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_463: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_718, slice_2494);  dropout_718 = slice_2494 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_945: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_463, 1, 2);  matmul_463 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_250: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_945, [1, 1, 512]);  transpose_945 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_967: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_250, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_719: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_967, 0.1, False);  linear_967 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_674: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_348, dropout_719);  layer_norm_348 = dropout_719 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_349: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_674, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_674 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_968: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_349, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias)
        silu_118: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_968);  linear_968 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_720: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_118, 0.0, False);  silu_118 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_969: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_720, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_720 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_721: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_969, 0.1, False);  linear_969 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_675: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_349, dropout_721);  layer_norm_349 = dropout_721 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_350: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_675, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_675 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_970: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_350, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias)
        mul_292: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_970, 0.125);  linear_970 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_502: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_292, [1, 1, 8, 64]);  mul_292 = None
        transpose_946: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_502, 1, 2);  view_502 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_971: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_350, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_503: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_971, [1, -1, 8, 64]);  linear_971 = None
        transpose_947: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_503, 1, 2);  view_503 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_972: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_350, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_504: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_972, [1, -1, 8, 64]);  linear_972 = None
        transpose_948: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_504, 1, 2);  view_504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_353: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_947, torch.float32);  transpose_947 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_354: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_948, torch.float32);  transpose_948 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2498: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__238: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2498, 2, add_647, to_353);  slice_2498 = to_353 = index_copy__238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2499: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__239: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2499, 2, add_647, to_354);  slice_2499 = to_354 = index_copy__239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2500: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2501: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2500, 2, 0, 9223372036854775807);  slice_2500 = None
        slice_2502: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2501, 3, 0, 9223372036854775807);  slice_2501 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2503: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2504: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2503, 2, 0, 9223372036854775807);  slice_2503 = None
        slice_2505: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2504, 3, 0, 9223372036854775807);  slice_2504 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_949: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2502, 2, 3);  slice_2502 = None
        matmul_464: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_946, transpose_949);  transpose_946 = transpose_949 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2506: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_38, 0, 0, 9223372036854775807);  expand_38 = None
        slice_2507: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2506, 1, 0, 9223372036854775807);  slice_2506 = None
        slice_2508: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2507, 2, 0, 9223372036854775807);  slice_2507 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_676: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_464, slice_2508);  matmul_464 = slice_2508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_232: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_676, -1);  add_676 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_722: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_232, 0.0, False);  softmax_232 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_465: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_722, slice_2505);  dropout_722 = slice_2505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_950: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_465, 1, 2);  matmul_465 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_251: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_950, [1, 1, 512]);  transpose_950 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_973: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_251, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_723: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_973, 0.1, False);  linear_973 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_677: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_350, dropout_723);  layer_norm_350 = dropout_723 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_351: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_677, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_677 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_974: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_351, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias)
        mul_293: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_974, 0.125);  linear_974 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_505: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_293, [1, 1, 8, 64]);  mul_293 = None
        transpose_951: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_505, 1, 2);  view_505 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2509: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807)
        slice_2510: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2509, 2, 0, 23);  slice_2509 = None
        slice_2511: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2510, 3, 0, 9223372036854775807);  slice_2510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2512: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807)
        slice_2513: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2512, 2, 0, 23);  slice_2512 = None
        slice_2514: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2513, 3, 0, 9223372036854775807);  slice_2513 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_952: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2511, 2, 3);  slice_2511 = None
        matmul_466: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_951, transpose_952);  transpose_951 = transpose_952 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2515: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_19, 0, 0, 9223372036854775807);  masked_fill_19 = None
        slice_2516: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2515, 1, 0, 9223372036854775807);  slice_2515 = None
        slice_2517: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2516, 2, 0, 9223372036854775807);  slice_2516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_678: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_466, slice_2517);  matmul_466 = slice_2517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_233: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_678, -1);  add_678 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_724: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_233, 0.0, False);  softmax_233 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_467: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_724, slice_2514);  dropout_724 = slice_2514 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_953: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_467, 1, 2);  matmul_467 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_252: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_953, [1, 1, 512]);  transpose_953 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_975: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_252, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_252 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_725: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_975, 0.1, False);  linear_975 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_679: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_351, dropout_725);  layer_norm_351 = dropout_725 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_352: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_679, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_679 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_976: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_352, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias)
        silu_119: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_976);  linear_976 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_726: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_119, 0.0, False);  silu_119 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_977: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_726, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_726 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_727: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_977, 0.1, False);  linear_977 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_680: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_352, dropout_727);  layer_norm_352 = dropout_727 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_353: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_680, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_680 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_978: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_353, p_model_lm_head_weight);  layer_norm_353 = None
        add_681: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_978, b_model_final_logits_bias);  linear_978 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_2518: "i64[1]" = torch.ops.aten.slice.Tensor(add_647, 0, -1, 9223372036854775807);  add_647 = None
        add_682: "i64[1]" = torch.ops.aten.add.Tensor(slice_2518, 1);  slice_2518 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_2519: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_681, 0, 0, 9223372036854775807);  add_681 = None
        select_80: "f32[1, 59514]" = torch.ops.aten.select.int(slice_2519, 1, -1);  slice_2519 = None
        slice_2520: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_80, 1, 0, 9223372036854775807);  select_80 = None
        clone_37: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_2520);  slice_2520 = None
        to_355: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_37, torch.float32);  clone_37 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_356: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_355, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_355 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_18: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_356, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__18: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_18, to_32);  zeros_like_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_683: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_356, add__18);  to_356 = add__18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_18: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(add_683, -1);  add_683 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_18: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_18, -1);  log_softmax_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_294: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_18, and_18);  argmax_18 = None
        rsub_38: "i64[1]" = torch.ops.aten.rsub.Scalar(and_18, 1)
        mul_295: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_38);  rsub_38 = None
        add_684: "i64[1]" = torch.ops.aten.add.Tensor(mul_294, mul_295);  mul_294 = mul_295 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_2521: "i64[1]" = torch.ops.aten.slice.Tensor(add_684, 0, 0, 9223372036854775807);  add_684 = None
        unsqueeze_116: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_2521, 1);  slice_2521 = None
        cat_18: "i64[1, 20]" = torch.ops.aten.cat.default([cat_17, unsqueeze_116], -1);  cat_17 = unsqueeze_116 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_55: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_56: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_37: "b8[1]" = torch.ops.aten.__or__.Tensor(full_55, full_56);  full_55 = full_56 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_357: "i64[1]" = torch.ops.aten.to.dtype_layout(to_339, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_339 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_2522: "i64[1, 20]" = torch.ops.aten.slice.Tensor(cat_18, 0, 0, 9223372036854775807)
        select_81: "i64[1]" = torch.ops.aten.select.int(slice_2522, 1, -1);  slice_2522 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_20: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_81, to_357);  select_81 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_38: "b8[1]" = torch.ops.aten.__or__.Tensor(or_37, isin_20);  or_37 = isin_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_20: "b8[1]" = torch.ops.aten.bitwise_not.default(or_38);  or_38 = None
        and_19: "i64[1]" = torch.ops.aten.__and__.Tensor(and_18, bitwise_not_20);  and_18 = bitwise_not_20 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_19: "i64[]" = torch.ops.aten.max.default(and_19)
        eq_18: "b8[]" = torch.ops.aten.eq.Scalar(max_19, 0);  max_19 = eq_18 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:390 in prepare_inputs_for_generation, code: input_ids = input_ids[:, -cache_position.shape[0] :]
        slice_2523: "i64[1, 20]" = torch.ops.aten.slice.Tensor(cat_18, 0, 0, 9223372036854775807)
        slice_2524: "i64[1, 1]" = torch.ops.aten.slice.Tensor(slice_2523, 1, -1, 9223372036854775807);  slice_2523 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:406 in prepare_inputs_for_generation, code: model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)
        clone_38: "i64[1, 1]" = torch.ops.aten.clone.default(slice_2524, memory_format = torch.contiguous_format);  slice_2524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:936 in forward, code: input_ids = input_ids.view(-1, input_shape[-1])
        view_506: "i64[1, 1]" = torch.ops.aten.view.default(clone_38, [-1, 1]);  clone_38 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:943 in forward, code: inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale
        embedding_40: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_lm_head_weight, view_506, 59513);  view_506 = None
        mul_296: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(embedding_40, 22.627416997969522);  embedding_40 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:972 in forward, code: position_ids = cache_position.unsqueeze(0)
        unsqueeze_117: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(add_682, 0)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
        slice_2525: "i64[1, 23]" = torch.ops.aten.slice.Tensor(add, 0, 0, 9223372036854775807);  add = None
        unsqueeze_118: "i64[1, 1, 23]" = torch.ops.aten.unsqueeze.default(slice_2525, 1);  slice_2525 = None
        unsqueeze_119: "i64[1, 1, 1, 23]" = torch.ops.aten.unsqueeze.default(unsqueeze_118, 2);  unsqueeze_118 = None
        slice_2526: "i64[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(unsqueeze_119, 3, 0, 9223372036854775807);  unsqueeze_119 = None
        expand_39: "i64[1, 1, 1, 23]" = torch.ops.aten.expand.default(slice_2526, [1, 1, 1, 23]);  slice_2526 = None
        to_358: "f32[1, 1, 1, 23]" = torch.ops.aten.to.dtype(expand_39, torch.float32);  expand_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
        rsub_39: "f32[1, 1, 1, 23]" = torch.ops.aten.rsub.Scalar(to_358, 1.0);  to_358 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
        to_359: "b8[1, 1, 1, 23]" = torch.ops.aten.to.dtype(rsub_39, torch.bool)
        masked_fill_20: "f32[1, 1, 1, 23]" = torch.ops.aten.masked_fill.Scalar(rsub_39, to_359, -3.4028234663852886e+38);  rsub_39 = to_359 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:107 in forward, code: return super().forward(positions)
        embedding_41: "f32[1, 1, 512]" = torch.ops.aten.embedding.default(p_model_model_decoder_embed_positions_weight, unsqueeze_117);  p_model_model_decoder_embed_positions_weight = unsqueeze_117 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:986 in forward, code: hidden_states = inputs_embeds + positions.to(inputs_embeds.device)
        to_360: "f32[1, 1, 512]" = torch.ops.aten.to.dtype_layout(embedding_41, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  embedding_41 = None
        add_685: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(mul_296, to_360);  mul_296 = to_360 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:987 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_728: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(add_685, 0.1, False);  add_685 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1225 in get_seq_length, code: return (self.key_cache[layer_idx][0, 0].any(dim=-1)).sum()
        select_82: "f32[8, 20, 64]" = torch.ops.aten.select.int(b___cache_self_attention_cache_key_cache_0, 0, 0)
        select_83: "f32[20, 64]" = torch.ops.aten.select.int(select_82, 0, 0);  select_82 = None
        any_24: "b8[20]" = torch.ops.aten.any.dim(select_83, -1);  select_83 = None
        sum_22: "i64[]" = torch.ops.aten.sum.default(any_24);  any_24 = sum_22 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1191 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = torch.full(
        full_57: "f32[1, 20]" = torch.ops.aten.full.default([1, 20], -3.4028234663852886e+38, dtype = torch.float32, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1196 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
        arange_26: "i64[20]" = torch.ops.aten.arange.default(20, device = device(type='cpu'), pin_memory = False)
        reshape_253: "i64[1, 1]" = torch.ops.aten.reshape.default(add_682, [-1, 1])
        gt_19: "b8[1, 20]" = torch.ops.aten.gt.Tensor(arange_26, reshape_253);  arange_26 = reshape_253 = None
        mul__19: "f32[1, 20]" = torch.ops.aten.mul_.Tensor(full_57, gt_19);  full_57 = gt_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1197 in _prepare_4d_causal_attention_mask_with_cache_position, code: causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)
        unsqueeze_120: "f32[1, 1, 20]" = torch.ops.aten.unsqueeze.default(mul__19, 0);  mul__19 = None
        unsqueeze_121: "f32[1, 1, 1, 20]" = torch.ops.aten.unsqueeze.default(unsqueeze_120, 1);  unsqueeze_120 = None
        slice_2527: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(unsqueeze_121, 2, 0, 9223372036854775807);  unsqueeze_121 = None
        slice_2528: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2527, 3, 0, 9223372036854775807);  slice_2527 = None
        expand_40: "f32[1, 1, 1, 20]" = torch.ops.aten.expand.default(slice_2528, [1, 1, -1, -1]);  slice_2528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_979: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_728, p_model_model_decoder_layers_0_self_attn_q_proj_weight, p_model_model_decoder_layers_0_self_attn_q_proj_bias);  p_model_model_decoder_layers_0_self_attn_q_proj_weight = p_model_model_decoder_layers_0_self_attn_q_proj_bias = None
        mul_297: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_979, 0.125);  linear_979 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_507: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_297, [1, 1, 8, 64]);  mul_297 = None
        transpose_954: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_507, 1, 2);  view_507 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_980: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_728, p_model_model_decoder_layers_0_self_attn_k_proj_weight, p_model_model_decoder_layers_0_self_attn_k_proj_bias);  p_model_model_decoder_layers_0_self_attn_k_proj_weight = p_model_model_decoder_layers_0_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_508: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_980, [1, -1, 8, 64]);  linear_980 = None
        transpose_955: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_508, 1, 2);  view_508 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_981: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_728, p_model_model_decoder_layers_0_self_attn_v_proj_weight, p_model_model_decoder_layers_0_self_attn_v_proj_bias);  p_model_model_decoder_layers_0_self_attn_v_proj_weight = p_model_model_decoder_layers_0_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_509: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_981, [1, -1, 8, 64]);  linear_981 = None
        transpose_956: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_509, 1, 2);  view_509 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_361: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_955, torch.float32);  transpose_955 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_362: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_956, torch.float32);  transpose_956 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2529: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 0, 0, 1)
        index_copy__240: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2529, 2, add_682, to_361);  slice_2529 = to_361 = index_copy__240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2530: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 0, 0, 1)
        index_copy__241: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2530, 2, add_682, to_362);  slice_2530 = to_362 = index_copy__241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2531: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_0, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_key_cache_0 = None
        slice_2532: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2531, 2, 0, 9223372036854775807);  slice_2531 = None
        slice_2533: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2532, 3, 0, 9223372036854775807);  slice_2532 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2534: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_0, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_value_cache_0 = None
        slice_2535: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2534, 2, 0, 9223372036854775807);  slice_2534 = None
        slice_2536: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2535, 3, 0, 9223372036854775807);  slice_2535 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_957: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2533, 2, 3);  slice_2533 = None
        matmul_468: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_954, transpose_957);  transpose_954 = transpose_957 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2537: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_40, 0, 0, 9223372036854775807)
        slice_2538: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2537, 1, 0, 9223372036854775807);  slice_2537 = None
        slice_2539: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2538, 2, 0, 9223372036854775807);  slice_2538 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_686: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_468, slice_2539);  matmul_468 = slice_2539 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_234: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_686, -1);  add_686 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_729: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_234, 0.0, False);  softmax_234 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_469: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_729, slice_2536);  dropout_729 = slice_2536 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_958: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_469, 1, 2);  matmul_469 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_254: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_958, [1, 1, 512]);  transpose_958 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_982: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_254, p_model_model_decoder_layers_0_self_attn_out_proj_weight, p_model_model_decoder_layers_0_self_attn_out_proj_bias);  reshape_254 = p_model_model_decoder_layers_0_self_attn_out_proj_weight = p_model_model_decoder_layers_0_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_730: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_982, 0.1, False);  linear_982 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_687: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(dropout_728, dropout_730);  dropout_728 = dropout_730 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_354: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_687, [512], p_model_model_decoder_layers_0_self_attn_layer_norm_weight, p_model_model_decoder_layers_0_self_attn_layer_norm_bias);  add_687 = p_model_model_decoder_layers_0_self_attn_layer_norm_weight = p_model_model_decoder_layers_0_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_983: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_354, p_model_model_decoder_layers_0_encoder_attn_q_proj_weight, p_model_model_decoder_layers_0_encoder_attn_q_proj_bias);  p_model_model_decoder_layers_0_encoder_attn_q_proj_weight = p_model_model_decoder_layers_0_encoder_attn_q_proj_bias = None
        mul_298: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_983, 0.125);  linear_983 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_510: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_298, [1, 1, 8, 64]);  mul_298 = None
        transpose_959: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_510, 1, 2);  view_510 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2540: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_0, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_key_cache_0 = None
        slice_2541: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2540, 2, 0, 23);  slice_2540 = None
        slice_2542: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2541, 3, 0, 9223372036854775807);  slice_2541 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2543: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_0, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_value_cache_0 = None
        slice_2544: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2543, 2, 0, 23);  slice_2543 = None
        slice_2545: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2544, 3, 0, 9223372036854775807);  slice_2544 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_960: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2542, 2, 3);  slice_2542 = None
        matmul_470: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_959, transpose_960);  transpose_959 = transpose_960 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2546: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_20, 0, 0, 9223372036854775807)
        slice_2547: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2546, 1, 0, 9223372036854775807);  slice_2546 = None
        slice_2548: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2547, 2, 0, 9223372036854775807);  slice_2547 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_688: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_470, slice_2548);  matmul_470 = slice_2548 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_235: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_688, -1);  add_688 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_731: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_235, 0.0, False);  softmax_235 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_471: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_731, slice_2545);  dropout_731 = slice_2545 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_961: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_471, 1, 2);  matmul_471 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_255: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_961, [1, 1, 512]);  transpose_961 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_984: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_255, p_model_model_decoder_layers_0_encoder_attn_out_proj_weight, p_model_model_decoder_layers_0_encoder_attn_out_proj_bias);  reshape_255 = p_model_model_decoder_layers_0_encoder_attn_out_proj_weight = p_model_model_decoder_layers_0_encoder_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_732: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_984, 0.1, False);  linear_984 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_689: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_354, dropout_732);  layer_norm_354 = dropout_732 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_355: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_689, [512], p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias);  add_689 = p_model_model_decoder_layers_0_encoder_attn_layer_norm_weight = p_model_model_decoder_layers_0_encoder_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_985: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_355, p_model_model_decoder_layers_0_fc1_weight, p_model_model_decoder_layers_0_fc1_bias);  p_model_model_decoder_layers_0_fc1_weight = p_model_model_decoder_layers_0_fc1_bias = None
        silu_120: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_985);  linear_985 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_733: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_120, 0.0, False);  silu_120 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_986: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_733, p_model_model_decoder_layers_0_fc2_weight, p_model_model_decoder_layers_0_fc2_bias);  dropout_733 = p_model_model_decoder_layers_0_fc2_weight = p_model_model_decoder_layers_0_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_734: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_986, 0.1, False);  linear_986 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_690: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_355, dropout_734);  layer_norm_355 = dropout_734 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_356: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_690, [512], p_model_model_decoder_layers_0_final_layer_norm_weight, p_model_model_decoder_layers_0_final_layer_norm_bias);  add_690 = p_model_model_decoder_layers_0_final_layer_norm_weight = p_model_model_decoder_layers_0_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_987: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_356, p_model_model_decoder_layers_1_self_attn_q_proj_weight, p_model_model_decoder_layers_1_self_attn_q_proj_bias);  p_model_model_decoder_layers_1_self_attn_q_proj_weight = p_model_model_decoder_layers_1_self_attn_q_proj_bias = None
        mul_299: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_987, 0.125);  linear_987 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_511: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_299, [1, 1, 8, 64]);  mul_299 = None
        transpose_962: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_511, 1, 2);  view_511 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_988: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_356, p_model_model_decoder_layers_1_self_attn_k_proj_weight, p_model_model_decoder_layers_1_self_attn_k_proj_bias);  p_model_model_decoder_layers_1_self_attn_k_proj_weight = p_model_model_decoder_layers_1_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_512: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_988, [1, -1, 8, 64]);  linear_988 = None
        transpose_963: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_512, 1, 2);  view_512 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_989: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_356, p_model_model_decoder_layers_1_self_attn_v_proj_weight, p_model_model_decoder_layers_1_self_attn_v_proj_bias);  p_model_model_decoder_layers_1_self_attn_v_proj_weight = p_model_model_decoder_layers_1_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_513: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_989, [1, -1, 8, 64]);  linear_989 = None
        transpose_964: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_513, 1, 2);  view_513 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_363: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_963, torch.float32);  transpose_963 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_364: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_964, torch.float32);  transpose_964 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2549: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 0, 0, 1)
        index_copy__242: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2549, 2, add_682, to_363);  slice_2549 = to_363 = index_copy__242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2550: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 0, 0, 1)
        index_copy__243: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2550, 2, add_682, to_364);  slice_2550 = to_364 = index_copy__243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2551: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_1, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_key_cache_1 = None
        slice_2552: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2551, 2, 0, 9223372036854775807);  slice_2551 = None
        slice_2553: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2552, 3, 0, 9223372036854775807);  slice_2552 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2554: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_1, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_value_cache_1 = None
        slice_2555: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2554, 2, 0, 9223372036854775807);  slice_2554 = None
        slice_2556: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2555, 3, 0, 9223372036854775807);  slice_2555 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_965: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2553, 2, 3);  slice_2553 = None
        matmul_472: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_962, transpose_965);  transpose_962 = transpose_965 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2557: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_40, 0, 0, 9223372036854775807)
        slice_2558: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2557, 1, 0, 9223372036854775807);  slice_2557 = None
        slice_2559: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2558, 2, 0, 9223372036854775807);  slice_2558 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_691: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_472, slice_2559);  matmul_472 = slice_2559 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_236: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_691, -1);  add_691 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_735: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_236, 0.0, False);  softmax_236 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_473: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_735, slice_2556);  dropout_735 = slice_2556 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_966: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_473, 1, 2);  matmul_473 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_256: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_966, [1, 1, 512]);  transpose_966 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_990: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_256, p_model_model_decoder_layers_1_self_attn_out_proj_weight, p_model_model_decoder_layers_1_self_attn_out_proj_bias);  reshape_256 = p_model_model_decoder_layers_1_self_attn_out_proj_weight = p_model_model_decoder_layers_1_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_736: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_990, 0.1, False);  linear_990 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_692: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_356, dropout_736);  layer_norm_356 = dropout_736 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_357: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_692, [512], p_model_model_decoder_layers_1_self_attn_layer_norm_weight, p_model_model_decoder_layers_1_self_attn_layer_norm_bias);  add_692 = p_model_model_decoder_layers_1_self_attn_layer_norm_weight = p_model_model_decoder_layers_1_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_991: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_357, p_model_model_decoder_layers_1_encoder_attn_q_proj_weight, p_model_model_decoder_layers_1_encoder_attn_q_proj_bias);  p_model_model_decoder_layers_1_encoder_attn_q_proj_weight = p_model_model_decoder_layers_1_encoder_attn_q_proj_bias = None
        mul_300: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_991, 0.125);  linear_991 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_514: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_300, [1, 1, 8, 64]);  mul_300 = None
        transpose_967: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_514, 1, 2);  view_514 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2560: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_1, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_key_cache_1 = None
        slice_2561: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2560, 2, 0, 23);  slice_2560 = None
        slice_2562: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2561, 3, 0, 9223372036854775807);  slice_2561 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2563: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_1, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_value_cache_1 = None
        slice_2564: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2563, 2, 0, 23);  slice_2563 = None
        slice_2565: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2564, 3, 0, 9223372036854775807);  slice_2564 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_968: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2562, 2, 3);  slice_2562 = None
        matmul_474: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_967, transpose_968);  transpose_967 = transpose_968 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2566: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_20, 0, 0, 9223372036854775807)
        slice_2567: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2566, 1, 0, 9223372036854775807);  slice_2566 = None
        slice_2568: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2567, 2, 0, 9223372036854775807);  slice_2567 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_693: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_474, slice_2568);  matmul_474 = slice_2568 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_237: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_693, -1);  add_693 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_737: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_237, 0.0, False);  softmax_237 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_475: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_737, slice_2565);  dropout_737 = slice_2565 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_969: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_475, 1, 2);  matmul_475 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_257: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_969, [1, 1, 512]);  transpose_969 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_992: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_257, p_model_model_decoder_layers_1_encoder_attn_out_proj_weight, p_model_model_decoder_layers_1_encoder_attn_out_proj_bias);  reshape_257 = p_model_model_decoder_layers_1_encoder_attn_out_proj_weight = p_model_model_decoder_layers_1_encoder_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_738: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_992, 0.1, False);  linear_992 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_694: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_357, dropout_738);  layer_norm_357 = dropout_738 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_358: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_694, [512], p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias);  add_694 = p_model_model_decoder_layers_1_encoder_attn_layer_norm_weight = p_model_model_decoder_layers_1_encoder_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_993: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_358, p_model_model_decoder_layers_1_fc1_weight, p_model_model_decoder_layers_1_fc1_bias);  p_model_model_decoder_layers_1_fc1_weight = p_model_model_decoder_layers_1_fc1_bias = None
        silu_121: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_993);  linear_993 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_739: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_121, 0.0, False);  silu_121 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_994: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_739, p_model_model_decoder_layers_1_fc2_weight, p_model_model_decoder_layers_1_fc2_bias);  dropout_739 = p_model_model_decoder_layers_1_fc2_weight = p_model_model_decoder_layers_1_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_740: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_994, 0.1, False);  linear_994 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_695: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_358, dropout_740);  layer_norm_358 = dropout_740 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_359: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_695, [512], p_model_model_decoder_layers_1_final_layer_norm_weight, p_model_model_decoder_layers_1_final_layer_norm_bias);  add_695 = p_model_model_decoder_layers_1_final_layer_norm_weight = p_model_model_decoder_layers_1_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_995: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_359, p_model_model_decoder_layers_2_self_attn_q_proj_weight, p_model_model_decoder_layers_2_self_attn_q_proj_bias);  p_model_model_decoder_layers_2_self_attn_q_proj_weight = p_model_model_decoder_layers_2_self_attn_q_proj_bias = None
        mul_301: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_995, 0.125);  linear_995 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_515: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_301, [1, 1, 8, 64]);  mul_301 = None
        transpose_970: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_515, 1, 2);  view_515 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_996: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_359, p_model_model_decoder_layers_2_self_attn_k_proj_weight, p_model_model_decoder_layers_2_self_attn_k_proj_bias);  p_model_model_decoder_layers_2_self_attn_k_proj_weight = p_model_model_decoder_layers_2_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_516: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_996, [1, -1, 8, 64]);  linear_996 = None
        transpose_971: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_516, 1, 2);  view_516 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_997: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_359, p_model_model_decoder_layers_2_self_attn_v_proj_weight, p_model_model_decoder_layers_2_self_attn_v_proj_bias);  p_model_model_decoder_layers_2_self_attn_v_proj_weight = p_model_model_decoder_layers_2_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_517: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_997, [1, -1, 8, 64]);  linear_997 = None
        transpose_972: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_517, 1, 2);  view_517 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_365: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_971, torch.float32);  transpose_971 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_366: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_972, torch.float32);  transpose_972 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2569: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 0, 0, 1)
        index_copy__244: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2569, 2, add_682, to_365);  slice_2569 = to_365 = index_copy__244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2570: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 0, 0, 1)
        index_copy__245: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2570, 2, add_682, to_366);  slice_2570 = to_366 = index_copy__245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2571: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_2, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_key_cache_2 = None
        slice_2572: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2571, 2, 0, 9223372036854775807);  slice_2571 = None
        slice_2573: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2572, 3, 0, 9223372036854775807);  slice_2572 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2574: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_2, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_value_cache_2 = None
        slice_2575: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2574, 2, 0, 9223372036854775807);  slice_2574 = None
        slice_2576: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2575, 3, 0, 9223372036854775807);  slice_2575 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_973: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2573, 2, 3);  slice_2573 = None
        matmul_476: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_970, transpose_973);  transpose_970 = transpose_973 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2577: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_40, 0, 0, 9223372036854775807)
        slice_2578: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2577, 1, 0, 9223372036854775807);  slice_2577 = None
        slice_2579: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2578, 2, 0, 9223372036854775807);  slice_2578 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_696: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_476, slice_2579);  matmul_476 = slice_2579 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_238: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_696, -1);  add_696 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_741: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_238, 0.0, False);  softmax_238 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_477: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_741, slice_2576);  dropout_741 = slice_2576 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_974: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_477, 1, 2);  matmul_477 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_258: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_974, [1, 1, 512]);  transpose_974 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_998: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_258, p_model_model_decoder_layers_2_self_attn_out_proj_weight, p_model_model_decoder_layers_2_self_attn_out_proj_bias);  reshape_258 = p_model_model_decoder_layers_2_self_attn_out_proj_weight = p_model_model_decoder_layers_2_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_742: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_998, 0.1, False);  linear_998 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_697: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_359, dropout_742);  layer_norm_359 = dropout_742 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_360: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_697, [512], p_model_model_decoder_layers_2_self_attn_layer_norm_weight, p_model_model_decoder_layers_2_self_attn_layer_norm_bias);  add_697 = p_model_model_decoder_layers_2_self_attn_layer_norm_weight = p_model_model_decoder_layers_2_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_999: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_360, p_model_model_decoder_layers_2_encoder_attn_q_proj_weight, p_model_model_decoder_layers_2_encoder_attn_q_proj_bias);  p_model_model_decoder_layers_2_encoder_attn_q_proj_weight = p_model_model_decoder_layers_2_encoder_attn_q_proj_bias = None
        mul_302: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_999, 0.125);  linear_999 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_518: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_302, [1, 1, 8, 64]);  mul_302 = None
        transpose_975: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_518, 1, 2);  view_518 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2580: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_2, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_key_cache_2 = None
        slice_2581: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2580, 2, 0, 23);  slice_2580 = None
        slice_2582: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2581, 3, 0, 9223372036854775807);  slice_2581 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2583: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_2, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_value_cache_2 = None
        slice_2584: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2583, 2, 0, 23);  slice_2583 = None
        slice_2585: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2584, 3, 0, 9223372036854775807);  slice_2584 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_976: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2582, 2, 3);  slice_2582 = None
        matmul_478: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_975, transpose_976);  transpose_975 = transpose_976 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2586: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_20, 0, 0, 9223372036854775807)
        slice_2587: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2586, 1, 0, 9223372036854775807);  slice_2586 = None
        slice_2588: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2587, 2, 0, 9223372036854775807);  slice_2587 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_698: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_478, slice_2588);  matmul_478 = slice_2588 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_239: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_698, -1);  add_698 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_743: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_239, 0.0, False);  softmax_239 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_479: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_743, slice_2585);  dropout_743 = slice_2585 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_977: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_479, 1, 2);  matmul_479 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_259: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_977, [1, 1, 512]);  transpose_977 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1000: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_259, p_model_model_decoder_layers_2_encoder_attn_out_proj_weight, p_model_model_decoder_layers_2_encoder_attn_out_proj_bias);  reshape_259 = p_model_model_decoder_layers_2_encoder_attn_out_proj_weight = p_model_model_decoder_layers_2_encoder_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_744: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1000, 0.1, False);  linear_1000 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_699: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_360, dropout_744);  layer_norm_360 = dropout_744 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_361: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_699, [512], p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias);  add_699 = p_model_model_decoder_layers_2_encoder_attn_layer_norm_weight = p_model_model_decoder_layers_2_encoder_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_1001: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_361, p_model_model_decoder_layers_2_fc1_weight, p_model_model_decoder_layers_2_fc1_bias);  p_model_model_decoder_layers_2_fc1_weight = p_model_model_decoder_layers_2_fc1_bias = None
        silu_122: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_1001);  linear_1001 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_745: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_122, 0.0, False);  silu_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_1002: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_745, p_model_model_decoder_layers_2_fc2_weight, p_model_model_decoder_layers_2_fc2_bias);  dropout_745 = p_model_model_decoder_layers_2_fc2_weight = p_model_model_decoder_layers_2_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_746: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1002, 0.1, False);  linear_1002 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_700: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_361, dropout_746);  layer_norm_361 = dropout_746 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_362: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_700, [512], p_model_model_decoder_layers_2_final_layer_norm_weight, p_model_model_decoder_layers_2_final_layer_norm_bias);  add_700 = p_model_model_decoder_layers_2_final_layer_norm_weight = p_model_model_decoder_layers_2_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_1003: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_362, p_model_model_decoder_layers_3_self_attn_q_proj_weight, p_model_model_decoder_layers_3_self_attn_q_proj_bias);  p_model_model_decoder_layers_3_self_attn_q_proj_weight = p_model_model_decoder_layers_3_self_attn_q_proj_bias = None
        mul_303: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_1003, 0.125);  linear_1003 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_519: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_303, [1, 1, 8, 64]);  mul_303 = None
        transpose_978: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_519, 1, 2);  view_519 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_1004: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_362, p_model_model_decoder_layers_3_self_attn_k_proj_weight, p_model_model_decoder_layers_3_self_attn_k_proj_bias);  p_model_model_decoder_layers_3_self_attn_k_proj_weight = p_model_model_decoder_layers_3_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_520: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_1004, [1, -1, 8, 64]);  linear_1004 = None
        transpose_979: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_520, 1, 2);  view_520 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_1005: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_362, p_model_model_decoder_layers_3_self_attn_v_proj_weight, p_model_model_decoder_layers_3_self_attn_v_proj_bias);  p_model_model_decoder_layers_3_self_attn_v_proj_weight = p_model_model_decoder_layers_3_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_521: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_1005, [1, -1, 8, 64]);  linear_1005 = None
        transpose_980: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_521, 1, 2);  view_521 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_367: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_979, torch.float32);  transpose_979 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_368: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_980, torch.float32);  transpose_980 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2589: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 0, 0, 1)
        index_copy__246: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2589, 2, add_682, to_367);  slice_2589 = to_367 = index_copy__246 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2590: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 0, 0, 1)
        index_copy__247: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2590, 2, add_682, to_368);  slice_2590 = to_368 = index_copy__247 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2591: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_3, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_key_cache_3 = None
        slice_2592: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2591, 2, 0, 9223372036854775807);  slice_2591 = None
        slice_2593: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2592, 3, 0, 9223372036854775807);  slice_2592 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2594: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_3, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_value_cache_3 = None
        slice_2595: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2594, 2, 0, 9223372036854775807);  slice_2594 = None
        slice_2596: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2595, 3, 0, 9223372036854775807);  slice_2595 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_981: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2593, 2, 3);  slice_2593 = None
        matmul_480: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_978, transpose_981);  transpose_978 = transpose_981 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2597: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_40, 0, 0, 9223372036854775807)
        slice_2598: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2597, 1, 0, 9223372036854775807);  slice_2597 = None
        slice_2599: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2598, 2, 0, 9223372036854775807);  slice_2598 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_701: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_480, slice_2599);  matmul_480 = slice_2599 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_240: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_701, -1);  add_701 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_747: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_240, 0.0, False);  softmax_240 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_481: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_747, slice_2596);  dropout_747 = slice_2596 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_982: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_481, 1, 2);  matmul_481 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_260: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_982, [1, 1, 512]);  transpose_982 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1006: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_260, p_model_model_decoder_layers_3_self_attn_out_proj_weight, p_model_model_decoder_layers_3_self_attn_out_proj_bias);  reshape_260 = p_model_model_decoder_layers_3_self_attn_out_proj_weight = p_model_model_decoder_layers_3_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_748: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1006, 0.1, False);  linear_1006 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_702: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_362, dropout_748);  layer_norm_362 = dropout_748 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_363: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_702, [512], p_model_model_decoder_layers_3_self_attn_layer_norm_weight, p_model_model_decoder_layers_3_self_attn_layer_norm_bias);  add_702 = p_model_model_decoder_layers_3_self_attn_layer_norm_weight = p_model_model_decoder_layers_3_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_1007: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_363, p_model_model_decoder_layers_3_encoder_attn_q_proj_weight, p_model_model_decoder_layers_3_encoder_attn_q_proj_bias);  p_model_model_decoder_layers_3_encoder_attn_q_proj_weight = p_model_model_decoder_layers_3_encoder_attn_q_proj_bias = None
        mul_304: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_1007, 0.125);  linear_1007 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_522: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_304, [1, 1, 8, 64]);  mul_304 = None
        transpose_983: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_522, 1, 2);  view_522 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2600: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_3, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_key_cache_3 = None
        slice_2601: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2600, 2, 0, 23);  slice_2600 = None
        slice_2602: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2601, 3, 0, 9223372036854775807);  slice_2601 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2603: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_3, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_value_cache_3 = None
        slice_2604: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2603, 2, 0, 23);  slice_2603 = None
        slice_2605: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2604, 3, 0, 9223372036854775807);  slice_2604 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_984: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2602, 2, 3);  slice_2602 = None
        matmul_482: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_983, transpose_984);  transpose_983 = transpose_984 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2606: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_20, 0, 0, 9223372036854775807)
        slice_2607: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2606, 1, 0, 9223372036854775807);  slice_2606 = None
        slice_2608: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2607, 2, 0, 9223372036854775807);  slice_2607 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_703: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_482, slice_2608);  matmul_482 = slice_2608 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_241: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_703, -1);  add_703 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_749: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_241, 0.0, False);  softmax_241 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_483: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_749, slice_2605);  dropout_749 = slice_2605 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_985: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_483, 1, 2);  matmul_483 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_261: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_985, [1, 1, 512]);  transpose_985 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1008: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_261, p_model_model_decoder_layers_3_encoder_attn_out_proj_weight, p_model_model_decoder_layers_3_encoder_attn_out_proj_bias);  reshape_261 = p_model_model_decoder_layers_3_encoder_attn_out_proj_weight = p_model_model_decoder_layers_3_encoder_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_750: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1008, 0.1, False);  linear_1008 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_704: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_363, dropout_750);  layer_norm_363 = dropout_750 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_364: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_704, [512], p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias);  add_704 = p_model_model_decoder_layers_3_encoder_attn_layer_norm_weight = p_model_model_decoder_layers_3_encoder_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_1009: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_364, p_model_model_decoder_layers_3_fc1_weight, p_model_model_decoder_layers_3_fc1_bias);  p_model_model_decoder_layers_3_fc1_weight = p_model_model_decoder_layers_3_fc1_bias = None
        silu_123: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_1009);  linear_1009 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_751: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_123, 0.0, False);  silu_123 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_1010: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_751, p_model_model_decoder_layers_3_fc2_weight, p_model_model_decoder_layers_3_fc2_bias);  dropout_751 = p_model_model_decoder_layers_3_fc2_weight = p_model_model_decoder_layers_3_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_752: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1010, 0.1, False);  linear_1010 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_705: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_364, dropout_752);  layer_norm_364 = dropout_752 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_365: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_705, [512], p_model_model_decoder_layers_3_final_layer_norm_weight, p_model_model_decoder_layers_3_final_layer_norm_bias);  add_705 = p_model_model_decoder_layers_3_final_layer_norm_weight = p_model_model_decoder_layers_3_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_1011: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_365, p_model_model_decoder_layers_4_self_attn_q_proj_weight, p_model_model_decoder_layers_4_self_attn_q_proj_bias);  p_model_model_decoder_layers_4_self_attn_q_proj_weight = p_model_model_decoder_layers_4_self_attn_q_proj_bias = None
        mul_305: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_1011, 0.125);  linear_1011 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_523: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_305, [1, 1, 8, 64]);  mul_305 = None
        transpose_986: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_523, 1, 2);  view_523 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_1012: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_365, p_model_model_decoder_layers_4_self_attn_k_proj_weight, p_model_model_decoder_layers_4_self_attn_k_proj_bias);  p_model_model_decoder_layers_4_self_attn_k_proj_weight = p_model_model_decoder_layers_4_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_524: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_1012, [1, -1, 8, 64]);  linear_1012 = None
        transpose_987: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_524, 1, 2);  view_524 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_1013: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_365, p_model_model_decoder_layers_4_self_attn_v_proj_weight, p_model_model_decoder_layers_4_self_attn_v_proj_bias);  p_model_model_decoder_layers_4_self_attn_v_proj_weight = p_model_model_decoder_layers_4_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_525: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_1013, [1, -1, 8, 64]);  linear_1013 = None
        transpose_988: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_525, 1, 2);  view_525 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_369: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_987, torch.float32);  transpose_987 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_370: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_988, torch.float32);  transpose_988 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2609: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 0, 0, 1)
        index_copy__248: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2609, 2, add_682, to_369);  slice_2609 = to_369 = index_copy__248 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2610: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 0, 0, 1)
        index_copy__249: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2610, 2, add_682, to_370);  slice_2610 = to_370 = index_copy__249 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2611: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_4, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_key_cache_4 = None
        slice_2612: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2611, 2, 0, 9223372036854775807);  slice_2611 = None
        slice_2613: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2612, 3, 0, 9223372036854775807);  slice_2612 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2614: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_4, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_value_cache_4 = None
        slice_2615: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2614, 2, 0, 9223372036854775807);  slice_2614 = None
        slice_2616: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2615, 3, 0, 9223372036854775807);  slice_2615 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_989: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2613, 2, 3);  slice_2613 = None
        matmul_484: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_986, transpose_989);  transpose_986 = transpose_989 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2617: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_40, 0, 0, 9223372036854775807)
        slice_2618: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2617, 1, 0, 9223372036854775807);  slice_2617 = None
        slice_2619: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2618, 2, 0, 9223372036854775807);  slice_2618 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_706: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_484, slice_2619);  matmul_484 = slice_2619 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_242: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_706, -1);  add_706 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_753: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_242, 0.0, False);  softmax_242 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_485: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_753, slice_2616);  dropout_753 = slice_2616 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_990: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_485, 1, 2);  matmul_485 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_262: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_990, [1, 1, 512]);  transpose_990 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1014: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_262, p_model_model_decoder_layers_4_self_attn_out_proj_weight, p_model_model_decoder_layers_4_self_attn_out_proj_bias);  reshape_262 = p_model_model_decoder_layers_4_self_attn_out_proj_weight = p_model_model_decoder_layers_4_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_754: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1014, 0.1, False);  linear_1014 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_707: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_365, dropout_754);  layer_norm_365 = dropout_754 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_366: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_707, [512], p_model_model_decoder_layers_4_self_attn_layer_norm_weight, p_model_model_decoder_layers_4_self_attn_layer_norm_bias);  add_707 = p_model_model_decoder_layers_4_self_attn_layer_norm_weight = p_model_model_decoder_layers_4_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_1015: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_366, p_model_model_decoder_layers_4_encoder_attn_q_proj_weight, p_model_model_decoder_layers_4_encoder_attn_q_proj_bias);  p_model_model_decoder_layers_4_encoder_attn_q_proj_weight = p_model_model_decoder_layers_4_encoder_attn_q_proj_bias = None
        mul_306: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_1015, 0.125);  linear_1015 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_526: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_306, [1, 1, 8, 64]);  mul_306 = None
        transpose_991: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_526, 1, 2);  view_526 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2620: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_4, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_key_cache_4 = None
        slice_2621: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2620, 2, 0, 23);  slice_2620 = None
        slice_2622: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2621, 3, 0, 9223372036854775807);  slice_2621 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2623: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_4, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_value_cache_4 = None
        slice_2624: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2623, 2, 0, 23);  slice_2623 = None
        slice_2625: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2624, 3, 0, 9223372036854775807);  slice_2624 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_992: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2622, 2, 3);  slice_2622 = None
        matmul_486: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_991, transpose_992);  transpose_991 = transpose_992 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2626: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_20, 0, 0, 9223372036854775807)
        slice_2627: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2626, 1, 0, 9223372036854775807);  slice_2626 = None
        slice_2628: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2627, 2, 0, 9223372036854775807);  slice_2627 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_708: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_486, slice_2628);  matmul_486 = slice_2628 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_243: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_708, -1);  add_708 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_755: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_243, 0.0, False);  softmax_243 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_487: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_755, slice_2625);  dropout_755 = slice_2625 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_993: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_487, 1, 2);  matmul_487 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_263: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_993, [1, 1, 512]);  transpose_993 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1016: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_263, p_model_model_decoder_layers_4_encoder_attn_out_proj_weight, p_model_model_decoder_layers_4_encoder_attn_out_proj_bias);  reshape_263 = p_model_model_decoder_layers_4_encoder_attn_out_proj_weight = p_model_model_decoder_layers_4_encoder_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_756: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1016, 0.1, False);  linear_1016 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_709: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_366, dropout_756);  layer_norm_366 = dropout_756 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_367: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_709, [512], p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias);  add_709 = p_model_model_decoder_layers_4_encoder_attn_layer_norm_weight = p_model_model_decoder_layers_4_encoder_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_1017: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_367, p_model_model_decoder_layers_4_fc1_weight, p_model_model_decoder_layers_4_fc1_bias);  p_model_model_decoder_layers_4_fc1_weight = p_model_model_decoder_layers_4_fc1_bias = None
        silu_124: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_1017);  linear_1017 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_757: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_124, 0.0, False);  silu_124 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_1018: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_757, p_model_model_decoder_layers_4_fc2_weight, p_model_model_decoder_layers_4_fc2_bias);  dropout_757 = p_model_model_decoder_layers_4_fc2_weight = p_model_model_decoder_layers_4_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_758: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1018, 0.1, False);  linear_1018 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_710: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_367, dropout_758);  layer_norm_367 = dropout_758 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_368: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_710, [512], p_model_model_decoder_layers_4_final_layer_norm_weight, p_model_model_decoder_layers_4_final_layer_norm_bias);  add_710 = p_model_model_decoder_layers_4_final_layer_norm_weight = p_model_model_decoder_layers_4_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_1019: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_368, p_model_model_decoder_layers_5_self_attn_q_proj_weight, p_model_model_decoder_layers_5_self_attn_q_proj_bias);  p_model_model_decoder_layers_5_self_attn_q_proj_weight = p_model_model_decoder_layers_5_self_attn_q_proj_bias = None
        mul_307: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_1019, 0.125);  linear_1019 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_527: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_307, [1, 1, 8, 64]);  mul_307 = None
        transpose_994: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_527, 1, 2);  view_527 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:202 in forward, code: key_states = self._shape(self.k_proj(current_states), -1, bsz)
        linear_1020: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_368, p_model_model_decoder_layers_5_self_attn_k_proj_weight, p_model_model_decoder_layers_5_self_attn_k_proj_bias);  p_model_model_decoder_layers_5_self_attn_k_proj_weight = p_model_model_decoder_layers_5_self_attn_k_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_528: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_1020, [1, -1, 8, 64]);  linear_1020 = None
        transpose_995: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_528, 1, 2);  view_528 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:203 in forward, code: value_states = self._shape(self.v_proj(current_states), -1, bsz)
        linear_1021: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_368, p_model_model_decoder_layers_5_self_attn_v_proj_weight, p_model_model_decoder_layers_5_self_attn_v_proj_bias);  p_model_model_decoder_layers_5_self_attn_v_proj_weight = p_model_model_decoder_layers_5_self_attn_v_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_529: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(linear_1021, [1, -1, 8, 64]);  linear_1021 = None
        transpose_996: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_529, 1, 2);  view_529 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1198 in update, code: key_states = key_states.to(k_out.dtype)
        to_371: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_995, torch.float32);  transpose_995 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1199 in update, code: value_states = value_states.to(v_out.dtype)
        to_372: "f32[1, 8, 1, 64]" = torch.ops.aten.to.dtype(transpose_996, torch.float32);  transpose_996 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1211 in update, code: k_out[:bz].index_copy_(2, cache_position, key_states)
        slice_2629: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 0, 0, 1)
        index_copy__250: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2629, 2, add_682, to_371);  slice_2629 = to_371 = index_copy__250 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/cache_utils.py:1212 in update, code: v_out[:bz].index_copy_(2, cache_position, value_states)
        slice_2630: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 0, 0, 1)
        index_copy__251: "f32[1, 8, 20, 64]" = torch.ops.aten.index_copy_.default(slice_2630, 2, add_682, to_372);  slice_2630 = to_372 = index_copy__251 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:224 in forward, code: key_states = key_states_full[:batch_size, :, :, :]
        slice_2631: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_key_cache_5, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_key_cache_5 = None
        slice_2632: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2631, 2, 0, 9223372036854775807);  slice_2631 = None
        slice_2633: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2632, 3, 0, 9223372036854775807);  slice_2632 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:225 in forward, code: value_states = value_states_full[:batch_size, :, :, :]
        slice_2634: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(b___cache_self_attention_cache_value_cache_5, 1, 0, 9223372036854775807);  b___cache_self_attention_cache_value_cache_5 = None
        slice_2635: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2634, 2, 0, 9223372036854775807);  slice_2634 = None
        slice_2636: "f32[1, 8, 20, 64]" = torch.ops.aten.slice.Tensor(slice_2635, 3, 0, 9223372036854775807);  slice_2635 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_997: "f32[1, 8, 64, 20]" = torch.ops.aten.transpose.int(slice_2633, 2, 3);  slice_2633 = None
        matmul_488: "f32[1, 8, 1, 20]" = torch.ops.aten.matmul.default(transpose_994, transpose_997);  transpose_994 = transpose_997 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2637: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(expand_40, 0, 0, 9223372036854775807);  expand_40 = None
        slice_2638: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2637, 1, 0, 9223372036854775807);  slice_2637 = None
        slice_2639: "f32[1, 1, 1, 20]" = torch.ops.aten.slice.Tensor(slice_2638, 2, 0, 9223372036854775807);  slice_2638 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_711: "f32[1, 8, 1, 20]" = torch.ops.aten.add.Tensor(matmul_488, slice_2639);  matmul_488 = slice_2639 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_244: "f32[1, 8, 1, 20]" = torch.ops.aten.softmax.int(add_711, -1);  add_711 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_759: "f32[1, 8, 1, 20]" = torch.ops.aten.dropout.default(softmax_244, 0.0, False);  softmax_244 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_489: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_759, slice_2636);  dropout_759 = slice_2636 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_998: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_489, 1, 2);  matmul_489 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_264: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_998, [1, 1, 512]);  transpose_998 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1022: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_264, p_model_model_decoder_layers_5_self_attn_out_proj_weight, p_model_model_decoder_layers_5_self_attn_out_proj_bias);  reshape_264 = p_model_model_decoder_layers_5_self_attn_out_proj_weight = p_model_model_decoder_layers_5_self_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:414 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_760: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1022, 0.1, False);  linear_1022 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:415 in forward, code: hidden_states = residual + hidden_states
        add_712: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_368, dropout_760);  layer_norm_368 = dropout_760 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:416 in forward, code: hidden_states = self.self_attn_layer_norm(hidden_states)
        layer_norm_369: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_712, [512], p_model_model_decoder_layers_5_self_attn_layer_norm_weight, p_model_model_decoder_layers_5_self_attn_layer_norm_bias);  add_712 = p_model_model_decoder_layers_5_self_attn_layer_norm_weight = p_model_model_decoder_layers_5_self_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:176 in forward, code: query_states = self._shape(self.q_proj(hidden_states) * self.scaling, tgt_len, bsz)
        linear_1023: "f32[1, 1, 512]" = torch.ops.aten.linear.default(layer_norm_369, p_model_model_decoder_layers_5_encoder_attn_q_proj_weight, p_model_model_decoder_layers_5_encoder_attn_q_proj_bias);  p_model_model_decoder_layers_5_encoder_attn_q_proj_weight = p_model_model_decoder_layers_5_encoder_attn_q_proj_bias = None
        mul_308: "f32[1, 1, 512]" = torch.ops.aten.mul.Tensor(linear_1023, 0.125);  linear_1023 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:155 in _shape, code: return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()
        view_530: "f32[1, 1, 8, 64]" = torch.ops.aten.view.default(mul_308, [1, 1, 8, 64]);  mul_308 = None
        transpose_999: "f32[1, 8, 1, 64]" = torch.ops.aten.transpose.int(view_530, 1, 2);  view_530 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:199 in forward, code: key_states = key_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2640: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_key_cache_5, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_key_cache_5 = None
        slice_2641: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2640, 2, 0, 23);  slice_2640 = None
        slice_2642: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2641, 3, 0, 9223372036854775807);  slice_2641 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:200 in forward, code: value_states = value_states_full[:batch_size, :, :cross_seq_length, :]
        slice_2643: "f32[1, 8, 40, 64]" = torch.ops.aten.slice.Tensor(b___cache_cross_attention_cache_value_cache_5, 1, 0, 9223372036854775807);  b___cache_cross_attention_cache_value_cache_5 = None
        slice_2644: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2643, 2, 0, 23);  slice_2643 = None
        slice_2645: "f32[1, 8, 23, 64]" = torch.ops.aten.slice.Tensor(slice_2644, 3, 0, 9223372036854775807);  slice_2644 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:227 in forward, code: attn_weights = torch.matmul(query_states, key_states.transpose(2, 3))
        transpose_1000: "f32[1, 8, 64, 23]" = torch.ops.aten.transpose.int(slice_2642, 2, 3);  slice_2642 = None
        matmul_490: "f32[1, 8, 1, 23]" = torch.ops.aten.matmul.default(transpose_999, transpose_1000);  transpose_999 = transpose_1000 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:230 in forward, code: causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]
        slice_2646: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(masked_fill_20, 0, 0, 9223372036854775807);  masked_fill_20 = None
        slice_2647: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2646, 1, 0, 9223372036854775807);  slice_2646 = None
        slice_2648: "f32[1, 1, 1, 23]" = torch.ops.aten.slice.Tensor(slice_2647, 2, 0, 9223372036854775807);  slice_2647 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:231 in forward, code: attn_weights = attn_weights + causal_mask
        add_713: "f32[1, 8, 1, 23]" = torch.ops.aten.add.Tensor(matmul_490, slice_2648);  matmul_490 = slice_2648 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:233 in forward, code: attn_weights = nn.functional.softmax(attn_weights, dim=-1)
        softmax_245: "f32[1, 8, 1, 23]" = torch.ops.aten.softmax.int(add_713, -1);  add_713 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:243 in forward, code: attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
        dropout_761: "f32[1, 8, 1, 23]" = torch.ops.aten.dropout.default(softmax_245, 0.0, False);  softmax_245 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:244 in forward, code: attn_output = torch.matmul(attn_probs, value_states)
        matmul_491: "f32[1, 8, 1, 64]" = torch.ops.aten.matmul.default(dropout_761, slice_2645);  dropout_761 = slice_2645 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:252 in forward, code: attn_output = attn_output.transpose(1, 2)
        transpose_1001: "f32[1, 1, 8, 64]" = torch.ops.aten.transpose.int(matmul_491, 1, 2);  matmul_491 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:255 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)
        reshape_265: "f32[1, 1, 512]" = torch.ops.aten.reshape.default(transpose_1001, [1, 1, 512]);  transpose_1001 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:257 in forward, code: attn_output = self.out_proj(attn_output)
        linear_1024: "f32[1, 1, 512]" = torch.ops.aten.linear.default(reshape_265, p_model_model_decoder_layers_5_encoder_attn_out_proj_weight, p_model_model_decoder_layers_5_encoder_attn_out_proj_bias);  reshape_265 = p_model_model_decoder_layers_5_encoder_attn_out_proj_weight = p_model_model_decoder_layers_5_encoder_attn_out_proj_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:434 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_762: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1024, 0.1, False);  linear_1024 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:435 in forward, code: hidden_states = residual + hidden_states
        add_714: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_369, dropout_762);  layer_norm_369 = dropout_762 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:436 in forward, code: hidden_states = self.encoder_attn_layer_norm(hidden_states)
        layer_norm_370: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_714, [512], p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight, p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias);  add_714 = p_model_model_decoder_layers_5_encoder_attn_layer_norm_weight = p_model_model_decoder_layers_5_encoder_attn_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:443 in forward, code: hidden_states = self.activation_fn(self.fc1(hidden_states))
        linear_1025: "f32[1, 1, 2048]" = torch.ops.aten.linear.default(layer_norm_370, p_model_model_decoder_layers_5_fc1_weight, p_model_model_decoder_layers_5_fc1_bias);  p_model_model_decoder_layers_5_fc1_weight = p_model_model_decoder_layers_5_fc1_bias = None
        silu_125: "f32[1, 1, 2048]" = torch.ops.aten.silu.default(linear_1025);  linear_1025 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:444 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)
        dropout_763: "f32[1, 1, 2048]" = torch.ops.aten.dropout.default(silu_125, 0.0, False);  silu_125 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:445 in forward, code: hidden_states = self.fc2(hidden_states)
        linear_1026: "f32[1, 1, 512]" = torch.ops.aten.linear.default(dropout_763, p_model_model_decoder_layers_5_fc2_weight, p_model_model_decoder_layers_5_fc2_bias);  dropout_763 = p_model_model_decoder_layers_5_fc2_weight = p_model_model_decoder_layers_5_fc2_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:446 in forward, code: hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
        dropout_764: "f32[1, 1, 512]" = torch.ops.aten.dropout.default(linear_1026, 0.1, False);  linear_1026 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:447 in forward, code: hidden_states = residual + hidden_states
        add_715: "f32[1, 1, 512]" = torch.ops.aten.add.Tensor(layer_norm_370, dropout_764);  layer_norm_370 = dropout_764 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:448 in forward, code: hidden_states = self.final_layer_norm(hidden_states)
        layer_norm_371: "f32[1, 1, 512]" = torch.ops.aten.layer_norm.default(add_715, [512], p_model_model_decoder_layers_5_final_layer_norm_weight, p_model_model_decoder_layers_5_final_layer_norm_bias);  add_715 = p_model_model_decoder_layers_5_final_layer_norm_weight = p_model_model_decoder_layers_5_final_layer_norm_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/models/marian/modeling_marian.py:1592 in forward, code: lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias
        linear_1027: "f32[1, 1, 59514]" = torch.ops.aten.linear.default(layer_norm_371, p_model_lm_head_weight);  layer_norm_371 = p_model_lm_head_weight = None
        add_716: "f32[1, 1, 59514]" = torch.ops.aten.add.Tensor(linear_1027, b_model_final_logits_bias);  linear_1027 = b_model_final_logits_bias = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:800 in _update_model_kwargs_for_generation, code: model_kwargs["cache_position"] = model_kwargs["cache_position"][-1:] + num_new_tokens
        slice_2649: "i64[1]" = torch.ops.aten.slice.Tensor(add_682, 0, -1, 9223372036854775807);  add_682 = None
        add_717: "i64[1]" = torch.ops.aten.add.Tensor(slice_2649, 1);  slice_2649 = add_717 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3269 in _sample, code: next_token_logits = outputs.logits[:, -1, :].clone().float()
        slice_2650: "f32[1, 1, 59514]" = torch.ops.aten.slice.Tensor(add_716, 0, 0, 9223372036854775807);  add_716 = None
        select_84: "f32[1, 59514]" = torch.ops.aten.select.int(slice_2650, 1, -1);  slice_2650 = None
        slice_2651: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(select_84, 1, 0, 9223372036854775807);  select_84 = None
        clone_39: "f32[1, 59514]" = torch.ops.aten.clone.default(slice_2651);  slice_2651 = None
        to_373: "f32[1, 59514]" = torch.ops.aten.to.dtype(clone_39, torch.float32);  clone_39 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3270 in _sample, code: next_token_logits = next_token_logits.to(input_ids.device)
        to_374: "f32[1, 59514]" = torch.ops.aten.to.dtype_layout(to_373, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'));  to_373 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1131 in __call__, code: bias = torch.zeros_like(scores)
        zeros_like_19: "f32[1, 59514]" = torch.ops.aten.zeros_like.default(to_374, pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1134 in __call__, code: bias += self.length_1_bias
        add__19: "f32[1, 59514]" = torch.ops.aten.add_.Tensor(zeros_like_19, to_32);  zeros_like_19 = to_32 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1155 in __call__, code: scores_processed = scores + bias
        add_718: "f32[1, 59514]" = torch.ops.aten.add.Tensor(to_374, add__19);  to_374 = add__19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1619 in __call__, code: scores_processed = torch.full_like(scores, -math.inf)
        full_like: "f32[1, 59514]" = torch.ops.aten.full_like.default(add_718, -inf, pin_memory = False);  add_718 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1620 in __call__, code: scores_processed[:, self.eos_token_id] = 0
        lift_fresh_copy_6: "f32[]" = torch.ops.aten.lift_fresh_copy.default(c_lifted_tensor_6);  c_lifted_tensor_6 = None
        slice_2652: "f32[1, 59514]" = torch.ops.aten.slice.Tensor(full_like, 0, 0, 9223372036854775807)
        index_put_: "f32[1, 59514]" = torch.ops.aten.index_put_.default(slice_2652, [None, detach__4], lift_fresh_copy_6);  slice_2652 = detach__4 = lift_fresh_copy_6 = index_put_ = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/logits_process.py:1779 in __call__, code: scores_processed = scores.log_softmax(dim=-1)
        log_softmax_19: "f32[1, 59514]" = torch.ops.aten.log_softmax.int(full_like, -1);  full_like = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3301 in _sample, code: next_tokens = torch.argmax(next_token_scores, dim=-1)
        argmax_19: "i64[1]" = torch.ops.aten.argmax.default(log_softmax_19, -1);  log_softmax_19 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3305 in _sample, code: next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)
        mul_309: "i64[1]" = torch.ops.aten.mul.Tensor(argmax_19, and_19);  argmax_19 = None
        rsub_40: "i64[1]" = torch.ops.aten.rsub.Scalar(and_19, 1)
        mul_310: "i64[1]" = torch.ops.aten.mul.Tensor(detach__2, rsub_40);  detach__2 = rsub_40 = None
        add_719: "i64[1]" = torch.ops.aten.add.Tensor(mul_309, mul_310);  mul_309 = mul_310 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3308 in _sample, code: input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)
        slice_2653: "i64[1]" = torch.ops.aten.slice.Tensor(add_719, 0, 0, 9223372036854775807);  add_719 = None
        unsqueeze_122: "i64[1, 1]" = torch.ops.aten.unsqueeze.default(slice_2653, 1);  slice_2653 = None
        cat_19: "i64[1, 21]" = torch.ops.aten.cat.default([cat_18, unsqueeze_122], -1);  cat_18 = unsqueeze_122 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:494 in __call__, code: is_done = torch.full((input_ids.shape[0],), False, device=input_ids.device, dtype=torch.bool)
        full_58: "b8[1]" = torch.ops.aten.full.default([1], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:84 in __call__, code: return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)
        full_59: "b8[1]" = torch.ops.aten.full.default([1], True, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_39: "b8[1]" = torch.ops.aten.__or__.Tensor(full_58, full_59);  full_58 = full_59 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:465 in __call__, code: self.eos_token_id = self.eos_token_id.to(input_ids.device)
        to_375: "i64[1]" = torch.ops.aten.to.dtype_layout(to_357, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'));  to_357 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:466 in __call__, code: is_done = isin_mps_friendly(input_ids[:, -1], self.eos_token_id)
        slice_2654: "i64[1, 21]" = torch.ops.aten.slice.Tensor(cat_19, 0, 0, 9223372036854775807)
        select_85: "i64[1]" = torch.ops.aten.select.int(slice_2654, 1, -1);  slice_2654 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/pytorch_utils.py:338 in isin_mps_friendly, code: return torch.isin(elements, test_elements)
        isin_21: "b8[1]" = torch.ops.aten.isin.Tensor_Tensor(select_85, to_375);  select_85 = to_375 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/stopping_criteria.py:496 in __call__, code: is_done = is_done | criteria(input_ids, scores, **kwargs)
        or_40: "b8[1]" = torch.ops.aten.__or__.Tensor(or_39, isin_21);  or_39 = isin_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3312 in _sample, code: unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)
        bitwise_not_21: "b8[1]" = torch.ops.aten.bitwise_not.default(or_40);  or_40 = None
        and_20: "i64[1]" = torch.ops.aten.__and__.Tensor(and_19, bitwise_not_21);  and_19 = bitwise_not_21 = None
        
         # File: /home/nlong/execu-tools/transformers/src/transformers/generation/utils.py:3313 in _sample, code: this_peer_finished = unfinished_sequences.max() == 0
        max_20: "i64[]" = torch.ops.aten.max.default(and_20);  and_20 = None
        eq_19: "b8[]" = torch.ops.aten.eq.Scalar(max_20, 0);  max_20 = eq_19 = None
        return (cat_19,)
        